defaults:
  - pretraining_hyperparameter_sweep_base # IMPORTANT: This defaults to the pre-defined repository config!
  - _self_

parameters:
  experiment_dir:
    value: /home/filip-marcus/ESGPT_new/EventStreamGPT
  data_config:
    save_dir:
      value: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/synthetic_mega
  config:
    measurements_per_dep_graph_level:
      values: null
    head_dim:
      max: 18
      min: 8
    hidden_size:
      max: 180
      min: 8
    structured_event_processing_mode:
      values: ["conditionally_independent"]
    intermediate_size:
      max: 128
      min: 8
    num_attention_heads:
      max: 10
      min: 2
    num_hidden_layers:
      max: 8
    seq_attention_types:
      values: ['global']
    static_embedding_mode:
      values: ['drop']
    do_split_embeddings:
      values: [False]    
  optimization_config:
    num_dataloader_workers:
      value: 5
    max_epochs:
      value: 50
    patience: 
      value: 10
    batch_size:
      max: 128
      min: 64
  trainer_config:
    log_every_n_steps:
      value: 20

    
  
  do_overwrite: 
    value: True 

entity: "marcus-student-chalmers"
project: "Hyperparameter_sweep_synthetic"
run_cap: 30



