defaults:
  - finetune_config
  - _self_

do_overwrite: true
seed: 1
strategy: 1-3
load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/synthetic_1/finetuning/task_df_synthetic_interruption_in_seq/finetune_weights
task_df_name: task_df_synthetic_interruption_next_week
pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/synthetic_1/finetuning/task_df_synthetic_interruption_in_seq/finetune_weights
data_config:
  save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/synthetic_1
  max_seq_len: 409
optimization_config:
  init_lr: 0.0006398098082729676
  end_lr: 8.05022482949952e-06
  end_lr_frac_of_init_lr: 0.012582215410591178
  max_epochs: 100
  batch_size: 106
  validation_batch_size: 32
  lr_frac_warmup_steps: 6.821087018693635e-06
  lr_num_warmup_steps: 0
  max_training_steps: 700
  lr_decay_power: 4.915424972614257
  weight_decay: 0.927050268775883
  patience: 15
  gradient_accumulation: 1
  gradient_clip_val: 1
  num_dataloader_workers: 5
