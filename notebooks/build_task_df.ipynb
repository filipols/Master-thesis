{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e05c17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filip-marcus/.local/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/filip-marcus/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import os\n",
    "import sys\n",
    "import rootutils\n",
    "sys.path.append('/home/filip-marcus/ESGPT_new/EventStreamGPT/')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "from EventStream.data.dataset_polars import Dataset\n",
    "\n",
    "# root = rootutils.setup_root(os.path.abspath(\"\"), dotenv=True, pythonpath=True, cwd=False)\n",
    " # CHECK IF YOU WANT NEW OR OLD DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7960a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_event_type(type_str: str) -> pl.Expr:\n",
    "    event_types = pl.col(\"event_type\").cast(pl.Utf8).str.split(\"&\")\n",
    "    return event_types.list.contains(type_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd3244",
   "metadata": {},
   "source": [
    "### Test ECOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d411ff0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m COHORT_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_ecom\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m PROJECT_DIR \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/filip-marcus/models/ESGPT_new/EventStreamGPT\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m DATA_DIR \u001b[38;5;241m=\u001b[39m PROJECT_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/processed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m COHORT_NAME\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m DATA_DIR\u001b[38;5;241m.\u001b[39mis_dir()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "COHORT_NAME = \"test_ecom\"\n",
    "PROJECT_DIR = Path('/home/filip-marcus/models/ESGPT_new/EventStreamGPT')\n",
    "DATA_DIR = PROJECT_DIR / \"data/processed\" / COHORT_NAME\n",
    "assert DATA_DIR.is_dir()\n",
    "\n",
    "TASK_DF_DIR = DATA_DIR / \"task_dfs\"\n",
    "TASK_DF_DIR.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "ESD = Dataset.load(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c205b08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading events from /home/filip-marcus/models/ESGPT_new/EventStreamGPT/data/processed/test_ecom/events_df.parquet...\n",
      "shape: (6_024, 4)\n",
      "┌──────────┬────────────┬─────────────────────┬────────────┐\n",
      "│ event_id ┆ subject_id ┆ timestamp           ┆ event_type │\n",
      "│ ---      ┆ ---        ┆ ---                 ┆ ---        │\n",
      "│ u16      ┆ u16        ┆ datetime[μs]        ┆ cat        │\n",
      "╞══════════╪════════════╪═════════════════════╪════════════╡\n",
      "│ 3        ┆ 1          ┆ 2020-09-24 12:19:57 ┆ view       │\n",
      "│ 25       ┆ 16         ┆ 2020-09-24 15:06:38 ┆ view       │\n",
      "│ 31       ┆ 16         ┆ 2020-09-24 15:41:46 ┆ view       │\n",
      "│ 38       ┆ 16         ┆ 2020-09-25 09:08:01 ┆ view       │\n",
      "│ …        ┆ …          ┆ …                   ┆ …          │\n",
      "│ 9869     ┆ 5601       ┆ 2020-09-26 22:23:35 ┆ view       │\n",
      "│ 9892     ┆ 5619       ┆ 2020-09-26 22:54:36 ┆ view       │\n",
      "│ 9916     ┆ 5637       ┆ 2020-09-26 23:30:51 ┆ view       │\n",
      "│ 9918     ┆ 5637       ┆ 2020-09-26 23:40:27 ┆ view       │\n",
      "└──────────┴────────────┴─────────────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "events_df = ESD.events_df.lazy()\n",
    "print(events_df.collect().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<polars.expr.expr.Expr object at 0x71b3584ff820>, <polars.expr.expr.Expr object at 0x71b3584fee60>, <polars.expr.expr.Expr object at 0x71b3584fdb40>]\n",
      "CPU times: user 379 μs, sys: 90 μs, total: 469 μs\n",
      "Wall time: 470 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "event_types = ['view', 'cart','purchase']\n",
    "\n",
    "# Create boolean flags for each event type in the event sequence\n",
    "event_flags = [has_event_type(event).alias(f\"is_{event.lower()}\") for event in event_types]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30052f",
   "metadata": {},
   "source": [
    "#### Dummy task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa8f3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_727, 4)\n",
      "┌────────────┬─────────────────────┬─────────────────────┬───────┐\n",
      "│ subject_id ┆ start_time          ┆ end_time            ┆ label │\n",
      "│ ---        ┆ ---                 ┆ ---                 ┆ ---   │\n",
      "│ u16        ┆ datetime[μs]        ┆ datetime[μs]        ┆ i32   │\n",
      "╞════════════╪═════════════════════╪═════════════════════╪═══════╡\n",
      "│ 1          ┆ 2020-09-24 11:57:26 ┆ 2020-09-24 12:19:57 ┆ 1     │\n",
      "│ 8          ┆ 2020-09-24 11:58:25 ┆ 2020-09-24 12:07:26 ┆ 1     │\n",
      "│ 10         ┆ 2020-09-24 11:58:34 ┆ 2020-09-24 12:00:59 ┆ 1     │\n",
      "│ 11         ┆ 2020-09-24 11:59:26 ┆ 2020-09-24 12:02:12 ┆ 1     │\n",
      "│ …          ┆ …                   ┆ …                   ┆ …     │\n",
      "│ 5658       ┆ 2020-09-27 00:38:10 ┆ 2020-09-27 00:39:00 ┆ 1     │\n",
      "│ 5659       ┆ 2020-09-27 00:49:03 ┆ 2020-09-27 00:57:44 ┆ 1     │\n",
      "│ 5661       ┆ 2020-09-27 00:54:25 ┆ 2020-09-27 00:57:28 ┆ 1     │\n",
      "│ 5662       ┆ 2020-09-27 00:56:08 ┆ 2020-09-27 01:00:16 ┆ 1     │\n",
      "└────────────┴─────────────────────┴─────────────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Create event data and calculate class distribution for each sequence\n",
    "class_distribution_df = (\n",
    "    events_df.with_columns(*event_flags)  # Add all event flags\n",
    "    .filter(\n",
    "        pl.col(\"timestamp\").is_not_null() & pl.col(\"subject_id\").is_not_null()  # Remove invalid rows\n",
    "    )\n",
    "    .sort([\"subject_id\", \"timestamp\"], descending=False)  # Sort by subject and timestamp\n",
    "    .with_columns(\n",
    "        [\n",
    "            pl.when(pl.col(f\"is_{event.lower()}\")).then(pl.lit(1)).otherwise(pl.lit(0)).alias(f\"{event.lower()}_class\")\n",
    "            for event in event_types\n",
    "        ]\n",
    "    )\n",
    "    .groupby(\"subject_id\")\n",
    "    .agg(\n",
    "        # Calculate the class distribution per subject_id\n",
    "        *[\n",
    "            (pl.col(f\"{event.lower()}_class\").sum() / pl.col(f\"{event.lower()}_class\").count()).alias(f\"{event.lower()}_dist\")\n",
    "            for event in event_types\n",
    "        ],\n",
    "        pl.col(\"timestamp\").min().alias(\"start_time\"),\n",
    "        pl.col(\"timestamp\").max().alias(\"end_time\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Task dataframe: Select relevant columns for class distribution\n",
    "class_distribution_df_all = class_distribution_df.select([\"subject_id\", \"start_time\", \"end_time\"] + [f\"{event.lower()}_dist\" for event in event_types])\n",
    "\n",
    "\n",
    "# DUMMY SECTION\n",
    "class_distribution_df_all = class_distribution_df_all.select(class_distribution_df_all.columns[:-2])\n",
    "\n",
    "last_col = class_distribution_df_all.columns[-1]\n",
    "\n",
    "# Modify the last column based on the condition\n",
    "class_distribution_df_all = class_distribution_df_all.with_columns(\n",
    "    pl.when(pl.col(last_col) > 0.0)\n",
    "    .then(1)\n",
    "    .otherwise(0)\n",
    "    .alias(\"label\")\n",
    ")\n",
    "class_distribution_df_all = class_distribution_df_all.select([\"subject_id\", \"start_time\",\"end_time\", \"label\"])\n",
    "# END DUMMY SECTION\n",
    "\n",
    "print(class_distribution_df_all.collect())\n",
    "\n",
    "# Save the class distribution DataFrame\n",
    "# class_distribution_df_all.collect().write_parquet(TASK_DF_DIR / \"task_df_ecom_cls_test.parquet\")\n",
    "# print(f\"saved task_df to {TASK_DF_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed08f9",
   "metadata": {},
   "source": [
    "#### Class dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5478979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_727, 6)\n",
      "┌────────────┬─────────────────────┬─────────────────────┬───────────┬───────────┬───────────────┐\n",
      "│ subject_id ┆ start_time          ┆ end_time            ┆ view_dist ┆ cart_dist ┆ purchase_dist │\n",
      "│ ---        ┆ ---                 ┆ ---                 ┆ ---       ┆ ---       ┆ ---           │\n",
      "│ u16        ┆ datetime[μs]        ┆ datetime[μs]        ┆ f64       ┆ f64       ┆ f64           │\n",
      "╞════════════╪═════════════════════╪═════════════════════╪═══════════╪═══════════╪═══════════════╡\n",
      "│ 1          ┆ 2020-09-24 11:57:26 ┆ 2020-09-24 12:19:57 ┆ 1.0       ┆ 0.0       ┆ 0.0           │\n",
      "│ 8          ┆ 2020-09-24 11:58:25 ┆ 2020-09-24 12:07:26 ┆ 1.0       ┆ 0.0       ┆ 0.0           │\n",
      "│ 10         ┆ 2020-09-24 11:58:34 ┆ 2020-09-24 12:00:59 ┆ 1.0       ┆ 0.0       ┆ 0.0           │\n",
      "│ 11         ┆ 2020-09-24 11:59:26 ┆ 2020-09-24 12:02:12 ┆ 1.0       ┆ 0.0       ┆ 0.0           │\n",
      "│ …          ┆ …                   ┆ …                   ┆ …         ┆ …         ┆ …             │\n",
      "│ 5658       ┆ 2020-09-27 00:38:10 ┆ 2020-09-27 00:39:00 ┆ 1.0       ┆ 0.0       ┆ 0.0           │\n",
      "│ 5659       ┆ 2020-09-27 00:49:03 ┆ 2020-09-27 00:57:44 ┆ 1.0       ┆ 0.0       ┆ 0.0           │\n",
      "│ 5661       ┆ 2020-09-27 00:54:25 ┆ 2020-09-27 00:57:28 ┆ 0.5       ┆ 0.5       ┆ 0.0           │\n",
      "│ 5662       ┆ 2020-09-27 00:56:08 ┆ 2020-09-27 01:00:16 ┆ 1.0       ┆ 0.0       ┆ 0.0           │\n",
      "└────────────┴─────────────────────┴─────────────────────┴───────────┴───────────┴───────────────┘\n",
      "saved task_df to /home/filip-marcus/models/ESGPT_new/EventStreamGPT/data/processed/test_ecom/task_dfs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create event data and calculate class distribution for each sequence\n",
    "class_distribution_df = (\n",
    "    events_df.with_columns(*event_flags)  # Add all event flags\n",
    "    .filter(\n",
    "        pl.col(\"timestamp\").is_not_null() & pl.col(\"subject_id\").is_not_null()  # Remove invalid rows\n",
    "    )\n",
    "    .sort([\"subject_id\", \"timestamp\"], descending=False)  # Sort by subject and timestamp\n",
    "    .with_columns(\n",
    "        [\n",
    "            pl.when(pl.col(f\"is_{event.lower()}\")).then(pl.lit(1)).otherwise(pl.lit(0)).alias(f\"{event.lower()}_class\")\n",
    "            for event in event_types\n",
    "        ]\n",
    "    )\n",
    "    .groupby(\"subject_id\")\n",
    "    .agg(\n",
    "        # Calculate the class distribution per subject_id\n",
    "        *[\n",
    "            (pl.col(f\"{event.lower()}_class\").sum() / pl.col(f\"{event.lower()}_class\").count()).alias(f\"{event.lower()}_dist\")\n",
    "            for event in event_types\n",
    "        ],\n",
    "        pl.col(\"timestamp\").min().alias(\"start_time\"),\n",
    "        pl.col(\"timestamp\").max().alias(\"end_time\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Task dataframe: Select relevant columns for class distribution\n",
    "class_distribution_df_all = class_distribution_df.select([\"subject_id\", \"start_time\", \"end_time\"] + [f\"{event.lower()}_dist\" for event in event_types])\n",
    "\n",
    "\n",
    "print(class_distribution_df_all.collect())\n",
    "\n",
    "# Save the class distribution DataFrame\n",
    "class_distribution_df_all.collect().write_parquet(TASK_DF_DIR / \"task_df_ecom_cls_test.parquet\")\n",
    "print(f\"saved task_df to {TASK_DF_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be22620",
   "metadata": {},
   "source": [
    "### Classification if event sequence contains 0: only view, 1: view and cart or 2: view,cart and purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "512ea172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_727, 4)\n",
      "┌────────────┬─────────────────────┬─────────────────────┬───────┐\n",
      "│ subject_id ┆ start_time          ┆ end_time            ┆ label │\n",
      "│ ---        ┆ ---                 ┆ ---                 ┆ ---   │\n",
      "│ u16        ┆ datetime[μs]        ┆ datetime[μs]        ┆ i32   │\n",
      "╞════════════╪═════════════════════╪═════════════════════╪═══════╡\n",
      "│ 1          ┆ 2020-09-24 11:57:26 ┆ 2020-09-24 12:19:57 ┆ 0     │\n",
      "│ 8          ┆ 2020-09-24 11:58:25 ┆ 2020-09-24 12:07:26 ┆ 0     │\n",
      "│ 10         ┆ 2020-09-24 11:58:34 ┆ 2020-09-24 12:00:59 ┆ 0     │\n",
      "│ 11         ┆ 2020-09-24 11:59:26 ┆ 2020-09-24 12:02:12 ┆ 0     │\n",
      "│ …          ┆ …                   ┆ …                   ┆ …     │\n",
      "│ 5658       ┆ 2020-09-27 00:38:10 ┆ 2020-09-27 00:39:00 ┆ 0     │\n",
      "│ 5659       ┆ 2020-09-27 00:49:03 ┆ 2020-09-27 00:57:44 ┆ 0     │\n",
      "│ 5661       ┆ 2020-09-27 00:54:25 ┆ 2020-09-27 00:57:28 ┆ 1     │\n",
      "│ 5662       ┆ 2020-09-27 00:56:08 ┆ 2020-09-27 01:00:16 ┆ 0     │\n",
      "└────────────┴─────────────────────┴─────────────────────┴───────┘\n",
      "shape: (3, 1)\n",
      "┌───────────┐\n",
      "│ label     │\n",
      "│ ---       │\n",
      "│ struct[2] │\n",
      "╞═══════════╡\n",
      "│ {0,1315}  │\n",
      "│ {1,190}   │\n",
      "│ {2,222}   │\n",
      "└───────────┘\n",
      "saved task_df to /home/filip-marcus/models/ESGPT_new/EventStreamGPT/data/processed/test_ecom/task_dfs\n"
     ]
    }
   ],
   "source": [
    "# Create event data and calculate class distribution for each sequence\n",
    "class_distribution_df = (\n",
    "    events_df.with_columns(*event_flags)  # Add all event flags\n",
    "    .filter(\n",
    "        pl.col(\"timestamp\").is_not_null() & pl.col(\"subject_id\").is_not_null()  # Remove invalid rows\n",
    "    )\n",
    "    .sort([\"subject_id\", \"timestamp\"], descending=False)  # Sort by subject and timestamp\n",
    "    .with_columns(\n",
    "        [\n",
    "            pl.when(pl.col(f\"is_{event.lower()}\")).then(pl.lit(1)).otherwise(pl.lit(0)).alias(f\"{event.lower()}_class\")\n",
    "            for event in event_types\n",
    "        ]\n",
    "    )\n",
    "    .groupby(\"subject_id\")\n",
    "    .agg(\n",
    "        # Calculate the class distribution per subject_id\n",
    "        *[\n",
    "            (pl.col(f\"{event.lower()}_class\").sum() / pl.col(f\"{event.lower()}_class\").count()).alias(f\"{event.lower()}_dist\")\n",
    "            for event in event_types\n",
    "        ],\n",
    "        pl.col(\"timestamp\").min().alias(\"start_time\"),\n",
    "        pl.col(\"timestamp\").max().alias(\"end_time\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Task dataframe: Select relevant columns for class distribution\n",
    "class_distribution_df_all = class_distribution_df.select([\"subject_id\", \"start_time\", \"end_time\"] + [f\"{event.lower()}_dist\" for event in event_types])\n",
    "\n",
    "# create col with label: 1 if purchase dist > 0, 0 otherwise\n",
    "class_distribution_df_all = class_distribution_df_all.with_columns(\n",
    "    pl.when(pl.col(\"view_dist\") == 1.0)\n",
    "    .then(pl.lit(0))\n",
    "    .when(pl.col(\"purchase_dist\") > 0.0)\n",
    "    .then(pl.lit(2))\n",
    "    .otherwise(pl.lit(1))\n",
    "    .alias(\"label\")\n",
    ")\n",
    "\n",
    "class_distribution_df_all = class_distribution_df_all.drop([\"view_dist\", \"cart_dist\", \"purchase_dist\"])\n",
    "print(class_distribution_df_all.collect())\n",
    "\n",
    "label_counts = class_distribution_df_all.select(pl.col(\"label\").value_counts())\n",
    "\n",
    "print(label_counts.collect())  # Print the count of each label\n",
    "\n",
    "# Save the class distribution DataFrame\n",
    "class_distribution_df_all.collect().write_parquet(TASK_DF_DIR / \"task_df_ecom_cls_purchase.parquet\")\n",
    "print(f\"saved task_df to {TASK_DF_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f6b938",
   "metadata": {},
   "source": [
    "#### Masked random event impute 'event_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e22c86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col(\"event_type\").sample_n()\n",
      "shape: (1_727, 4)\n",
      "┌────────────┬─────────────────────┬─────────────────────┬───────────────────┐\n",
      "│ subject_id ┆ start_time          ┆ end_time            ┆ masked_event_type │\n",
      "│ ---        ┆ ---                 ┆ ---                 ┆ ---               │\n",
      "│ u16        ┆ datetime[μs]        ┆ datetime[μs]        ┆ cat               │\n",
      "╞════════════╪═════════════════════╪═════════════════════╪═══════════════════╡\n",
      "│ 1          ┆ 2020-09-24 11:57:26 ┆ 2020-09-24 12:19:57 ┆ view              │\n",
      "│ 8          ┆ 2020-09-24 11:58:25 ┆ 2020-09-24 12:07:26 ┆ view              │\n",
      "│ 10         ┆ 2020-09-24 11:58:34 ┆ 2020-09-24 12:00:59 ┆ view              │\n",
      "│ 11         ┆ 2020-09-24 11:59:26 ┆ 2020-09-24 12:02:12 ┆ view              │\n",
      "│ …          ┆ …                   ┆ …                   ┆ …                 │\n",
      "│ 5658       ┆ 2020-09-27 00:38:10 ┆ 2020-09-27 00:39:00 ┆ view              │\n",
      "│ 5659       ┆ 2020-09-27 00:49:03 ┆ 2020-09-27 00:57:44 ┆ view              │\n",
      "│ 5661       ┆ 2020-09-27 00:54:25 ┆ 2020-09-27 00:57:28 ┆ cart              │\n",
      "│ 5662       ┆ 2020-09-27 00:56:08 ┆ 2020-09-27 01:00:16 ┆ view              │\n",
      "└────────────┴─────────────────────┴─────────────────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(pl.col(\"event_type\").sample(1))\n",
    "# Create event data and calculate class distribution for each sequence\n",
    "masked_event_type_df = (\n",
    "    events_df.with_columns(*event_flags)  # Add all event flags\n",
    "    .filter(\n",
    "        pl.col(\"timestamp\").is_not_null() & pl.col(\"subject_id\").is_not_null()  # Remove invalid rows\n",
    "    )\n",
    "    .sort([\"subject_id\", \"timestamp\"], descending=False)  # Sort by subject and timestamp\n",
    "    .with_columns(\n",
    "        [\n",
    "            pl.when(pl.col(f\"is_{event.lower()}\")).then(pl.lit(1)).otherwise(pl.lit(0)).alias(f\"{event.lower()}_class\")\n",
    "            for event in event_types\n",
    "        ]\n",
    "    )\n",
    "    .groupby(\"subject_id\")\n",
    "    .agg(\n",
    "        # Calculate the class distribution per subject_id\n",
    "        *[\n",
    "            # pl.col(\"event_id\").sample(1),\n",
    "            pl.col(\"event_type\").sample(1).first().alias(\"masked_event_type\"),\n",
    "        ],\n",
    "        pl.col(\"timestamp\").min().alias(\"start_time\"),\n",
    "        pl.col(\"timestamp\").max().alias(\"end_time\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Task dataframe: Select relevant columns for class distribution\n",
    "masked_event_type_df_all = masked_event_type_df.select([\"subject_id\", \"start_time\", \"end_time\", \"masked_event_type\"] )\n",
    "\n",
    "\n",
    "print(masked_event_type_df_all.collect())\n",
    "\n",
    "# Save the class distribution DataFrame\n",
    "# masked_event_type_df_all.collect().write_parquet(TASK_DF_DIR / \"task_df_ecom_masked_event_type.parquet\")\n",
    "# print(f\"saved task_df to {TASK_DF_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1fa8c",
   "metadata": {},
   "source": [
    "### Eneryield TTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d060ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading events from /home/filip-marcus/models/ESGPT_new/EventStreamGPT/data/processed/eneryield_combined/events_df.parquet...\n",
      "shape: (332_042, 4)\n",
      "┌──────────┬────────────┬─────────────────────┬─────────────┐\n",
      "│ event_id ┆ subject_id ┆ timestamp           ┆ event_type  │\n",
      "│ ---      ┆ ---        ┆ ---                 ┆ ---         │\n",
      "│ u32      ┆ u16        ┆ datetime[μs]        ┆ cat         │\n",
      "╞══════════╪════════════╪═════════════════════╪═════════════╡\n",
      "│ 5        ┆ 2          ┆ 2025-01-24 07:07:57 ┆ disturbance │\n",
      "│ 6        ┆ 2          ┆ 2025-01-24 12:54:08 ┆ disturbance │\n",
      "│ 22       ┆ 5          ┆ 2025-01-21 22:24:30 ┆ disturbance │\n",
      "│ 31       ┆ 5          ┆ 2025-01-24 12:54:08 ┆ disturbance │\n",
      "│ …        ┆ …          ┆ …                   ┆ …           │\n",
      "│ 332039   ┆ 1406       ┆ 2020-10-06 12:11:11 ┆ disturbance │\n",
      "│ 332046   ┆ 1406       ┆ 2020-10-08 07:51:45 ┆ disturbance │\n",
      "│ 332049   ┆ 1407       ┆ 2020-10-06 12:11:02 ┆ disturbance │\n",
      "│ 332054   ┆ 1407       ┆ 2020-10-07 00:52:12 ┆ disturbance │\n",
      "└──────────┴────────────┴─────────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "COHORT_NAME = \"eneryield_combined\"\n",
    "PROJECT_DIR = Path('/home/filip-marcus/models/ESGPT_new/EventStreamGPT')\n",
    "DATA_DIR = PROJECT_DIR / \"data/processed\" / COHORT_NAME\n",
    "assert DATA_DIR.is_dir()\n",
    "\n",
    "TASK_DF_DIR = DATA_DIR / \"task_dfs\"\n",
    "TASK_DF_DIR.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "ESD = Dataset.load(DATA_DIR)\n",
    "\n",
    "events_df = ESD.events_df.lazy()\n",
    "print(events_df.collect().unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c200c0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_388, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subject_id</th><th>start_time</th><th>end_time</th><th>label</th></tr><tr><td>u16</td><td>datetime[μs]</td><td>datetime[μs]</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>81.0</td></tr><tr><td>1</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>81.0</td></tr><tr><td>2</td><td>2025-01-24 07:02:57</td><td>2025-01-24 12:54:08</td><td>20771.0</td></tr><tr><td>3</td><td>2025-01-23 23:10:07</td><td>2025-01-24 12:54:08</td><td>20771.0</td></tr><tr><td>4</td><td>2025-01-22 06:21:20</td><td>2025-01-24 12:54:08</td><td>20771.0</td></tr><tr><td>5</td><td>2025-01-21 09:58:36</td><td>2025-01-24 12:54:08</td><td>20771.0</td></tr><tr><td>6</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>20771.0</td></tr><tr><td>7</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>20771.0</td></tr><tr><td>8</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>20771.0</td></tr><tr><td>9</td><td>2025-01-20 04:26:17</td><td>2025-01-23 23:56:01</td><td>2754.0</td></tr><tr><td>10</td><td>2025-01-20 04:26:17</td><td>2025-01-22 22:58:42</td><td>59799.0</td></tr><tr><td>11</td><td>2025-01-15 12:31:54</td><td>2025-01-21 23:03:28</td><td>2338.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1397</td><td>2020-10-11 11:32:57</td><td>2020-10-17 23:31:09</td><td>8.0</td></tr><tr><td>1398</td><td>2020-10-10 06:32:23</td><td>2020-10-16 14:37:09</td><td>8.0</td></tr><tr><td>1399</td><td>2020-10-09 10:28:31</td><td>2020-10-15 14:33:27</td><td>5.0</td></tr><tr><td>1400</td><td>2020-10-08 07:48:21</td><td>2020-10-14 16:20:46</td><td>3.0</td></tr><tr><td>1401</td><td>2020-10-07 00:52:12</td><td>2020-10-13 14:55:12</td><td>4724.0</td></tr><tr><td>1402</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td><td>23026.0</td></tr><tr><td>1403</td><td>2020-10-06 12:11:01</td><td>2020-10-11 13:53:19</td><td>11.0</td></tr><tr><td>1404</td><td>2020-10-06 12:11:01</td><td>2020-10-10 13:16:56</td><td>20.0</td></tr><tr><td>1405</td><td>2020-10-06 12:11:01</td><td>2020-10-09 17:50:47</td><td>15438.0</td></tr><tr><td>1406</td><td>2020-10-06 12:11:01</td><td>2020-10-08 08:09:50</td><td>1085.0</td></tr><tr><td>1407</td><td>2020-10-06 12:11:01</td><td>2020-10-07 05:41:14</td><td>10439.0</td></tr><tr><td>1408</td><td>2020-10-06 12:11:01</td><td>2020-10-06 13:18:33</td><td>2629.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_388, 4)\n",
       "┌────────────┬─────────────────────┬─────────────────────┬─────────┐\n",
       "│ subject_id ┆ start_time          ┆ end_time            ┆ label   │\n",
       "│ ---        ┆ ---                 ┆ ---                 ┆ ---     │\n",
       "│ u16        ┆ datetime[μs]        ┆ datetime[μs]        ┆ f64     │\n",
       "╞════════════╪═════════════════════╪═════════════════════╪═════════╡\n",
       "│ 0          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ 81.0    │\n",
       "│ 1          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ 81.0    │\n",
       "│ 2          ┆ 2025-01-24 07:02:57 ┆ 2025-01-24 12:54:08 ┆ 20771.0 │\n",
       "│ 3          ┆ 2025-01-23 23:10:07 ┆ 2025-01-24 12:54:08 ┆ 20771.0 │\n",
       "│ …          ┆ …                   ┆ …                   ┆ …       │\n",
       "│ 1405       ┆ 2020-10-06 12:11:01 ┆ 2020-10-09 17:50:47 ┆ 15438.0 │\n",
       "│ 1406       ┆ 2020-10-06 12:11:01 ┆ 2020-10-08 08:09:50 ┆ 1085.0  │\n",
       "│ 1407       ┆ 2020-10-06 12:11:01 ┆ 2020-10-07 05:41:14 ┆ 10439.0 │\n",
       "│ 1408       ┆ 2020-10-06 12:11:01 ┆ 2020-10-06 13:18:33 ┆ 2629.0  │\n",
       "└────────────┴─────────────────────┴─────────────────────┴─────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tte_df = (\n",
    "    events_df.filter(\n",
    "        pl.col(\"timestamp\").is_not_null() & pl.col(\"subject_id\").is_not_null()  # Remove invalid rows\n",
    "    )\n",
    "    .sort([\"subject_id\", \"timestamp\"], descending=False)  # Sort by subject and timestamp\n",
    "    .with_columns(\n",
    "        pl.col(\"timestamp\").shift(-1).over(\"subject_id\").alias(\"next_event_time\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Calculate the time difference and convert it to seconds using .seconds()\n",
    "        (pl.col(\"next_event_time\") - pl.col(\"timestamp\")).dt.seconds().alias(\"label\")  # Duration in seconds\n",
    "    )\n",
    "    .groupby(\"subject_id\")\n",
    "    .agg(\n",
    "        pl.col(\"timestamp\").min().alias(\"start_time\"),\n",
    "        pl.col(\"timestamp\").max().alias(\"end_time\"),\n",
    "        # Apply the function to get the second-to-last label value in seconds\n",
    "        pl.col(\"label\").apply(lambda x: x[-2] if len(x) >= 2 else None)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# tte_df = tte_df.with_columns(pl.lit(1).alias(\"label\"))\n",
    "tte_df = tte_df.with_columns(pl.col(\"label\").cast(pl.Float64))\n",
    "\n",
    "tte_df.collect()\n",
    "# print(tte_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3349c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved task_df to /home/filip-marcus/models/ESGPT_new/EventStreamGPT/data/processed/eneryield_combined/task_dfs\n"
     ]
    }
   ],
   "source": [
    "# Save the task_df\n",
    "  \n",
    "tte_df.collect().write_parquet(TASK_DF_DIR / \"task_df_eneryield_tte.parquet\")\n",
    "print(f\"saved task_df to {TASK_DF_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd201e",
   "metadata": {},
   "source": [
    "### Eneryield classification if interruption in this event sequence (subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a142cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading events from /home/filip-marcus/models/ESGPT_new/EventStreamGPT/data/processed/eneryield_event_type/events_df.parquet...\n",
      "shape: (330_052, 4)\n",
      "┌──────────┬────────────┬─────────────────────┬─────────────┐\n",
      "│ event_id ┆ subject_id ┆ timestamp           ┆ event_type  │\n",
      "│ ---      ┆ ---        ┆ ---                 ┆ ---         │\n",
      "│ u32      ┆ u16        ┆ datetime[μs]        ┆ cat         │\n",
      "╞══════════╪════════════╪═════════════════════╪═════════════╡\n",
      "│ 5        ┆ 3          ┆ 2025-01-24 07:07:57 ┆ unbalance_i │\n",
      "│ 14       ┆ 5          ┆ 2025-01-23 23:10:07 ┆ unbalance_i │\n",
      "│ 19       ┆ 6          ┆ 2025-01-21 09:58:36 ┆ unbalance_i │\n",
      "│ 23       ┆ 6          ┆ 2025-01-22 06:22:03 ┆ transient   │\n",
      "│ …        ┆ …          ┆ …                   ┆ …           │\n",
      "│ 330014   ┆ 1408       ┆ 2020-10-07 00:52:12 ┆ unbalance_u │\n",
      "│ 330022   ┆ 1408       ┆ 2020-10-09 17:50:47 ┆ VD          │\n",
      "│ 330029   ┆ 1408       ┆ 2020-10-11 11:32:57 ┆ unbalance_u │\n",
      "│ 330034   ┆ 1408       ┆ 2020-10-11 11:43:45 ┆ unbalance_u │\n",
      "└──────────┴────────────┴─────────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "COHORT_NAME = \"eneryield_event_type\"\n",
    "PROJECT_DIR = Path('/home/filip-marcus/models/ESGPT_new/EventStreamGPT')\n",
    "DATA_DIR = PROJECT_DIR / \"data/processed\" / COHORT_NAME\n",
    "assert DATA_DIR.is_dir()\n",
    "\n",
    "TASK_DF_DIR = DATA_DIR / \"task_dfs\"\n",
    "TASK_DF_DIR.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "ESD = Dataset.load(DATA_DIR)\n",
    "\n",
    "events_df = ESD.events_df.lazy()\n",
    "print(events_df.collect().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fe20a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (109,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th></tr><tr><td>datetime[μs]</td></tr></thead><tbody><tr><td>2020-10-06 12:11:01</td></tr><tr><td>2020-10-30 21:57:02</td></tr><tr><td>2020-10-31 06:35:06</td></tr><tr><td>2020-10-31 06:38:25</td></tr><tr><td>2020-10-31 06:38:27</td></tr><tr><td>2020-11-02 11:36:27</td></tr><tr><td>2020-11-05 07:45:38</td></tr><tr><td>2020-11-05 07:47:01</td></tr><tr><td>2020-11-07 06:14:26</td></tr><tr><td>2020-11-07 06:14:28</td></tr><tr><td>2020-11-26 00:59:42</td></tr><tr><td>2021-02-21 15:49:35</td></tr><tr><td>&hellip;</td></tr><tr><td>2024-10-10 06:07:58</td></tr><tr><td>2024-10-10 13:11:26</td></tr><tr><td>2024-10-17 13:18:42</td></tr><tr><td>2024-10-23 11:50:09</td></tr><tr><td>2024-10-26 12:44:31</td></tr><tr><td>2024-11-12 09:18:51</td></tr><tr><td>2024-12-14 18:14:49</td></tr><tr><td>2024-12-14 18:51:34</td></tr><tr><td>2024-12-14 19:24:22</td></tr><tr><td>2024-12-14 19:26:15</td></tr><tr><td>2024-12-14 20:33:18</td></tr><tr><td>2024-12-14 22:13:54</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (109,)\n",
       "Series: '' [datetime[μs]]\n",
       "[\n",
       "\t2020-10-06 12:11:01\n",
       "\t2020-10-30 21:57:02\n",
       "\t2020-10-31 06:35:06\n",
       "\t2020-10-31 06:38:25\n",
       "\t2020-10-31 06:38:27\n",
       "\t2020-11-02 11:36:27\n",
       "\t2020-11-05 07:45:38\n",
       "\t2020-11-05 07:47:01\n",
       "\t2020-11-07 06:14:26\n",
       "\t2020-11-07 06:14:28\n",
       "\t2020-11-26 00:59:42\n",
       "\t2021-02-21 15:49:35\n",
       "\t…\n",
       "\t2024-10-08 01:34:00\n",
       "\t2024-10-10 06:07:58\n",
       "\t2024-10-10 13:11:26\n",
       "\t2024-10-17 13:18:42\n",
       "\t2024-10-23 11:50:09\n",
       "\t2024-10-26 12:44:31\n",
       "\t2024-11-12 09:18:51\n",
       "\t2024-12-14 18:14:49\n",
       "\t2024-12-14 18:51:34\n",
       "\t2024-12-14 19:24:22\n",
       "\t2024-12-14 19:26:15\n",
       "\t2024-12-14 20:33:18\n",
       "\t2024-12-14 22:13:54\n",
       "]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "datetime_list = [datetime.datetime(2020, 10, 6, 12, 11, 1), datetime.datetime(2020, 10, 30, 21, 57, 2), datetime.datetime(2020, 10, 31, 6, 35, 6), datetime.datetime(2020, 10, 31, 6, 38, 25), datetime.datetime(2020, 10, 31, 6, 38, 27), datetime.datetime(2020, 11, 2, 11, 36, 27), datetime.datetime(2020, 11, 5, 7, 45, 38), datetime.datetime(2020, 11, 5, 7, 47, 1), datetime.datetime(2020, 11, 7, 6, 14, 26), datetime.datetime(2020, 11, 7, 6, 14, 28), datetime.datetime(2020, 11, 26, 0, 59, 42), datetime.datetime(2021, 2, 21, 15, 49, 35), datetime.datetime(2021, 2, 21, 15, 58, 37), datetime.datetime(2021, 2, 21, 17, 36, 55), datetime.datetime(2021, 4, 24, 11, 34, 32), datetime.datetime(2021, 4, 24, 11, 35, 11), datetime.datetime(2021, 4, 24, 11, 38, 3), datetime.datetime(2021, 6, 22, 6, 2, 46), datetime.datetime(2021, 7, 30, 14, 57, 4), datetime.datetime(2021, 8, 14, 23, 44, 48), datetime.datetime(2021, 8, 16, 14, 37, 50), datetime.datetime(2021, 8, 29, 4, 18, 58), datetime.datetime(2021, 9, 29, 15, 51, 30), datetime.datetime(2021, 10, 14, 7, 24, 32), datetime.datetime(2021, 10, 26, 15, 11, 54), datetime.datetime(2021, 11, 19, 14, 18, 36), datetime.datetime(2022, 1, 5, 16, 54, 11), datetime.datetime(2022, 4, 13, 14, 44, 56), datetime.datetime(2022, 4, 19, 21, 28, 43), datetime.datetime(2022, 4, 20, 7, 34, 35), datetime.datetime(2022, 4, 21, 20, 31, 51), datetime.datetime(2022, 4, 22, 8, 1, 8), datetime.datetime(2022, 5, 2, 7, 40, 14), datetime.datetime(2022, 6, 9, 7, 10, 32), datetime.datetime(2022, 6, 9, 8, 38, 40), datetime.datetime(2022, 6, 9, 8, 39, 4), datetime.datetime(2022, 6, 28, 18, 58, 20), datetime.datetime(2022, 6, 28, 19, 51, 3), datetime.datetime(2022, 6, 28, 19, 55, 18), datetime.datetime(2022, 6, 28, 19, 56, 24), datetime.datetime(2022, 7, 13, 8, 28, 59), datetime.datetime(2022, 10, 13, 15, 51, 31), datetime.datetime(2022, 10, 31, 14, 23, 32), datetime.datetime(2022, 11, 3, 14, 54, 27), datetime.datetime(2022, 11, 7, 14, 54, 31), datetime.datetime(2023, 2, 19, 6, 26, 30), datetime.datetime(2023, 2, 19, 6, 59, 36), datetime.datetime(2023, 2, 19, 7, 0, 58), datetime.datetime(2023, 3, 23, 22, 29, 9), datetime.datetime(2023, 4, 13, 0, 12, 5), datetime.datetime(2023, 4, 13, 16, 42, 11), datetime.datetime(2023, 4, 15, 4, 44, 44), datetime.datetime(2023, 4, 15, 11, 36, 7), datetime.datetime(2023, 4, 16, 19, 39, 34), datetime.datetime(2023, 4, 29, 10, 31, 50), datetime.datetime(2023, 4, 30, 11, 39, 50), datetime.datetime(2023, 8, 6, 21, 41, 59), datetime.datetime(2023, 8, 8, 5, 50, 18), datetime.datetime(2023, 8, 8, 5, 52, 4), datetime.datetime(2023, 8, 8, 5, 58, 16), datetime.datetime(2023, 8, 8, 8, 40, 21), datetime.datetime(2023, 8, 8, 8, 57, 39), datetime.datetime(2023, 8, 8, 10, 50, 18), datetime.datetime(2023, 8, 8, 11, 30, 10), datetime.datetime(2023, 8, 15, 22, 8, 48), datetime.datetime(2023, 8, 22, 1, 24, 10), datetime.datetime(2023, 10, 7, 5, 44, 52), datetime.datetime(2023, 11, 26, 16, 44, 7), datetime.datetime(2023, 11, 27, 22, 11, 17), datetime.datetime(2023, 11, 27, 22, 12, 37), datetime.datetime(2023, 11, 27, 22, 16, 47), datetime.datetime(2023, 12, 3, 20, 34, 7), datetime.datetime(2023, 12, 3, 23, 20, 33), datetime.datetime(2023, 12, 3, 23, 22, 30), datetime.datetime(2023, 12, 3, 23, 33, 27), datetime.datetime(2023, 12, 13, 12, 11, 17), datetime.datetime(2023, 12, 13, 14, 32, 45), datetime.datetime(2023, 12, 13, 14, 35, 22), datetime.datetime(2023, 12, 16, 6, 49, 4), datetime.datetime(2023, 12, 22, 12, 16, 50), datetime.datetime(2023, 12, 22, 12, 18, 54), datetime.datetime(2023, 12, 22, 13, 32, 20), datetime.datetime(2024, 1, 7, 22, 42, 23), datetime.datetime(2024, 1, 7, 22, 43, 14), datetime.datetime(2024, 1, 7, 22, 51, 6), datetime.datetime(2024, 4, 2, 17, 27, 33), datetime.datetime(2024, 4, 5, 17, 17, 48), datetime.datetime(2024, 4, 9, 15, 45, 42), datetime.datetime(2024, 4, 16, 3, 5, 16), datetime.datetime(2024, 5, 2, 2, 37, 46), datetime.datetime(2024, 7, 23, 21, 33, 35), datetime.datetime(2024, 7, 23, 21, 35, 42), datetime.datetime(2024, 8, 30, 5, 51, 19), datetime.datetime(2024, 8, 30, 5, 53, 17), datetime.datetime(2024, 8, 30, 5, 55, 14), datetime.datetime(2024, 8, 31, 11, 27, 51), datetime.datetime(2024, 10, 8, 1, 34), datetime.datetime(2024, 10, 10, 6, 7, 58), datetime.datetime(2024, 10, 10, 13, 11, 26), datetime.datetime(2024, 10, 17, 13, 18, 42), datetime.datetime(2024, 10, 23, 11, 50, 9), datetime.datetime(2024, 10, 26, 12, 44, 31), datetime.datetime(2024, 11, 12, 9, 18, 51), datetime.datetime(2024, 12, 14, 18, 14, 49), datetime.datetime(2024, 12, 14, 18, 51, 34), datetime.datetime(2024, 12, 14, 19, 24, 22), datetime.datetime(2024, 12, 14, 19, 26, 15), datetime.datetime(2024, 12, 14, 20, 33, 18), datetime.datetime(2024, 12, 14, 22, 13, 54)]\n",
    "\n",
    "timestamp_series = pl.Series(datetime_list, dtype=pl.Datetime(time_unit=\"us\"))\n",
    "timestamp_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb1737f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (330_052, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subject_id</th><th>label</th><th>start_time</th><th>end_time</th></tr><tr><td>u16</td><td>f64</td><td>datetime[μs]</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>0</td><td>null</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td></tr><tr><td>0</td><td>null</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td></tr><tr><td>1</td><td>null</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td></tr><tr><td>1</td><td>null</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td></tr><tr><td>3</td><td>null</td><td>2025-01-24 07:02:57</td><td>2025-01-24 12:54:08</td></tr><tr><td>3</td><td>null</td><td>2025-01-24 07:02:57</td><td>2025-01-24 12:54:08</td></tr><tr><td>3</td><td>null</td><td>2025-01-24 07:02:57</td><td>2025-01-24 12:54:08</td></tr><tr><td>4</td><td>null</td><td>2025-01-23 23:10:07</td><td>2025-01-24 12:54:08</td></tr><tr><td>4</td><td>null</td><td>2025-01-23 23:10:07</td><td>2025-01-24 12:54:08</td></tr><tr><td>4</td><td>null</td><td>2025-01-23 23:10:07</td><td>2025-01-24 12:54:08</td></tr><tr><td>4</td><td>null</td><td>2025-01-23 23:10:07</td><td>2025-01-24 12:54:08</td></tr><tr><td>4</td><td>null</td><td>2025-01-23 23:10:07</td><td>2025-01-24 12:54:08</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1408</td><td>27843.916667</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr><tr><td>1408</td><td>27843.9</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr><tr><td>1408</td><td>27843.716667</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr><tr><td>1408</td><td>26878.75</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr><tr><td>1408</td><td>26874.65</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr><tr><td>1408</td><td>26866.366667</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr><tr><td>1408</td><td>26858.166667</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr><tr><td>1408</td><td>26843.7</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr><tr><td>1408</td><td>26692.583333</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr><tr><td>1408</td><td>26571.616667</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr><tr><td>1408</td><td>26452.633333</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr><tr><td>1408</td><td>26068.866667</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (330_052, 4)\n",
       "┌────────────┬──────────────┬─────────────────────┬─────────────────────┐\n",
       "│ subject_id ┆ label        ┆ start_time          ┆ end_time            │\n",
       "│ ---        ┆ ---          ┆ ---                 ┆ ---                 │\n",
       "│ u16        ┆ f64          ┆ datetime[μs]        ┆ datetime[μs]        │\n",
       "╞════════════╪══════════════╪═════════════════════╪═════════════════════╡\n",
       "│ 0          ┆ null         ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 │\n",
       "│ 0          ┆ null         ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 │\n",
       "│ 1          ┆ null         ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 │\n",
       "│ 1          ┆ null         ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 │\n",
       "│ …          ┆ …            ┆ …                   ┆ …                   │\n",
       "│ 1408       ┆ 26692.583333 ┆ 2020-10-06 12:11:01 ┆ 2020-10-12 19:28:10 │\n",
       "│ 1408       ┆ 26571.616667 ┆ 2020-10-06 12:11:01 ┆ 2020-10-12 19:28:10 │\n",
       "│ 1408       ┆ 26452.633333 ┆ 2020-10-06 12:11:01 ┆ 2020-10-12 19:28:10 │\n",
       "│ 1408       ┆ 26068.866667 ┆ 2020-10-06 12:11:01 ┆ 2020-10-12 19:28:10 │\n",
       "└────────────┴──────────────┴─────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interruption_df = pl.DataFrame({\"timestamp\": datetime_list})\n",
    "\n",
    "# Function to calculate the time difference to the next interruption in minutes\n",
    "def calculate_time_to_next_interruption(event_timestamp, interruption_df):\n",
    "    # Find the first interruption that occurs after the current event timestamp\n",
    "    future_interruption = interruption_df.filter(pl.col(\"timestamp\") > event_timestamp)\n",
    "    if future_interruption.height > 0:  # If there are interruptions after the event timestamp\n",
    "        next_interruption = future_interruption[0, \"timestamp\"]  # Get the next interruption timestamp\n",
    "        time_diff = next_interruption - event_timestamp  # Calculate the time difference\n",
    "        return time_diff.total_seconds() / 60  # Return the time difference in minutes\n",
    "    else:\n",
    "        return None  # If no interruption is found, return None\n",
    "\n",
    "# Now, assuming `events_df` contains your event data, here's how we modify it:\n",
    "tte_df = (\n",
    "    events_df.filter(\n",
    "        pl.col(\"timestamp\").is_not_null() & pl.col(\"subject_id\").is_not_null()  # Remove invalid rows\n",
    "    )\n",
    "    .sort([\"subject_id\", \"timestamp\"], descending=False)  # Sort by subject and timestamp\n",
    "    .with_columns(\n",
    "        pl.col(\"timestamp\").apply(\n",
    "            lambda x: calculate_time_to_next_interruption(x, interruption_df) if x else None\n",
    "        ).alias(\"label\")  # This will be the time to next interruption in minutes\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"timestamp\").min().over(\"subject_id\").alias(\"start_time\"),  # Get the minimum timestamp for the subject\n",
    "        pl.col(\"timestamp\").max().over(\"subject_id\").alias(\"end_time\")     # Get the maximum timestamp for the subject\n",
    "    )\n",
    "    .drop([\"timestamp\", \"event_id\", \"event_type\"])  # Drop the 'timestamp', 'event_id', and 'event_type' columns\n",
    ")\n",
    "\n",
    "tte_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0308535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved task_df to /home/filip-marcus/models/ESGPT_new/EventStreamGPT/data/processed/eneryield_event_type/task_dfs\n"
     ]
    }
   ],
   "source": [
    "interruption_df.write_parquet(TASK_DF_DIR / \"task_df_eneryield_interruption_cls.parquet\")\n",
    "print(f\"saved task_df to {TASK_DF_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbadd4a",
   "metadata": {},
   "source": [
    "### Eneryield task df: binary classification if interruption is in the week after end_time, for each event sequence (subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "516e130e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading events from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield_event_type/events_df.parquet...\n",
      "shape: (330_052, 4)\n",
      "┌──────────┬────────────┬─────────────────────┬─────────────┐\n",
      "│ event_id ┆ subject_id ┆ timestamp           ┆ event_type  │\n",
      "│ ---      ┆ ---        ┆ ---                 ┆ ---         │\n",
      "│ u32      ┆ u16        ┆ datetime[μs]        ┆ cat         │\n",
      "╞══════════╪════════════╪═════════════════════╪═════════════╡\n",
      "│ 5        ┆ 3          ┆ 2025-01-24 07:07:57 ┆ unbalance_i │\n",
      "│ 14       ┆ 5          ┆ 2025-01-23 23:10:07 ┆ unbalance_i │\n",
      "│ 19       ┆ 6          ┆ 2025-01-21 09:58:36 ┆ unbalance_i │\n",
      "│ 23       ┆ 6          ┆ 2025-01-22 06:22:03 ┆ transient   │\n",
      "│ …        ┆ …          ┆ …                   ┆ …           │\n",
      "│ 330014   ┆ 1408       ┆ 2020-10-07 00:52:12 ┆ unbalance_u │\n",
      "│ 330022   ┆ 1408       ┆ 2020-10-09 17:50:47 ┆ VD          │\n",
      "│ 330029   ┆ 1408       ┆ 2020-10-11 11:32:57 ┆ unbalance_u │\n",
      "│ 330034   ┆ 1408       ┆ 2020-10-11 11:43:45 ┆ unbalance_u │\n",
      "└──────────┴────────────┴─────────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "COHORT_NAME = \"eneryield_event_type\"\n",
    "PROJECT_DIR = Path('/home/filip-marcus/ESGPT_new/EventStreamGPT')\n",
    "DATA_DIR = PROJECT_DIR / \"data/processed\" / COHORT_NAME\n",
    "assert DATA_DIR.is_dir()\n",
    "\n",
    "TASK_DF_DIR = DATA_DIR / \"task_dfs\"\n",
    "TASK_DF_DIR.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "ESD = Dataset.load(DATA_DIR)\n",
    "\n",
    "events_df = ESD.events_df.lazy()\n",
    "print(events_df.collect().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1487988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (109,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th></tr><tr><td>datetime[μs]</td></tr></thead><tbody><tr><td>2020-10-06 12:11:01</td></tr><tr><td>2020-10-30 21:57:02</td></tr><tr><td>2020-10-31 06:35:06</td></tr><tr><td>2020-10-31 06:38:25</td></tr><tr><td>2020-10-31 06:38:27</td></tr><tr><td>2020-11-02 11:36:27</td></tr><tr><td>2020-11-05 07:45:38</td></tr><tr><td>2020-11-05 07:47:01</td></tr><tr><td>2020-11-07 06:14:26</td></tr><tr><td>2020-11-07 06:14:28</td></tr><tr><td>2020-11-26 00:59:42</td></tr><tr><td>2021-02-21 15:49:35</td></tr><tr><td>&hellip;</td></tr><tr><td>2024-10-10 06:07:58</td></tr><tr><td>2024-10-10 13:11:26</td></tr><tr><td>2024-10-17 13:18:42</td></tr><tr><td>2024-10-23 11:50:09</td></tr><tr><td>2024-10-26 12:44:31</td></tr><tr><td>2024-11-12 09:18:51</td></tr><tr><td>2024-12-14 18:14:49</td></tr><tr><td>2024-12-14 18:51:34</td></tr><tr><td>2024-12-14 19:24:22</td></tr><tr><td>2024-12-14 19:26:15</td></tr><tr><td>2024-12-14 20:33:18</td></tr><tr><td>2024-12-14 22:13:54</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (109,)\n",
       "Series: '' [datetime[μs]]\n",
       "[\n",
       "\t2020-10-06 12:11:01\n",
       "\t2020-10-30 21:57:02\n",
       "\t2020-10-31 06:35:06\n",
       "\t2020-10-31 06:38:25\n",
       "\t2020-10-31 06:38:27\n",
       "\t2020-11-02 11:36:27\n",
       "\t2020-11-05 07:45:38\n",
       "\t2020-11-05 07:47:01\n",
       "\t2020-11-07 06:14:26\n",
       "\t2020-11-07 06:14:28\n",
       "\t2020-11-26 00:59:42\n",
       "\t2021-02-21 15:49:35\n",
       "\t…\n",
       "\t2024-10-08 01:34:00\n",
       "\t2024-10-10 06:07:58\n",
       "\t2024-10-10 13:11:26\n",
       "\t2024-10-17 13:18:42\n",
       "\t2024-10-23 11:50:09\n",
       "\t2024-10-26 12:44:31\n",
       "\t2024-11-12 09:18:51\n",
       "\t2024-12-14 18:14:49\n",
       "\t2024-12-14 18:51:34\n",
       "\t2024-12-14 19:24:22\n",
       "\t2024-12-14 19:26:15\n",
       "\t2024-12-14 20:33:18\n",
       "\t2024-12-14 22:13:54\n",
       "]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "datetime_list = [datetime.datetime(2020, 10, 6, 12, 11, 1), datetime.datetime(2020, 10, 30, 21, 57, 2), datetime.datetime(2020, 10, 31, 6, 35, 6), datetime.datetime(2020, 10, 31, 6, 38, 25), datetime.datetime(2020, 10, 31, 6, 38, 27), datetime.datetime(2020, 11, 2, 11, 36, 27), datetime.datetime(2020, 11, 5, 7, 45, 38), datetime.datetime(2020, 11, 5, 7, 47, 1), datetime.datetime(2020, 11, 7, 6, 14, 26), datetime.datetime(2020, 11, 7, 6, 14, 28), datetime.datetime(2020, 11, 26, 0, 59, 42), datetime.datetime(2021, 2, 21, 15, 49, 35), datetime.datetime(2021, 2, 21, 15, 58, 37), datetime.datetime(2021, 2, 21, 17, 36, 55), datetime.datetime(2021, 4, 24, 11, 34, 32), datetime.datetime(2021, 4, 24, 11, 35, 11), datetime.datetime(2021, 4, 24, 11, 38, 3), datetime.datetime(2021, 6, 22, 6, 2, 46), datetime.datetime(2021, 7, 30, 14, 57, 4), datetime.datetime(2021, 8, 14, 23, 44, 48), datetime.datetime(2021, 8, 16, 14, 37, 50), datetime.datetime(2021, 8, 29, 4, 18, 58), datetime.datetime(2021, 9, 29, 15, 51, 30), datetime.datetime(2021, 10, 14, 7, 24, 32), datetime.datetime(2021, 10, 26, 15, 11, 54), datetime.datetime(2021, 11, 19, 14, 18, 36), datetime.datetime(2022, 1, 5, 16, 54, 11), datetime.datetime(2022, 4, 13, 14, 44, 56), datetime.datetime(2022, 4, 19, 21, 28, 43), datetime.datetime(2022, 4, 20, 7, 34, 35), datetime.datetime(2022, 4, 21, 20, 31, 51), datetime.datetime(2022, 4, 22, 8, 1, 8), datetime.datetime(2022, 5, 2, 7, 40, 14), datetime.datetime(2022, 6, 9, 7, 10, 32), datetime.datetime(2022, 6, 9, 8, 38, 40), datetime.datetime(2022, 6, 9, 8, 39, 4), datetime.datetime(2022, 6, 28, 18, 58, 20), datetime.datetime(2022, 6, 28, 19, 51, 3), datetime.datetime(2022, 6, 28, 19, 55, 18), datetime.datetime(2022, 6, 28, 19, 56, 24), datetime.datetime(2022, 7, 13, 8, 28, 59), datetime.datetime(2022, 10, 13, 15, 51, 31), datetime.datetime(2022, 10, 31, 14, 23, 32), datetime.datetime(2022, 11, 3, 14, 54, 27), datetime.datetime(2022, 11, 7, 14, 54, 31), datetime.datetime(2023, 2, 19, 6, 26, 30), datetime.datetime(2023, 2, 19, 6, 59, 36), datetime.datetime(2023, 2, 19, 7, 0, 58), datetime.datetime(2023, 3, 23, 22, 29, 9), datetime.datetime(2023, 4, 13, 0, 12, 5), datetime.datetime(2023, 4, 13, 16, 42, 11), datetime.datetime(2023, 4, 15, 4, 44, 44), datetime.datetime(2023, 4, 15, 11, 36, 7), datetime.datetime(2023, 4, 16, 19, 39, 34), datetime.datetime(2023, 4, 29, 10, 31, 50), datetime.datetime(2023, 4, 30, 11, 39, 50), datetime.datetime(2023, 8, 6, 21, 41, 59), datetime.datetime(2023, 8, 8, 5, 50, 18), datetime.datetime(2023, 8, 8, 5, 52, 4), datetime.datetime(2023, 8, 8, 5, 58, 16), datetime.datetime(2023, 8, 8, 8, 40, 21), datetime.datetime(2023, 8, 8, 8, 57, 39), datetime.datetime(2023, 8, 8, 10, 50, 18), datetime.datetime(2023, 8, 8, 11, 30, 10), datetime.datetime(2023, 8, 15, 22, 8, 48), datetime.datetime(2023, 8, 22, 1, 24, 10), datetime.datetime(2023, 10, 7, 5, 44, 52), datetime.datetime(2023, 11, 26, 16, 44, 7), datetime.datetime(2023, 11, 27, 22, 11, 17), datetime.datetime(2023, 11, 27, 22, 12, 37), datetime.datetime(2023, 11, 27, 22, 16, 47), datetime.datetime(2023, 12, 3, 20, 34, 7), datetime.datetime(2023, 12, 3, 23, 20, 33), datetime.datetime(2023, 12, 3, 23, 22, 30), datetime.datetime(2023, 12, 3, 23, 33, 27), datetime.datetime(2023, 12, 13, 12, 11, 17), datetime.datetime(2023, 12, 13, 14, 32, 45), datetime.datetime(2023, 12, 13, 14, 35, 22), datetime.datetime(2023, 12, 16, 6, 49, 4), datetime.datetime(2023, 12, 22, 12, 16, 50), datetime.datetime(2023, 12, 22, 12, 18, 54), datetime.datetime(2023, 12, 22, 13, 32, 20), datetime.datetime(2024, 1, 7, 22, 42, 23), datetime.datetime(2024, 1, 7, 22, 43, 14), datetime.datetime(2024, 1, 7, 22, 51, 6), datetime.datetime(2024, 4, 2, 17, 27, 33), datetime.datetime(2024, 4, 5, 17, 17, 48), datetime.datetime(2024, 4, 9, 15, 45, 42), datetime.datetime(2024, 4, 16, 3, 5, 16), datetime.datetime(2024, 5, 2, 2, 37, 46), datetime.datetime(2024, 7, 23, 21, 33, 35), datetime.datetime(2024, 7, 23, 21, 35, 42), datetime.datetime(2024, 8, 30, 5, 51, 19), datetime.datetime(2024, 8, 30, 5, 53, 17), datetime.datetime(2024, 8, 30, 5, 55, 14), datetime.datetime(2024, 8, 31, 11, 27, 51), datetime.datetime(2024, 10, 8, 1, 34), datetime.datetime(2024, 10, 10, 6, 7, 58), datetime.datetime(2024, 10, 10, 13, 11, 26), datetime.datetime(2024, 10, 17, 13, 18, 42), datetime.datetime(2024, 10, 23, 11, 50, 9), datetime.datetime(2024, 10, 26, 12, 44, 31), datetime.datetime(2024, 11, 12, 9, 18, 51), datetime.datetime(2024, 12, 14, 18, 14, 49), datetime.datetime(2024, 12, 14, 18, 51, 34), datetime.datetime(2024, 12, 14, 19, 24, 22), datetime.datetime(2024, 12, 14, 19, 26, 15), datetime.datetime(2024, 12, 14, 20, 33, 18), datetime.datetime(2024, 12, 14, 22, 13, 54)]\n",
    "\n",
    "timestamp_series = pl.Series(datetime_list, dtype=pl.Datetime(time_unit=\"us\"))\n",
    "timestamp_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c05a87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_395, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subject_id</th><th>start_time</th><th>end_time</th><th>label</th></tr><tr><td>u16</td><td>datetime[μs]</td><td>datetime[μs]</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>0</td></tr><tr><td>1</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>0</td></tr><tr><td>3</td><td>2025-01-24 07:02:57</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>4</td><td>2025-01-23 23:10:07</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>5</td><td>2025-01-22 06:22:03</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>6</td><td>2025-01-21 09:58:36</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>7</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>8</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>9</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>10</td><td>2025-01-20 04:26:17</td><td>2025-01-23 23:56:01</td><td>0</td></tr><tr><td>11</td><td>2025-01-20 04:26:17</td><td>2025-01-22 22:58:42</td><td>0</td></tr><tr><td>12</td><td>2025-01-15 12:31:54</td><td>2025-01-21 23:03:28</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1397</td><td>2020-10-17 05:38:55</td><td>2020-10-23 11:24:08</td><td>0</td></tr><tr><td>1398</td><td>2020-10-16 01:50:26</td><td>2020-10-22 13:35:38</td><td>0</td></tr><tr><td>1399</td><td>2020-10-15 03:41:13</td><td>2020-10-21 13:14:45</td><td>0</td></tr><tr><td>1400</td><td>2020-10-14 05:11:08</td><td>2020-10-20 13:05:13</td><td>0</td></tr><tr><td>1401</td><td>2020-10-13 03:56:13</td><td>2020-10-19 10:46:58</td><td>0</td></tr><tr><td>1402</td><td>2020-10-12 05:58:17</td><td>2020-10-18 09:43:36</td><td>0</td></tr><tr><td>1403</td><td>2020-10-11 11:32:57</td><td>2020-10-17 23:31:09</td><td>0</td></tr><tr><td>1404</td><td>2020-10-10 06:32:23</td><td>2020-10-16 14:37:09</td><td>0</td></tr><tr><td>1405</td><td>2020-10-09 10:28:31</td><td>2020-10-15 14:33:27</td><td>0</td></tr><tr><td>1406</td><td>2020-10-08 07:48:21</td><td>2020-10-14 16:20:46</td><td>0</td></tr><tr><td>1407</td><td>2020-10-07 00:52:12</td><td>2020-10-13 14:55:12</td><td>0</td></tr><tr><td>1408</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_395, 4)\n",
       "┌────────────┬─────────────────────┬─────────────────────┬───────┐\n",
       "│ subject_id ┆ start_time          ┆ end_time            ┆ label │\n",
       "│ ---        ┆ ---                 ┆ ---                 ┆ ---   │\n",
       "│ u16        ┆ datetime[μs]        ┆ datetime[μs]        ┆ i64   │\n",
       "╞════════════╪═════════════════════╪═════════════════════╪═══════╡\n",
       "│ 0          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ 0     │\n",
       "│ 1          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ 0     │\n",
       "│ 3          ┆ 2025-01-24 07:02:57 ┆ 2025-01-24 12:54:08 ┆ 0     │\n",
       "│ 4          ┆ 2025-01-23 23:10:07 ┆ 2025-01-24 12:54:08 ┆ 0     │\n",
       "│ …          ┆ …                   ┆ …                   ┆ …     │\n",
       "│ 1405       ┆ 2020-10-09 10:28:31 ┆ 2020-10-15 14:33:27 ┆ 0     │\n",
       "│ 1406       ┆ 2020-10-08 07:48:21 ┆ 2020-10-14 16:20:46 ┆ 0     │\n",
       "│ 1407       ┆ 2020-10-07 00:52:12 ┆ 2020-10-13 14:55:12 ┆ 0     │\n",
       "│ 1408       ┆ 2020-10-06 12:11:01 ┆ 2020-10-12 19:28:10 ┆ 0     │\n",
       "└────────────┴─────────────────────┴─────────────────────┴───────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "aggregated_df = (\n",
    "        events_df.filter(\n",
    "            pl.col(\"timestamp\").is_not_null() & pl.col(\"subject_id\").is_not_null()\n",
    "        )\n",
    "        .sort([\"subject_id\", \"timestamp\"], descending=False)\n",
    "        .groupby(\"subject_id\")\n",
    "        .agg(\n",
    "            pl.col(\"timestamp\").min().alias(\"start_time\"),\n",
    "            pl.col(\"timestamp\").max().alias(\"end_time\"),\n",
    "        )\n",
    "    ).collect()\n",
    "\n",
    "interruption_df = aggregated_df.with_columns(\n",
    "        pl.Series([\n",
    "            int(any(end <= ts <= end + timedelta(weeks=1) for ts in timestamp_series))\n",
    "            for end in aggregated_df[\"end_time\"].to_list()\n",
    "        ]).alias(\"label\")\n",
    "    )\n",
    "interruption_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e99bc85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_395, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subject_id</th><th>start_time</th><th>end_time</th><th>label</th></tr><tr><td>u16</td><td>datetime[μs]</td><td>datetime[μs]</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>0.0</td></tr><tr><td>1</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>0.0</td></tr><tr><td>3</td><td>2025-01-24 07:02:57</td><td>2025-01-24 12:54:08</td><td>0.0</td></tr><tr><td>4</td><td>2025-01-23 23:10:07</td><td>2025-01-24 12:54:08</td><td>0.0</td></tr><tr><td>5</td><td>2025-01-22 06:22:03</td><td>2025-01-24 12:54:08</td><td>0.0</td></tr><tr><td>6</td><td>2025-01-21 09:58:36</td><td>2025-01-24 12:54:08</td><td>0.0</td></tr><tr><td>7</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>0.0</td></tr><tr><td>8</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>0.0</td></tr><tr><td>9</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>0.0</td></tr><tr><td>10</td><td>2025-01-20 04:26:17</td><td>2025-01-23 23:56:01</td><td>0.0</td></tr><tr><td>11</td><td>2025-01-20 04:26:17</td><td>2025-01-22 22:58:42</td><td>0.0</td></tr><tr><td>12</td><td>2025-01-15 12:31:54</td><td>2025-01-21 23:03:28</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1397</td><td>2020-10-17 05:38:55</td><td>2020-10-23 11:24:08</td><td>19698.116667</td></tr><tr><td>1398</td><td>2020-10-16 01:50:26</td><td>2020-10-22 13:35:38</td><td>21366.6</td></tr><tr><td>1399</td><td>2020-10-15 03:41:13</td><td>2020-10-21 13:14:45</td><td>22695.816667</td></tr><tr><td>1400</td><td>2020-10-14 05:11:08</td><td>2020-10-20 13:05:13</td><td>24045.9</td></tr><tr><td>1401</td><td>2020-10-13 03:56:13</td><td>2020-10-19 10:46:58</td><td>25560.816667</td></tr><tr><td>1402</td><td>2020-10-12 05:58:17</td><td>2020-10-18 09:43:36</td><td>26878.75</td></tr><tr><td>1403</td><td>2020-10-11 11:32:57</td><td>2020-10-17 23:31:09</td><td>27984.083333</td></tr><tr><td>1404</td><td>2020-10-10 06:32:23</td><td>2020-10-16 14:37:09</td><td>29724.65</td></tr><tr><td>1405</td><td>2020-10-09 10:28:31</td><td>2020-10-15 14:33:27</td><td>30928.516667</td></tr><tr><td>1406</td><td>2020-10-08 07:48:21</td><td>2020-10-14 16:20:46</td><td>32528.683333</td></tr><tr><td>1407</td><td>2020-10-07 00:52:12</td><td>2020-10-13 14:55:12</td><td>34384.833333</td></tr><tr><td>1408</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td><td>35146.016667</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_395, 4)\n",
       "┌────────────┬─────────────────────┬─────────────────────┬──────────────┐\n",
       "│ subject_id ┆ start_time          ┆ end_time            ┆ label        │\n",
       "│ ---        ┆ ---                 ┆ ---                 ┆ ---          │\n",
       "│ u16        ┆ datetime[μs]        ┆ datetime[μs]        ┆ f64          │\n",
       "╞════════════╪═════════════════════╪═════════════════════╪══════════════╡\n",
       "│ 0          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ 0.0          │\n",
       "│ 1          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ 0.0          │\n",
       "│ 3          ┆ 2025-01-24 07:02:57 ┆ 2025-01-24 12:54:08 ┆ 0.0          │\n",
       "│ 4          ┆ 2025-01-23 23:10:07 ┆ 2025-01-24 12:54:08 ┆ 0.0          │\n",
       "│ …          ┆ …                   ┆ …                   ┆ …            │\n",
       "│ 1405       ┆ 2020-10-09 10:28:31 ┆ 2020-10-15 14:33:27 ┆ 30928.516667 │\n",
       "│ 1406       ┆ 2020-10-08 07:48:21 ┆ 2020-10-14 16:20:46 ┆ 32528.683333 │\n",
       "│ 1407       ┆ 2020-10-07 00:52:12 ┆ 2020-10-13 14:55:12 ┆ 34384.833333 │\n",
       "│ 1408       ┆ 2020-10-06 12:11:01 ┆ 2020-10-12 19:28:10 ┆ 35146.016667 │\n",
       "└────────────┴─────────────────────┴─────────────────────┴──────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interruption_df_copy = interruption_df\n",
    "interruption_df_copy = interruption_df_copy.with_columns(\n",
    "    pl.Series(\"label\", tti_labels)\n",
    ")\n",
    "interruption_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bf08c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "interruption_df_copy.write_parquet(TASK_DF_DIR / \"task_df_eneryield_tti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "509987ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved task_df to /home/filip-marcus/models/ESGPT_new/EventStreamGPT/data/processed/eneryield_event_type/task_dfs\n"
     ]
    }
   ],
   "source": [
    "interruption_df.write_parquet(TASK_DF_DIR / \"task_df_eneryield_interruption_cls_one_week_ahead.parquet\")\n",
    "print(f\"saved task_df to {TASK_DF_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b8c87",
   "metadata": {},
   "source": [
    "### Time-to-Interruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34577fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading events from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/synthetic_mega/events_df.parquet...\n",
      "shape: (209_601, 4)\n",
      "┌──────────┬────────────┬─────────────────────┬─────────────┐\n",
      "│ event_id ┆ subject_id ┆ timestamp           ┆ event_type  │\n",
      "│ ---      ┆ ---        ┆ ---                 ┆ ---         │\n",
      "│ u32      ┆ u16        ┆ datetime[μs]        ┆ cat         │\n",
      "╞══════════╪════════════╪═════════════════════╪═════════════╡\n",
      "│ 9        ┆ 0          ┆ 2024-12-26 16:49:41 ┆ disturbance │\n",
      "│ 10       ┆ 0          ┆ 2024-12-26 21:12:47 ┆ disturbance │\n",
      "│ 14       ┆ 0          ┆ 2024-12-27 14:45:15 ┆ disturbance │\n",
      "│ 15       ┆ 0          ┆ 2024-12-27 19:08:22 ┆ disturbance │\n",
      "│ …        ┆ …          ┆ …                   ┆ …           │\n",
      "│ 209578   ┆ 5502       ┆ 2020-01-01 12:51:21 ┆ disturbance │\n",
      "│ 209588   ┆ 5503       ┆ 2020-01-01 00:00:00 ┆ disturbance │\n",
      "│ 209591   ┆ 5503       ┆ 2020-01-01 06:44:09 ┆ disturbance │\n",
      "│ 209593   ┆ 5503       ┆ 2020-01-01 09:55:18 ┆ disturbance │\n",
      "└──────────┴────────────┴─────────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "COHORT_NAME = \"synthetic_mega\"\n",
    "PROJECT_DIR = Path('/home/filip-marcus/ESGPT_new/EventStreamGPT')\n",
    "DATA_DIR = PROJECT_DIR / \"data/processed\" / COHORT_NAME\n",
    "assert DATA_DIR.is_dir()\n",
    "\n",
    "TASK_DF_DIR = DATA_DIR / \"task_dfs\"\n",
    "TASK_DF_DIR.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "ESD = Dataset.load(DATA_DIR)\n",
    "\n",
    "events_df = ESD.events_df.lazy()\n",
    "print(events_df.collect().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10ff542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (109,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th></tr><tr><td>datetime[μs]</td></tr></thead><tbody><tr><td>2020-10-06 12:11:01</td></tr><tr><td>2020-10-30 21:57:02</td></tr><tr><td>2020-10-31 06:35:06</td></tr><tr><td>2020-10-31 06:38:25</td></tr><tr><td>2020-10-31 06:38:27</td></tr><tr><td>2020-11-02 11:36:27</td></tr><tr><td>2020-11-05 07:45:38</td></tr><tr><td>2020-11-05 07:47:01</td></tr><tr><td>2020-11-07 06:14:26</td></tr><tr><td>2020-11-07 06:14:28</td></tr><tr><td>2020-11-26 00:59:42</td></tr><tr><td>2021-02-21 15:49:35</td></tr><tr><td>&hellip;</td></tr><tr><td>2024-10-10 06:07:58</td></tr><tr><td>2024-10-10 13:11:26</td></tr><tr><td>2024-10-17 13:18:42</td></tr><tr><td>2024-10-23 11:50:09</td></tr><tr><td>2024-10-26 12:44:31</td></tr><tr><td>2024-11-12 09:18:51</td></tr><tr><td>2024-12-14 18:14:49</td></tr><tr><td>2024-12-14 18:51:34</td></tr><tr><td>2024-12-14 19:24:22</td></tr><tr><td>2024-12-14 19:26:15</td></tr><tr><td>2024-12-14 20:33:18</td></tr><tr><td>2024-12-14 22:13:54</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (109,)\n",
       "Series: '' [datetime[μs]]\n",
       "[\n",
       "\t2020-10-06 12:11:01\n",
       "\t2020-10-30 21:57:02\n",
       "\t2020-10-31 06:35:06\n",
       "\t2020-10-31 06:38:25\n",
       "\t2020-10-31 06:38:27\n",
       "\t2020-11-02 11:36:27\n",
       "\t2020-11-05 07:45:38\n",
       "\t2020-11-05 07:47:01\n",
       "\t2020-11-07 06:14:26\n",
       "\t2020-11-07 06:14:28\n",
       "\t2020-11-26 00:59:42\n",
       "\t2021-02-21 15:49:35\n",
       "\t…\n",
       "\t2024-10-08 01:34:00\n",
       "\t2024-10-10 06:07:58\n",
       "\t2024-10-10 13:11:26\n",
       "\t2024-10-17 13:18:42\n",
       "\t2024-10-23 11:50:09\n",
       "\t2024-10-26 12:44:31\n",
       "\t2024-11-12 09:18:51\n",
       "\t2024-12-14 18:14:49\n",
       "\t2024-12-14 18:51:34\n",
       "\t2024-12-14 19:24:22\n",
       "\t2024-12-14 19:26:15\n",
       "\t2024-12-14 20:33:18\n",
       "\t2024-12-14 22:13:54\n",
       "]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "datetime_list = [datetime.datetime(2020, 10, 6, 12, 11, 1), datetime.datetime(2020, 10, 30, 21, 57, 2), datetime.datetime(2020, 10, 31, 6, 35, 6), datetime.datetime(2020, 10, 31, 6, 38, 25), datetime.datetime(2020, 10, 31, 6, 38, 27), datetime.datetime(2020, 11, 2, 11, 36, 27), datetime.datetime(2020, 11, 5, 7, 45, 38), datetime.datetime(2020, 11, 5, 7, 47, 1), datetime.datetime(2020, 11, 7, 6, 14, 26), datetime.datetime(2020, 11, 7, 6, 14, 28), datetime.datetime(2020, 11, 26, 0, 59, 42), datetime.datetime(2021, 2, 21, 15, 49, 35), datetime.datetime(2021, 2, 21, 15, 58, 37), datetime.datetime(2021, 2, 21, 17, 36, 55), datetime.datetime(2021, 4, 24, 11, 34, 32), datetime.datetime(2021, 4, 24, 11, 35, 11), datetime.datetime(2021, 4, 24, 11, 38, 3), datetime.datetime(2021, 6, 22, 6, 2, 46), datetime.datetime(2021, 7, 30, 14, 57, 4), datetime.datetime(2021, 8, 14, 23, 44, 48), datetime.datetime(2021, 8, 16, 14, 37, 50), datetime.datetime(2021, 8, 29, 4, 18, 58), datetime.datetime(2021, 9, 29, 15, 51, 30), datetime.datetime(2021, 10, 14, 7, 24, 32), datetime.datetime(2021, 10, 26, 15, 11, 54), datetime.datetime(2021, 11, 19, 14, 18, 36), datetime.datetime(2022, 1, 5, 16, 54, 11), datetime.datetime(2022, 4, 13, 14, 44, 56), datetime.datetime(2022, 4, 19, 21, 28, 43), datetime.datetime(2022, 4, 20, 7, 34, 35), datetime.datetime(2022, 4, 21, 20, 31, 51), datetime.datetime(2022, 4, 22, 8, 1, 8), datetime.datetime(2022, 5, 2, 7, 40, 14), datetime.datetime(2022, 6, 9, 7, 10, 32), datetime.datetime(2022, 6, 9, 8, 38, 40), datetime.datetime(2022, 6, 9, 8, 39, 4), datetime.datetime(2022, 6, 28, 18, 58, 20), datetime.datetime(2022, 6, 28, 19, 51, 3), datetime.datetime(2022, 6, 28, 19, 55, 18), datetime.datetime(2022, 6, 28, 19, 56, 24), datetime.datetime(2022, 7, 13, 8, 28, 59), datetime.datetime(2022, 10, 13, 15, 51, 31), datetime.datetime(2022, 10, 31, 14, 23, 32), datetime.datetime(2022, 11, 3, 14, 54, 27), datetime.datetime(2022, 11, 7, 14, 54, 31), datetime.datetime(2023, 2, 19, 6, 26, 30), datetime.datetime(2023, 2, 19, 6, 59, 36), datetime.datetime(2023, 2, 19, 7, 0, 58), datetime.datetime(2023, 3, 23, 22, 29, 9), datetime.datetime(2023, 4, 13, 0, 12, 5), datetime.datetime(2023, 4, 13, 16, 42, 11), datetime.datetime(2023, 4, 15, 4, 44, 44), datetime.datetime(2023, 4, 15, 11, 36, 7), datetime.datetime(2023, 4, 16, 19, 39, 34), datetime.datetime(2023, 4, 29, 10, 31, 50), datetime.datetime(2023, 4, 30, 11, 39, 50), datetime.datetime(2023, 8, 6, 21, 41, 59), datetime.datetime(2023, 8, 8, 5, 50, 18), datetime.datetime(2023, 8, 8, 5, 52, 4), datetime.datetime(2023, 8, 8, 5, 58, 16), datetime.datetime(2023, 8, 8, 8, 40, 21), datetime.datetime(2023, 8, 8, 8, 57, 39), datetime.datetime(2023, 8, 8, 10, 50, 18), datetime.datetime(2023, 8, 8, 11, 30, 10), datetime.datetime(2023, 8, 15, 22, 8, 48), datetime.datetime(2023, 8, 22, 1, 24, 10), datetime.datetime(2023, 10, 7, 5, 44, 52), datetime.datetime(2023, 11, 26, 16, 44, 7), datetime.datetime(2023, 11, 27, 22, 11, 17), datetime.datetime(2023, 11, 27, 22, 12, 37), datetime.datetime(2023, 11, 27, 22, 16, 47), datetime.datetime(2023, 12, 3, 20, 34, 7), datetime.datetime(2023, 12, 3, 23, 20, 33), datetime.datetime(2023, 12, 3, 23, 22, 30), datetime.datetime(2023, 12, 3, 23, 33, 27), datetime.datetime(2023, 12, 13, 12, 11, 17), datetime.datetime(2023, 12, 13, 14, 32, 45), datetime.datetime(2023, 12, 13, 14, 35, 22), datetime.datetime(2023, 12, 16, 6, 49, 4), datetime.datetime(2023, 12, 22, 12, 16, 50), datetime.datetime(2023, 12, 22, 12, 18, 54), datetime.datetime(2023, 12, 22, 13, 32, 20), datetime.datetime(2024, 1, 7, 22, 42, 23), datetime.datetime(2024, 1, 7, 22, 43, 14), datetime.datetime(2024, 1, 7, 22, 51, 6), datetime.datetime(2024, 4, 2, 17, 27, 33), datetime.datetime(2024, 4, 5, 17, 17, 48), datetime.datetime(2024, 4, 9, 15, 45, 42), datetime.datetime(2024, 4, 16, 3, 5, 16), datetime.datetime(2024, 5, 2, 2, 37, 46), datetime.datetime(2024, 7, 23, 21, 33, 35), datetime.datetime(2024, 7, 23, 21, 35, 42), datetime.datetime(2024, 8, 30, 5, 51, 19), datetime.datetime(2024, 8, 30, 5, 53, 17), datetime.datetime(2024, 8, 30, 5, 55, 14), datetime.datetime(2024, 8, 31, 11, 27, 51), datetime.datetime(2024, 10, 8, 1, 34), datetime.datetime(2024, 10, 10, 6, 7, 58), datetime.datetime(2024, 10, 10, 13, 11, 26), datetime.datetime(2024, 10, 17, 13, 18, 42), datetime.datetime(2024, 10, 23, 11, 50, 9), datetime.datetime(2024, 10, 26, 12, 44, 31), datetime.datetime(2024, 11, 12, 9, 18, 51), datetime.datetime(2024, 12, 14, 18, 14, 49), datetime.datetime(2024, 12, 14, 18, 51, 34), datetime.datetime(2024, 12, 14, 19, 24, 22), datetime.datetime(2024, 12, 14, 19, 26, 15), datetime.datetime(2024, 12, 14, 20, 33, 18), datetime.datetime(2024, 12, 14, 22, 13, 54)]\n",
    " \n",
    "timestamp_series = pl.Series(datetime_list, dtype=pl.Datetime(time_unit=\"us\"))\n",
    "timestamp_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3da2f6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_395, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subject_id</th><th>start_time</th><th>end_time</th><th>label</th></tr><tr><td>u16</td><td>datetime[μs]</td><td>datetime[μs]</td><td>i32</td></tr></thead><tbody><tr><td>0</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>1</td></tr><tr><td>1</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>1</td></tr><tr><td>3</td><td>2025-01-24 07:02:57</td><td>2025-01-24 12:54:08</td><td>1</td></tr><tr><td>4</td><td>2025-01-23 23:10:07</td><td>2025-01-24 12:54:08</td><td>1</td></tr><tr><td>5</td><td>2025-01-22 06:22:03</td><td>2025-01-24 12:54:08</td><td>1</td></tr><tr><td>6</td><td>2025-01-21 09:58:36</td><td>2025-01-24 12:54:08</td><td>1</td></tr><tr><td>7</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>1</td></tr><tr><td>8</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>1</td></tr><tr><td>9</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>1</td></tr><tr><td>10</td><td>2025-01-20 04:26:17</td><td>2025-01-23 23:56:01</td><td>1</td></tr><tr><td>11</td><td>2025-01-20 04:26:17</td><td>2025-01-22 22:58:42</td><td>1</td></tr><tr><td>12</td><td>2025-01-15 12:31:54</td><td>2025-01-21 23:03:28</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1397</td><td>2020-10-17 05:38:55</td><td>2020-10-23 11:24:08</td><td>1</td></tr><tr><td>1398</td><td>2020-10-16 01:50:26</td><td>2020-10-22 13:35:38</td><td>1</td></tr><tr><td>1399</td><td>2020-10-15 03:41:13</td><td>2020-10-21 13:14:45</td><td>1</td></tr><tr><td>1400</td><td>2020-10-14 05:11:08</td><td>2020-10-20 13:05:13</td><td>1</td></tr><tr><td>1401</td><td>2020-10-13 03:56:13</td><td>2020-10-19 10:46:58</td><td>1</td></tr><tr><td>1402</td><td>2020-10-12 05:58:17</td><td>2020-10-18 09:43:36</td><td>1</td></tr><tr><td>1403</td><td>2020-10-11 11:32:57</td><td>2020-10-17 23:31:09</td><td>1</td></tr><tr><td>1404</td><td>2020-10-10 06:32:23</td><td>2020-10-16 14:37:09</td><td>1</td></tr><tr><td>1405</td><td>2020-10-09 10:28:31</td><td>2020-10-15 14:33:27</td><td>1</td></tr><tr><td>1406</td><td>2020-10-08 07:48:21</td><td>2020-10-14 16:20:46</td><td>1</td></tr><tr><td>1407</td><td>2020-10-07 00:52:12</td><td>2020-10-13 14:55:12</td><td>1</td></tr><tr><td>1408</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_395, 4)\n",
       "┌────────────┬─────────────────────┬─────────────────────┬───────┐\n",
       "│ subject_id ┆ start_time          ┆ end_time            ┆ label │\n",
       "│ ---        ┆ ---                 ┆ ---                 ┆ ---   │\n",
       "│ u16        ┆ datetime[μs]        ┆ datetime[μs]        ┆ i32   │\n",
       "╞════════════╪═════════════════════╪═════════════════════╪═══════╡\n",
       "│ 0          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ 1     │\n",
       "│ 1          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ 1     │\n",
       "│ 3          ┆ 2025-01-24 07:02:57 ┆ 2025-01-24 12:54:08 ┆ 1     │\n",
       "│ 4          ┆ 2025-01-23 23:10:07 ┆ 2025-01-24 12:54:08 ┆ 1     │\n",
       "│ …          ┆ …                   ┆ …                   ┆ …     │\n",
       "│ 1405       ┆ 2020-10-09 10:28:31 ┆ 2020-10-15 14:33:27 ┆ 1     │\n",
       "│ 1406       ┆ 2020-10-08 07:48:21 ┆ 2020-10-14 16:20:46 ┆ 1     │\n",
       "│ 1407       ┆ 2020-10-07 00:52:12 ┆ 2020-10-13 14:55:12 ┆ 1     │\n",
       "│ 1408       ┆ 2020-10-06 12:11:01 ┆ 2020-10-12 19:28:10 ┆ 1     │\n",
       "└────────────┴─────────────────────┴─────────────────────┴───────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interruption_in_seq_df = pl.read_parquet('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield_event_type/task_dfs/task_df_eneryield_interruption_cls.parquet')\n",
    "tti_df2 = interruption_in_seq_df.with_columns(pl.lit(1).alias(\"label\"))\n",
    "tti_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36c271a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_right\n",
    "\n",
    "# Ensure datetime_list is sorted.\n",
    "datetime_list.sort()\n",
    "\n",
    "# Group events_df by subject_id to get start_time (min) and end_time (max)\n",
    "subject_df = (\n",
    "    events_df\n",
    "    .groupby(\"subject_id\")\n",
    "    .agg([\n",
    "        pl.col(\"timestamp\").min().alias(\"start_time\"),\n",
    "        pl.col(\"timestamp\").max().alias(\"end_time\")\n",
    "    ])\n",
    ").collect()\n",
    "\n",
    "# Define a function that, given an end_time, computes time-to-next interruption (in minutes)\n",
    "def compute_time_to_next_interrupt(end_time):\n",
    "    # bisect_right returns the index where end_time would be inserted to keep datetime_list sorted.\n",
    "    idx = bisect_right(datetime_list, end_time)\n",
    "    if idx < len(datetime_list):\n",
    "        next_interrupt = datetime_list[idx]\n",
    "        # Compute difference in minutes\n",
    "        diff_minutes = (next_interrupt - end_time).total_seconds() / 60.0\n",
    "        return diff_minutes\n",
    "    else:\n",
    "        # Return None if no interruption occurs after end_time\n",
    "        return None\n",
    "\n",
    "# Apply the function row-wise to create the \"label\" column.\n",
    "tti_df = subject_df.with_columns(\n",
    "    pl.col(\"end_time\").apply(compute_time_to_next_interrupt).alias(\"label\")\n",
    ")\n",
    "tti_df = tti_df.sort(by=\"subject_id\")\n",
    "tti_df = tti_df.drop_nulls(subset=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09bce180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_429,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>label</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>46.05</td></tr><tr><td>1223.15</td></tr><tr><td>2538.716667</td></tr><tr><td>4117.4</td></tr><tr><td>5432.966667</td></tr><tr><td>7011.65</td></tr><tr><td>8327.233333</td></tr><tr><td>9905.916667</td></tr><tr><td>11221.483333</td></tr><tr><td>12800.166667</td></tr><tr><td>14115.75</td></tr><tr><td>15694.433333</td></tr><tr><td>&hellip;</td></tr><tr><td>385557.833333</td></tr><tr><td>386851.15</td></tr><tr><td>388374.15</td></tr><tr><td>389907.066667</td></tr><tr><td>391265.05</td></tr><tr><td>392577.783333</td></tr><tr><td>394118.516667</td></tr><tr><td>395521.4</td></tr><tr><td>397171.483333</td></tr><tr><td>398578.533333</td></tr><tr><td>400402.983333</td></tr><tr><td>401118.583333</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5_429,)\n",
       "Series: 'label' [f64]\n",
       "[\n",
       "\t46.05\n",
       "\t1223.15\n",
       "\t2538.716667\n",
       "\t4117.4\n",
       "\t5432.966667\n",
       "\t7011.65\n",
       "\t8327.233333\n",
       "\t9905.916667\n",
       "\t11221.483333\n",
       "\t12800.166667\n",
       "\t14115.75\n",
       "\t15694.433333\n",
       "\t…\n",
       "\t383942.883333\n",
       "\t385557.833333\n",
       "\t386851.15\n",
       "\t388374.15\n",
       "\t389907.066667\n",
       "\t391265.05\n",
       "\t392577.783333\n",
       "\t394118.516667\n",
       "\t395521.4\n",
       "\t397171.483333\n",
       "\t398578.533333\n",
       "\t400402.983333\n",
       "\t401118.583333\n",
       "]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tti_labels = tti_df[\"label\"]\n",
    "tti_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "957a76fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved task_df to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/synthetic_mega/task_dfs\n"
     ]
    }
   ],
   "source": [
    "# TA BORT GAMLA INNAN!!!!\n",
    "tti_df.write_parquet(TASK_DF_DIR / \"task_df_synthetic_tti.parquet\")\n",
    "print(f\"saved task_df to {TASK_DF_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74b4f3",
   "metadata": {},
   "source": [
    "### Eneryield Class dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0d09d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading events from /home/filip-marcus/models/ESGPT_new/EventStreamGPT/data/processed/eneryield_event_type/events_df.parquet...\n",
      "shape: (330_052, 4)\n",
      "┌──────────┬────────────┬─────────────────────┬─────────────┐\n",
      "│ event_id ┆ subject_id ┆ timestamp           ┆ event_type  │\n",
      "│ ---      ┆ ---        ┆ ---                 ┆ ---         │\n",
      "│ u32      ┆ u16        ┆ datetime[μs]        ┆ cat         │\n",
      "╞══════════╪════════════╪═════════════════════╪═════════════╡\n",
      "│ 5        ┆ 3          ┆ 2025-01-24 07:07:57 ┆ unbalance_i │\n",
      "│ 14       ┆ 5          ┆ 2025-01-23 23:10:07 ┆ unbalance_i │\n",
      "│ 19       ┆ 6          ┆ 2025-01-21 09:58:36 ┆ unbalance_i │\n",
      "│ 23       ┆ 6          ┆ 2025-01-22 06:22:03 ┆ transient   │\n",
      "│ …        ┆ …          ┆ …                   ┆ …           │\n",
      "│ 330014   ┆ 1408       ┆ 2020-10-07 00:52:12 ┆ unbalance_u │\n",
      "│ 330022   ┆ 1408       ┆ 2020-10-09 17:50:47 ┆ VD          │\n",
      "│ 330029   ┆ 1408       ┆ 2020-10-11 11:32:57 ┆ unbalance_u │\n",
      "│ 330034   ┆ 1408       ┆ 2020-10-11 11:43:45 ┆ unbalance_u │\n",
      "└──────────┴────────────┴─────────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "COHORT_NAME = \"eneryield_event_type\"\n",
    "PROJECT_DIR = Path('/home/filip-marcus/models/ESGPT_new/EventStreamGPT')\n",
    "DATA_DIR = PROJECT_DIR / \"data/processed\" / COHORT_NAME\n",
    "assert DATA_DIR.is_dir()\n",
    "\n",
    "TASK_DF_DIR = DATA_DIR / \"task_dfs\"\n",
    "TASK_DF_DIR.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "ESD = Dataset.load(DATA_DIR)\n",
    "\n",
    "events_df = ESD.events_df.lazy()\n",
    "print(events_df.collect().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a98973e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (109,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th></tr><tr><td>datetime[μs]</td></tr></thead><tbody><tr><td>2020-10-06 12:11:01</td></tr><tr><td>2020-10-30 21:57:02</td></tr><tr><td>2020-10-31 06:35:06</td></tr><tr><td>2020-10-31 06:38:25</td></tr><tr><td>2020-10-31 06:38:27</td></tr><tr><td>2020-11-02 11:36:27</td></tr><tr><td>2020-11-05 07:45:38</td></tr><tr><td>2020-11-05 07:47:01</td></tr><tr><td>2020-11-07 06:14:26</td></tr><tr><td>2020-11-07 06:14:28</td></tr><tr><td>2020-11-26 00:59:42</td></tr><tr><td>2021-02-21 15:49:35</td></tr><tr><td>&hellip;</td></tr><tr><td>2024-10-10 06:07:58</td></tr><tr><td>2024-10-10 13:11:26</td></tr><tr><td>2024-10-17 13:18:42</td></tr><tr><td>2024-10-23 11:50:09</td></tr><tr><td>2024-10-26 12:44:31</td></tr><tr><td>2024-11-12 09:18:51</td></tr><tr><td>2024-12-14 18:14:49</td></tr><tr><td>2024-12-14 18:51:34</td></tr><tr><td>2024-12-14 19:24:22</td></tr><tr><td>2024-12-14 19:26:15</td></tr><tr><td>2024-12-14 20:33:18</td></tr><tr><td>2024-12-14 22:13:54</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (109,)\n",
       "Series: '' [datetime[μs]]\n",
       "[\n",
       "\t2020-10-06 12:11:01\n",
       "\t2020-10-30 21:57:02\n",
       "\t2020-10-31 06:35:06\n",
       "\t2020-10-31 06:38:25\n",
       "\t2020-10-31 06:38:27\n",
       "\t2020-11-02 11:36:27\n",
       "\t2020-11-05 07:45:38\n",
       "\t2020-11-05 07:47:01\n",
       "\t2020-11-07 06:14:26\n",
       "\t2020-11-07 06:14:28\n",
       "\t2020-11-26 00:59:42\n",
       "\t2021-02-21 15:49:35\n",
       "\t…\n",
       "\t2024-10-08 01:34:00\n",
       "\t2024-10-10 06:07:58\n",
       "\t2024-10-10 13:11:26\n",
       "\t2024-10-17 13:18:42\n",
       "\t2024-10-23 11:50:09\n",
       "\t2024-10-26 12:44:31\n",
       "\t2024-11-12 09:18:51\n",
       "\t2024-12-14 18:14:49\n",
       "\t2024-12-14 18:51:34\n",
       "\t2024-12-14 19:24:22\n",
       "\t2024-12-14 19:26:15\n",
       "\t2024-12-14 20:33:18\n",
       "\t2024-12-14 22:13:54\n",
       "]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "datetime_list = [datetime.datetime(2020, 10, 6, 12, 11, 1), datetime.datetime(2020, 10, 30, 21, 57, 2), datetime.datetime(2020, 10, 31, 6, 35, 6), datetime.datetime(2020, 10, 31, 6, 38, 25), datetime.datetime(2020, 10, 31, 6, 38, 27), datetime.datetime(2020, 11, 2, 11, 36, 27), datetime.datetime(2020, 11, 5, 7, 45, 38), datetime.datetime(2020, 11, 5, 7, 47, 1), datetime.datetime(2020, 11, 7, 6, 14, 26), datetime.datetime(2020, 11, 7, 6, 14, 28), datetime.datetime(2020, 11, 26, 0, 59, 42), datetime.datetime(2021, 2, 21, 15, 49, 35), datetime.datetime(2021, 2, 21, 15, 58, 37), datetime.datetime(2021, 2, 21, 17, 36, 55), datetime.datetime(2021, 4, 24, 11, 34, 32), datetime.datetime(2021, 4, 24, 11, 35, 11), datetime.datetime(2021, 4, 24, 11, 38, 3), datetime.datetime(2021, 6, 22, 6, 2, 46), datetime.datetime(2021, 7, 30, 14, 57, 4), datetime.datetime(2021, 8, 14, 23, 44, 48), datetime.datetime(2021, 8, 16, 14, 37, 50), datetime.datetime(2021, 8, 29, 4, 18, 58), datetime.datetime(2021, 9, 29, 15, 51, 30), datetime.datetime(2021, 10, 14, 7, 24, 32), datetime.datetime(2021, 10, 26, 15, 11, 54), datetime.datetime(2021, 11, 19, 14, 18, 36), datetime.datetime(2022, 1, 5, 16, 54, 11), datetime.datetime(2022, 4, 13, 14, 44, 56), datetime.datetime(2022, 4, 19, 21, 28, 43), datetime.datetime(2022, 4, 20, 7, 34, 35), datetime.datetime(2022, 4, 21, 20, 31, 51), datetime.datetime(2022, 4, 22, 8, 1, 8), datetime.datetime(2022, 5, 2, 7, 40, 14), datetime.datetime(2022, 6, 9, 7, 10, 32), datetime.datetime(2022, 6, 9, 8, 38, 40), datetime.datetime(2022, 6, 9, 8, 39, 4), datetime.datetime(2022, 6, 28, 18, 58, 20), datetime.datetime(2022, 6, 28, 19, 51, 3), datetime.datetime(2022, 6, 28, 19, 55, 18), datetime.datetime(2022, 6, 28, 19, 56, 24), datetime.datetime(2022, 7, 13, 8, 28, 59), datetime.datetime(2022, 10, 13, 15, 51, 31), datetime.datetime(2022, 10, 31, 14, 23, 32), datetime.datetime(2022, 11, 3, 14, 54, 27), datetime.datetime(2022, 11, 7, 14, 54, 31), datetime.datetime(2023, 2, 19, 6, 26, 30), datetime.datetime(2023, 2, 19, 6, 59, 36), datetime.datetime(2023, 2, 19, 7, 0, 58), datetime.datetime(2023, 3, 23, 22, 29, 9), datetime.datetime(2023, 4, 13, 0, 12, 5), datetime.datetime(2023, 4, 13, 16, 42, 11), datetime.datetime(2023, 4, 15, 4, 44, 44), datetime.datetime(2023, 4, 15, 11, 36, 7), datetime.datetime(2023, 4, 16, 19, 39, 34), datetime.datetime(2023, 4, 29, 10, 31, 50), datetime.datetime(2023, 4, 30, 11, 39, 50), datetime.datetime(2023, 8, 6, 21, 41, 59), datetime.datetime(2023, 8, 8, 5, 50, 18), datetime.datetime(2023, 8, 8, 5, 52, 4), datetime.datetime(2023, 8, 8, 5, 58, 16), datetime.datetime(2023, 8, 8, 8, 40, 21), datetime.datetime(2023, 8, 8, 8, 57, 39), datetime.datetime(2023, 8, 8, 10, 50, 18), datetime.datetime(2023, 8, 8, 11, 30, 10), datetime.datetime(2023, 8, 15, 22, 8, 48), datetime.datetime(2023, 8, 22, 1, 24, 10), datetime.datetime(2023, 10, 7, 5, 44, 52), datetime.datetime(2023, 11, 26, 16, 44, 7), datetime.datetime(2023, 11, 27, 22, 11, 17), datetime.datetime(2023, 11, 27, 22, 12, 37), datetime.datetime(2023, 11, 27, 22, 16, 47), datetime.datetime(2023, 12, 3, 20, 34, 7), datetime.datetime(2023, 12, 3, 23, 20, 33), datetime.datetime(2023, 12, 3, 23, 22, 30), datetime.datetime(2023, 12, 3, 23, 33, 27), datetime.datetime(2023, 12, 13, 12, 11, 17), datetime.datetime(2023, 12, 13, 14, 32, 45), datetime.datetime(2023, 12, 13, 14, 35, 22), datetime.datetime(2023, 12, 16, 6, 49, 4), datetime.datetime(2023, 12, 22, 12, 16, 50), datetime.datetime(2023, 12, 22, 12, 18, 54), datetime.datetime(2023, 12, 22, 13, 32, 20), datetime.datetime(2024, 1, 7, 22, 42, 23), datetime.datetime(2024, 1, 7, 22, 43, 14), datetime.datetime(2024, 1, 7, 22, 51, 6), datetime.datetime(2024, 4, 2, 17, 27, 33), datetime.datetime(2024, 4, 5, 17, 17, 48), datetime.datetime(2024, 4, 9, 15, 45, 42), datetime.datetime(2024, 4, 16, 3, 5, 16), datetime.datetime(2024, 5, 2, 2, 37, 46), datetime.datetime(2024, 7, 23, 21, 33, 35), datetime.datetime(2024, 7, 23, 21, 35, 42), datetime.datetime(2024, 8, 30, 5, 51, 19), datetime.datetime(2024, 8, 30, 5, 53, 17), datetime.datetime(2024, 8, 30, 5, 55, 14), datetime.datetime(2024, 8, 31, 11, 27, 51), datetime.datetime(2024, 10, 8, 1, 34), datetime.datetime(2024, 10, 10, 6, 7, 58), datetime.datetime(2024, 10, 10, 13, 11, 26), datetime.datetime(2024, 10, 17, 13, 18, 42), datetime.datetime(2024, 10, 23, 11, 50, 9), datetime.datetime(2024, 10, 26, 12, 44, 31), datetime.datetime(2024, 11, 12, 9, 18, 51), datetime.datetime(2024, 12, 14, 18, 14, 49), datetime.datetime(2024, 12, 14, 18, 51, 34), datetime.datetime(2024, 12, 14, 19, 24, 22), datetime.datetime(2024, 12, 14, 19, 26, 15), datetime.datetime(2024, 12, 14, 20, 33, 18), datetime.datetime(2024, 12, 14, 22, 13, 54)]\n",
    "\n",
    "timestamp_series = pl.Series(datetime_list, dtype=pl.Datetime(time_unit=\"us\"))\n",
    "timestamp_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f471ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_395, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subject_id</th><th>start_time</th><th>end_time</th><th>label</th></tr><tr><td>u16</td><td>datetime[μs]</td><td>datetime[μs]</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>0</td></tr><tr><td>1</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>0</td></tr><tr><td>3</td><td>2025-01-24 07:02:57</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>4</td><td>2025-01-23 23:10:07</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>5</td><td>2025-01-22 06:22:03</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>6</td><td>2025-01-21 09:58:36</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>7</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>8</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>9</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>0</td></tr><tr><td>10</td><td>2025-01-20 04:26:17</td><td>2025-01-23 23:56:01</td><td>0</td></tr><tr><td>11</td><td>2025-01-20 04:26:17</td><td>2025-01-22 22:58:42</td><td>0</td></tr><tr><td>12</td><td>2025-01-15 12:31:54</td><td>2025-01-21 23:03:28</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1397</td><td>2020-10-17 05:38:55</td><td>2020-10-23 11:24:08</td><td>0</td></tr><tr><td>1398</td><td>2020-10-16 01:50:26</td><td>2020-10-22 13:35:38</td><td>0</td></tr><tr><td>1399</td><td>2020-10-15 03:41:13</td><td>2020-10-21 13:14:45</td><td>0</td></tr><tr><td>1400</td><td>2020-10-14 05:11:08</td><td>2020-10-20 13:05:13</td><td>0</td></tr><tr><td>1401</td><td>2020-10-13 03:56:13</td><td>2020-10-19 10:46:58</td><td>0</td></tr><tr><td>1402</td><td>2020-10-12 05:58:17</td><td>2020-10-18 09:43:36</td><td>0</td></tr><tr><td>1403</td><td>2020-10-11 11:32:57</td><td>2020-10-17 23:31:09</td><td>0</td></tr><tr><td>1404</td><td>2020-10-10 06:32:23</td><td>2020-10-16 14:37:09</td><td>0</td></tr><tr><td>1405</td><td>2020-10-09 10:28:31</td><td>2020-10-15 14:33:27</td><td>0</td></tr><tr><td>1406</td><td>2020-10-08 07:48:21</td><td>2020-10-14 16:20:46</td><td>0</td></tr><tr><td>1407</td><td>2020-10-07 00:52:12</td><td>2020-10-13 14:55:12</td><td>0</td></tr><tr><td>1408</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_395, 4)\n",
       "┌────────────┬─────────────────────┬─────────────────────┬───────┐\n",
       "│ subject_id ┆ start_time          ┆ end_time            ┆ label │\n",
       "│ ---        ┆ ---                 ┆ ---                 ┆ ---   │\n",
       "│ u16        ┆ datetime[μs]        ┆ datetime[μs]        ┆ i64   │\n",
       "╞════════════╪═════════════════════╪═════════════════════╪═══════╡\n",
       "│ 0          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ 0     │\n",
       "│ 1          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ 0     │\n",
       "│ 3          ┆ 2025-01-24 07:02:57 ┆ 2025-01-24 12:54:08 ┆ 0     │\n",
       "│ 4          ┆ 2025-01-23 23:10:07 ┆ 2025-01-24 12:54:08 ┆ 0     │\n",
       "│ …          ┆ …                   ┆ …                   ┆ …     │\n",
       "│ 1405       ┆ 2020-10-09 10:28:31 ┆ 2020-10-15 14:33:27 ┆ 0     │\n",
       "│ 1406       ┆ 2020-10-08 07:48:21 ┆ 2020-10-14 16:20:46 ┆ 0     │\n",
       "│ 1407       ┆ 2020-10-07 00:52:12 ┆ 2020-10-13 14:55:12 ┆ 0     │\n",
       "│ 1408       ┆ 2020-10-06 12:11:01 ┆ 2020-10-12 19:28:10 ┆ 0     │\n",
       "└────────────┴─────────────────────┴─────────────────────┴───────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "aggregated_df = (\n",
    "        events_df.filter(\n",
    "            pl.col(\"timestamp\").is_not_null() & pl.col(\"subject_id\").is_not_null()\n",
    "        )\n",
    "        .sort([\"subject_id\", \"timestamp\"], descending=False)\n",
    "        .groupby(\"subject_id\")\n",
    "        .agg(\n",
    "            pl.col(\"timestamp\").min().alias(\"start_time\"),\n",
    "            pl.col(\"timestamp\").max().alias(\"end_time\"),\n",
    "        )\n",
    "    ).collect()\n",
    "\n",
    "interruption_df = aggregated_df.with_columns(\n",
    "        pl.Series([\n",
    "            int(any(end <= ts <= end + timedelta(weeks=1) for ts in timestamp_series))\n",
    "            for end in aggregated_df[\"end_time\"].to_list()\n",
    "        ]).alias(\"label\")\n",
    "    )\n",
    "interruption_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c06ecfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_395, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subject_id</th><th>start_time</th><th>end_time</th><th>label</th></tr><tr><td>u16</td><td>datetime[μs]</td><td>datetime[μs]</td><td>list[i64]</td></tr></thead><tbody><tr><td>0</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>[0, 1, … 10]</td></tr><tr><td>1</td><td>2025-02-01 13:51:48</td><td>2025-02-01 13:53:09</td><td>[0, 1, … 10]</td></tr><tr><td>3</td><td>2025-01-24 07:02:57</td><td>2025-01-24 12:54:08</td><td>[0, 1, … 10]</td></tr><tr><td>4</td><td>2025-01-23 23:10:07</td><td>2025-01-24 12:54:08</td><td>[0, 1, … 10]</td></tr><tr><td>5</td><td>2025-01-22 06:22:03</td><td>2025-01-24 12:54:08</td><td>[0, 1, … 10]</td></tr><tr><td>6</td><td>2025-01-21 09:58:36</td><td>2025-01-24 12:54:08</td><td>[0, 1, … 10]</td></tr><tr><td>7</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>[0, 1, … 10]</td></tr><tr><td>8</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>[0, 1, … 10]</td></tr><tr><td>9</td><td>2025-01-20 04:26:17</td><td>2025-01-24 12:54:08</td><td>[0, 1, … 10]</td></tr><tr><td>10</td><td>2025-01-20 04:26:17</td><td>2025-01-23 23:56:01</td><td>[0, 1, … 10]</td></tr><tr><td>11</td><td>2025-01-20 04:26:17</td><td>2025-01-22 22:58:42</td><td>[0, 1, … 10]</td></tr><tr><td>12</td><td>2025-01-15 12:31:54</td><td>2025-01-21 23:03:28</td><td>[0, 1, … 10]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1397</td><td>2020-10-17 05:38:55</td><td>2020-10-23 11:24:08</td><td>[0, 1, … 10]</td></tr><tr><td>1398</td><td>2020-10-16 01:50:26</td><td>2020-10-22 13:35:38</td><td>[0, 1, … 10]</td></tr><tr><td>1399</td><td>2020-10-15 03:41:13</td><td>2020-10-21 13:14:45</td><td>[0, 1, … 10]</td></tr><tr><td>1400</td><td>2020-10-14 05:11:08</td><td>2020-10-20 13:05:13</td><td>[0, 1, … 10]</td></tr><tr><td>1401</td><td>2020-10-13 03:56:13</td><td>2020-10-19 10:46:58</td><td>[0, 1, … 10]</td></tr><tr><td>1402</td><td>2020-10-12 05:58:17</td><td>2020-10-18 09:43:36</td><td>[0, 1, … 10]</td></tr><tr><td>1403</td><td>2020-10-11 11:32:57</td><td>2020-10-17 23:31:09</td><td>[0, 1, … 10]</td></tr><tr><td>1404</td><td>2020-10-10 06:32:23</td><td>2020-10-16 14:37:09</td><td>[0, 1, … 10]</td></tr><tr><td>1405</td><td>2020-10-09 10:28:31</td><td>2020-10-15 14:33:27</td><td>[0, 1, … 10]</td></tr><tr><td>1406</td><td>2020-10-08 07:48:21</td><td>2020-10-14 16:20:46</td><td>[0, 1, … 10]</td></tr><tr><td>1407</td><td>2020-10-07 00:52:12</td><td>2020-10-13 14:55:12</td><td>[0, 1, … 10]</td></tr><tr><td>1408</td><td>2020-10-06 12:11:01</td><td>2020-10-12 19:28:10</td><td>[0, 1, … 10]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_395, 4)\n",
       "┌────────────┬─────────────────────┬─────────────────────┬──────────────┐\n",
       "│ subject_id ┆ start_time          ┆ end_time            ┆ label        │\n",
       "│ ---        ┆ ---                 ┆ ---                 ┆ ---          │\n",
       "│ u16        ┆ datetime[μs]        ┆ datetime[μs]        ┆ list[i64]    │\n",
       "╞════════════╪═════════════════════╪═════════════════════╪══════════════╡\n",
       "│ 0          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ [0, 1, … 10] │\n",
       "│ 1          ┆ 2025-02-01 13:51:48 ┆ 2025-02-01 13:53:09 ┆ [0, 1, … 10] │\n",
       "│ 3          ┆ 2025-01-24 07:02:57 ┆ 2025-01-24 12:54:08 ┆ [0, 1, … 10] │\n",
       "│ 4          ┆ 2025-01-23 23:10:07 ┆ 2025-01-24 12:54:08 ┆ [0, 1, … 10] │\n",
       "│ …          ┆ …                   ┆ …                   ┆ …            │\n",
       "│ 1405       ┆ 2020-10-09 10:28:31 ┆ 2020-10-15 14:33:27 ┆ [0, 1, … 10] │\n",
       "│ 1406       ┆ 2020-10-08 07:48:21 ┆ 2020-10-14 16:20:46 ┆ [0, 1, … 10] │\n",
       "│ 1407       ┆ 2020-10-07 00:52:12 ┆ 2020-10-13 14:55:12 ┆ [0, 1, … 10] │\n",
       "│ 1408       ┆ 2020-10-06 12:11:01 ┆ 2020-10-12 19:28:10 ┆ [0, 1, … 10] │\n",
       "└────────────┴─────────────────────┴─────────────────────┴──────────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels = \"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\"\n",
    "\n",
    "# # Create a column where every row has the same label string\n",
    "# label_column = pl.Series(\"label\", [labels] * len(interruption_df))\n",
    "\n",
    "# # Add the new column to the DataFrame\n",
    "# interruption_df = interruption_df.with_columns(label_column)\n",
    "\n",
    "\n",
    "\n",
    "labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Create a column where every row has the same list\n",
    "label_column = pl.Series(\"label\", [labels] * len(interruption_df))\n",
    "\n",
    "# Add the new column to the DataFrame\n",
    "interruption_df = interruption_df.with_columns(label_column)\n",
    "\n",
    "\n",
    "\n",
    "interruption_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4ec5ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved task_df to /home/filip-marcus/models/ESGPT_new/EventStreamGPT/data/processed/eneryield_event_type/task_dfs\n"
     ]
    }
   ],
   "source": [
    "interruption_df.write_parquet(TASK_DF_DIR / \"task_df_eneryield_class_dist_test.parquet\")\n",
    "print(f\"saved task_df to {TASK_DF_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffbe86d",
   "metadata": {},
   "source": [
    "### Syntheti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d6eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading events from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/synthetic_1/events_df.parquet...\n",
      "shape: (69_887, 4)\n",
      "┌──────────┬────────────┬─────────────────────┬─────────────┐\n",
      "│ event_id ┆ subject_id ┆ timestamp           ┆ event_type  │\n",
      "│ ---      ┆ ---        ┆ ---                 ┆ ---         │\n",
      "│ u32      ┆ u16        ┆ datetime[μs]        ┆ cat         │\n",
      "╞══════════╪════════════╪═════════════════════╪═════════════╡\n",
      "│ 12       ┆ 0          ┆ 2024-12-27 05:59:01 ┆ disturbance │\n",
      "│ 31       ┆ 0          ┆ 2024-12-30 17:18:11 ┆ disturbance │\n",
      "│ 38       ┆ 0          ┆ 2025-01-01 00:00:00 ┆ disturbance │\n",
      "│ 59       ┆ 1          ┆ 2024-12-27 19:08:22 ┆ disturbance │\n",
      "│ …        ┆ …          ┆ …                   ┆ …           │\n",
      "│ 69857    ┆ 1824       ┆ 2020-01-01 17:32:27 ┆ disturbance │\n",
      "│ 69870    ┆ 1825       ┆ 2020-01-01 00:00:00 ┆ disturbance │\n",
      "│ 69873    ┆ 1825       ┆ 2020-01-01 13:09:20 ┆ disturbance │\n",
      "│ 69878    ┆ 1825       ┆ 2020-01-02 11:04:54 ┆ disturbance │\n",
      "└──────────┴────────────┴─────────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "COHORT_NAME = \"synthetic_1\"\n",
    "PROJECT_DIR = Path('/home/filip-marcus/ESGPT_new/EventStreamGPT')\n",
    "DATA_DIR = PROJECT_DIR / \"data/processed\" / COHORT_NAME\n",
    "assert DATA_DIR.is_dir()\n",
    "\n",
    "TASK_DF_DIR = DATA_DIR / \"task_dfs\"\n",
    "TASK_DF_DIR.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "ESD = Dataset.load(DATA_DIR)\n",
    "\n",
    "events_df = ESD.events_df.lazy()\n",
    "print(events_df.collect().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229fbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_1 = pd.read_csv('/home/filip-marcus/preprocessed_data/synthetic/pretrain/synthetic_dataset_1.csv')\n",
    "dataset_2 = pd.read_csv('/home/filip-marcus/preprocessed_data/synthetic/pretrain/synthetic_dataset_2.csv')\n",
    "dataset_3 = pd.read_csv('/home/filip-marcus/preprocessed_data/synthetic/pretrain/synthetic_dataset_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af31f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "interruption_indices = dataset_1.index[dataset_1['event_label'] == 'interruption'].tolist()\n",
    "\n",
    "# Extract the interruption times as strings from the DataFrame (index 3 refers to the 4th column)\n",
    "interruption_times_str = dataset_1.iloc[interruption_indices, 3].tolist()\n",
    "\n",
    "datetime_list = pd.to_datetime(interruption_times_str).tolist()\n",
    "\n",
    "# Step 2: Create a Polars Series with the correct datetime format (microsecond precision)\n",
    "# Polars can handle datetime objects directly\n",
    "interruption_times_series = pl.from_pandas(pd.Series(datetime_list))\n",
    "interruption_times_series = interruption_times_series.cast(pl.Datetime(time_unit=\"us\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcbb07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interruption_indices = dataset_1.index[dataset_1['event_label'] == 'interruption'].tolist()\n",
    "interruption_times_str = dataset_1.iloc[interruption_indices, 3].tolist()\n",
    "datetime_list = pd.to_datetime(interruption_times_str).tolist()\n",
    "\n",
    "# Step 2: Convert interruption times to a Polars Series with the correct datetime format (microsecond precision)\n",
    "interruption_times_series = pl.from_pandas(pd.Series(datetime_list))\n",
    "\n",
    "# Ensure interruption_times_series is in the correct datetime[μs] format\n",
    "interruption_times_series = interruption_times_series.cast(pl.Datetime(time_unit=\"us\"))\n",
    "\n",
    "# Step 3: Process the events_df and ensure the 'timestamp' column is in datetime[μs] format\n",
    "aggregated_df = (\n",
    "    events_df.filter(\n",
    "        pl.col(\"timestamp\").is_not_null() & pl.col(\"subject_id\").is_not_null()\n",
    "    )\n",
    "    .sort([\"subject_id\", \"timestamp\"])  # Sort by subject_id and timestamp\n",
    "    .with_columns([\n",
    "        # Ensure the 'timestamp' column is correctly cast to datetime[μs] if it's not already\n",
    "        pl.col(\"timestamp\").cast(pl.Datetime(time_unit=\"us\")).alias(\"timestamp\")\n",
    "    ])\n",
    "    .groupby(\"subject_id\")  # Group by subject_id\n",
    "    .agg([\n",
    "        pl.col(\"timestamp\").min().alias(\"start_time\"),  # Get the min timestamp as start_time\n",
    "        pl.col(\"timestamp\").max().alias(\"end_time\"),    # Get the max timestamp as end_time\n",
    "    ])\n",
    "    .collect()  # Collect the result into a DataFrame\n",
    ")\n",
    "\n",
    "# Step 4: Check if any interruption occurs within (start_time, end_time)\n",
    "interruption_df = aggregated_df.with_columns(\n",
    "    # Check if the start_time is between any of the interruption_times\n",
    "    pl.when(\n",
    "        pl.col(\"start_time\").is_between(interruption_times_series[0], interruption_times_series[-1])\n",
    "    )\n",
    "    .then(1)  # If interruption is within the range, assign 1 (label for interruption)\n",
    "    .otherwise(0)  # Otherwise, assign 0\n",
    "    .alias(\"label\")  # The new column will be named 'label'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2976759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interruptions: 0\n"
     ]
    }
   ],
   "source": [
    "num_interruptions = interruption_df.filter(pl.col(\"label\") == 1).height\n",
    "\n",
    "print(f\"Number of interruptions: {num_interruptions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c35451c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved task_df to /home/filip-marcus/models/ESGPT_new/EventStreamGPT/data/processed/synthetic/task_dfs\n"
     ]
    }
   ],
   "source": [
    "# Save the task_df\n",
    "  \n",
    "tte_df.collect().write_parquet(TASK_DF_DIR / \"task_df_synthetic_tte.parquet\")\n",
    "print(f\"saved task_df to {TASK_DF_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b47bc5",
   "metadata": {},
   "source": [
    "### MEGAMIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d12df13-ce7b-4ed6-9f47-badc90e7f1b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_643140/3320573384.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mPROJECT_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/filip-marcus/models/ESGPT_new/EventStreamGPT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPROJECT_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"data/processed\"\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mCOHORT_NAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mDATA_DIR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mTASK_DF_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"task_dfs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create a task_df to be used in zeroshot evaluation. This task_df should evaluate TTE prediction on eneryield data\n",
    "COHORT_NAME = \"megamind\"\n",
    "PROJECT_DIR = Path('/home/filip-marcus/models/ESGPT_new/EventStreamGPT')\n",
    "DATA_DIR = PROJECT_DIR / \"data/processed\" / COHORT_NAME\n",
    "assert DATA_DIR.is_dir()\n",
    "\n",
    "TASK_DF_DIR = DATA_DIR / \"task_dfs\"\n",
    "TASK_DF_DIR.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "ESD = Dataset.load(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31608a99-223e-42bc-b762-295fba98b508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (esgpt-venv)",
   "language": "python",
   "name": "esgpt-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
