nohup: ignoring input
Running sweep with config: FT_hp_sweep_event_label
2025-04-10 14:32:20,032 - wandb.wandb_agent - INFO - Running runs: []
Create sweep with ID: sj5xnnh1
Sweep URL: https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
[2025-04-10 14:32:20,032][wandb.wandb_agent][INFO] - Running runs: []
2025-04-10 14:32:20,386 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:32:20,386][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:32:20,386 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.30833528635345203
	config.input_dropout: 0.42045688601518394
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.07840490921006177
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: max
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 53
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.00024858911730323615
	optimization_config.init_lr: 1.4620743539614804e-05
	optimization_config.lr_decay_power: 0.9787228425083344
	optimization_config.lr_frac_warmup_steps: 1.2426418640607272e-05
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.007687563458786614
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:32:20,386][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.30833528635345203
	config.input_dropout: 0.42045688601518394
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.07840490921006177
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: max
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 53
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.00024858911730323615
	optimization_config.init_lr: 1.4620743539614804e-05
	optimization_config.lr_decay_power: 0.9787228425083344
	optimization_config.lr_frac_warmup_steps: 1.2426418640607272e-05
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.007687563458786614
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:32:20,398 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.30833528635345203 config.input_dropout=0.42045688601518394 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.07840490921006177 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=max data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=53 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.00024858911730323615 optimization_config.init_lr=1.4620743539614804e-05 optimization_config.lr_decay_power=0.9787228425083344 optimization_config.lr_frac_warmup_steps=1.2426418640607272e-05 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.007687563458786614 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:32:20,398][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.30833528635345203 config.input_dropout=0.42045688601518394 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.07840490921006177 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=max data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=53 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.00024858911730323615 optimization_config.init_lr=1.4620743539614804e-05 optimization_config.lr_decay_power=0.9787228425083344 optimization_config.lr_frac_warmup_steps=1.2426418640607272e-05 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.007687563458786614 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
2025-04-10 14:32:25,409 - wandb.wandb_agent - INFO - Running runs: ['0bqp45hz']
[2025-04-10 14:32:25,409][wandb.wandb_agent][INFO] - Running runs: ['0bqp45hz']
Seed set to 1
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_143227-0bqp45hz
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/0bqp45hz
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.30833528635345203
Overwriting input_dropout in config from 0.4494236115512016 to 0.42045688601518394
Overwriting resid_dropout in config from 0.4939188761966135 to 0.07840490921006177
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'max', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.30833528635345203
Overwriting input_dropout in config from 0.4494236115512016 to 0.42045688601518394
Overwriting resid_dropout in config from 0.4939188761966135 to 0.07840490921006177
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'max', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/2 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] 
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.94it/s]
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.94it/s, v_num=45hz]/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.
  warnings.warn(*args, **kwargs)

Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.54it/s, v_num=45hz]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.54it/s, v_num=45hz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.44it/s][A

                                                                      [A
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.03it/s, v_num=45hz]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.02it/s, v_num=45hz]
Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]        
Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.83it/s, v_num=45hz]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.83it/s, v_num=45hz]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.40it/s, v_num=45hz]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.40it/s, v_num=45hz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.43it/s][A

                                                                      [A
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.96it/s, v_num=45hz]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.96it/s, v_num=45hz]
Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]        
Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.90it/s, v_num=45hz]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.90it/s, v_num=45hz]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.49it/s, v_num=45hz]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.49it/s, v_num=45hz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.20it/s][A

                                                                      [A
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.01it/s, v_num=45hz]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.01it/s, v_num=45hz]
Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]        
Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]
Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.81it/s, v_num=45hz]
Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.81it/s, v_num=45hz]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.37it/s, v_num=45hz]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.37it/s, v_num=45hz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.53it/s][A

                                                                      [A
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.96it/s, v_num=45hz]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.95it/s, v_num=45hz]
Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]        
Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]
Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.81it/s, v_num=45hz]
Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.81it/s, v_num=45hz]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.36it/s, v_num=45hz]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.36it/s, v_num=45hz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.42it/s][A

                                                                      [A
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.95it/s, v_num=45hz]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.95it/s, v_num=45hz]
Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]        
Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]
Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.79it/s, v_num=45hz]
Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.79it/s, v_num=45hz]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.35it/s, v_num=45hz]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.35it/s, v_num=45hz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.31it/s][A

                                                                      [A
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.94it/s, v_num=45hz]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.94it/s, v_num=45hz]
Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]        
Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]
Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.82it/s, v_num=45hz]
Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.82it/s, v_num=45hz]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.37it/s, v_num=45hz]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.37it/s, v_num=45hz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.60it/s][A

                                                                      [A
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.96it/s, v_num=45hz]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.96it/s, v_num=45hz]
Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]        
Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]
Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.90it/s, v_num=45hz]
Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.90it/s, v_num=45hz]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.49it/s, v_num=45hz]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.48it/s, v_num=45hz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.35it/s][A

                                                                      [A
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.01it/s, v_num=45hz]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.01it/s, v_num=45hz]
Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]        
Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]
Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.83it/s, v_num=45hz]
Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.83it/s, v_num=45hz]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.39it/s, v_num=45hz]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.39it/s, v_num=45hz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.64it/s][A

                                                                      [A
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.96it/s, v_num=45hz]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.96it/s, v_num=45hz]
Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz]        
Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s, v_num=45hz][rank: 1] Child process with PID 1147109 terminated with code -9. Forcefully terminating all other processes to avoid zombies üßü
2025-04-10 14:33:01,579 - wandb.wandb_agent - INFO - Cleaning up finished run: 0bqp45hz
[2025-04-10 14:33:01,579][wandb.wandb_agent][INFO] - Cleaning up finished run: 0bqp45hz
wandb: Waiting for W&B process to finish... (failed -9). Press Control-C to abort syncing.
wandb: - 0.000 MB of 0.030 MB uploaded (0.000 MB deduped)
wandb: \ 0.030 MB of 0.030 MB uploaded (0.000 MB deduped)
wandb: 
wandb: Run history:
wandb:                                epoch ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:                           task_AUROC ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                        task_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                            task_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:                  trainer/global_step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:                       tuning_TTE_MSE ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb:                      tuning_TTE_MSLE ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÅ‚ñÇ‚ñÇ
wandb:                   tuning_TTE_reg_NLL ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           tuning_event_label_cls_NLL ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:    tuning_event_label_macro_accuracy ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:    tuning_event_label_micro_accuracy ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:    tuning_event_label_weighted_AUROC ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: tuning_event_label_weighted_accuracy ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:            tuning_event_type_cls_NLL ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñà
wandb:     tuning_event_type_macro_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     tuning_event_type_micro_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     tuning_event_type_weighted_AUROC ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  tuning_event_type_weighted_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 tuning_feature_0_MSE ‚ñÅ‚ñà‚ñá‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÉ
wandb:             tuning_feature_0_reg_NLL ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:                tuning_feature_10_MSE ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÜ‚ñÇ‚ñÖ‚ñÇ
wandb:            tuning_feature_10_reg_NLL ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:                tuning_feature_11_MSE ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñá‚ñà‚ñÑ‚ñá‚ñá
wandb:            tuning_feature_11_reg_NLL ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                tuning_feature_12_MSE ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÖ
wandb:            tuning_feature_12_reg_NLL ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                tuning_feature_13_MSE ‚ñÅ‚ñà‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÅ
wandb:            tuning_feature_13_reg_NLL ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                tuning_feature_14_MSE ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÉ‚ñÅ
wandb:            tuning_feature_14_reg_NLL ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ
wandb:                tuning_feature_15_MSE ‚ñà‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñá‚ñÅ
wandb:            tuning_feature_15_reg_NLL ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:                tuning_feature_16_MSE ‚ñÑ‚ñá‚ñà‚ñÖ‚ñÇ‚ñá‚ñÜ‚ñÅ‚ñÖ
wandb:            tuning_feature_16_reg_NLL ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:                tuning_feature_17_MSE ‚ñá‚ñÜ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñà‚ñÑ‚ñÇ
wandb:            tuning_feature_17_reg_NLL ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:                tuning_feature_18_MSE ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÑ‚ñà‚ñÇ‚ñÜ
wandb:            tuning_feature_18_reg_NLL ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:                tuning_feature_19_MSE ‚ñà‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÑ
wandb:            tuning_feature_19_reg_NLL ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                 tuning_feature_1_MSE ‚ñá‚ñÑ‚ñÜ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñà‚ñá
wandb:             tuning_feature_1_reg_NLL ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                tuning_feature_20_MSE ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñà
wandb:            tuning_feature_20_reg_NLL ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                tuning_feature_21_MSE ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÅ‚ñá
wandb:            tuning_feature_21_reg_NLL ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                tuning_feature_22_MSE ‚ñÜ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÅ
wandb:            tuning_feature_22_reg_NLL ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:                tuning_feature_23_MSE ‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñà‚ñá‚ñÑ‚ñÜ‚ñÅ
wandb:            tuning_feature_23_reg_NLL ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:                tuning_feature_24_MSE ‚ñá‚ñà‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÇ‚ñÅ
wandb:            tuning_feature_24_reg_NLL ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:                 tuning_feature_2_MSE ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÖ
wandb:             tuning_feature_2_reg_NLL ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                 tuning_feature_3_MSE ‚ñà‚ñÅ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñà‚ñÇ‚ñÖ
wandb:             tuning_feature_3_reg_NLL ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                 tuning_feature_4_MSE ‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñÑ
wandb:             tuning_feature_4_reg_NLL ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                 tuning_feature_5_MSE ‚ñÜ‚ñÇ‚ñà‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñá
wandb:             tuning_feature_5_reg_NLL ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb:                 tuning_feature_6_MSE ‚ñà‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ
wandb:             tuning_feature_6_reg_NLL ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                 tuning_feature_7_MSE ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñà
wandb:             tuning_feature_7_reg_NLL ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                 tuning_feature_8_MSE ‚ñÅ‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÇ
wandb:             tuning_feature_8_reg_NLL ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:                 tuning_feature_9_MSE ‚ñÇ‚ñÅ‚ñÜ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñÇ
wandb:             tuning_feature_9_reg_NLL ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                          tuning_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                                epoch 8
wandb:                           task_AUROC 0.00078
wandb:                        task_accuracy 0.99883
wandb:                            task_loss 0.25618
wandb:                  trainer/global_step 17
wandb:                       tuning_TTE_MSE 36312.10938
wandb:                      tuning_TTE_MSLE 8.18556
wandb:                   tuning_TTE_reg_NLL 5.33474
wandb:           tuning_event_label_cls_NLL 0.16412
wandb:    tuning_event_label_macro_accuracy 0.92392
wandb:    tuning_event_label_micro_accuracy 0.92392
wandb:    tuning_event_label_weighted_AUROC 0.76419
wandb: tuning_event_label_weighted_accuracy 0.72307
wandb:            tuning_event_type_cls_NLL 0.00949
wandb:     tuning_event_type_macro_accuracy 0.0
wandb:     tuning_event_type_micro_accuracy 0.0
wandb:     tuning_event_type_weighted_AUROC 0.0
wandb:  tuning_event_type_weighted_accuracy 0.0
wandb:                 tuning_feature_0_MSE 0.15546
wandb:             tuning_feature_0_reg_NLL -0.47931
wandb:                tuning_feature_10_MSE 0.68969
wandb:            tuning_feature_10_reg_NLL 0.78988
wandb:                tuning_feature_11_MSE 1.88631
wandb:            tuning_feature_11_reg_NLL 1.17761
wandb:                tuning_feature_12_MSE 1.63209
wandb:            tuning_feature_12_reg_NLL 1.12184
wandb:                tuning_feature_13_MSE 2.20124
wandb:            tuning_feature_13_reg_NLL 1.41203
wandb:                tuning_feature_14_MSE 0.67043
wandb:            tuning_feature_14_reg_NLL 0.76037
wandb:                tuning_feature_15_MSE 1.30579
wandb:            tuning_feature_15_reg_NLL 1.25428
wandb:                tuning_feature_16_MSE 1.13331
wandb:            tuning_feature_16_reg_NLL 1.14126
wandb:                tuning_feature_17_MSE 1.17342
wandb:            tuning_feature_17_reg_NLL 1.18059
wandb:                tuning_feature_18_MSE 1.34495
wandb:            tuning_feature_18_reg_NLL 0.97309
wandb:                tuning_feature_19_MSE 0.49666
wandb:            tuning_feature_19_reg_NLL 0.5393
wandb:                 tuning_feature_1_MSE 0.57027
wandb:             tuning_feature_1_reg_NLL 0.59694
wandb:                tuning_feature_20_MSE 0.48291
wandb:            tuning_feature_20_reg_NLL 0.48133
wandb:                tuning_feature_21_MSE 0.49481
wandb:            tuning_feature_21_reg_NLL 0.45928
wandb:                tuning_feature_22_MSE 6.90277
wandb:            tuning_feature_22_reg_NLL 5.32661
wandb:                tuning_feature_23_MSE 6.47014
wandb:            tuning_feature_23_reg_NLL 1.15622
wandb:                tuning_feature_24_MSE 14.85734
wandb:            tuning_feature_24_reg_NLL 2.27246
wandb:                 tuning_feature_2_MSE 1.72085
wandb:             tuning_feature_2_reg_NLL 0.33251
wandb:                 tuning_feature_3_MSE 1.89114
wandb:             tuning_feature_3_reg_NLL 0.42093
wandb:                 tuning_feature_4_MSE 1.49096
wandb:             tuning_feature_4_reg_NLL -0.07246
wandb:                 tuning_feature_5_MSE 0.65781
wandb:             tuning_feature_5_reg_NLL 0.13706
wandb:                 tuning_feature_6_MSE 0.89198
wandb:             tuning_feature_6_reg_NLL 0.9995
wandb:                 tuning_feature_7_MSE 1.60004
wandb:             tuning_feature_7_reg_NLL 1.35593
wandb:                 tuning_feature_8_MSE 1.43591
wandb:             tuning_feature_8_reg_NLL 1.28297
wandb:                 tuning_feature_9_MSE 1.58446
wandb:             tuning_feature_9_reg_NLL 1.26891
wandb:                          tuning_loss 31.65364
wandb: 
wandb: üöÄ View run generative_event_stream_transformer at: https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/0bqp45hz
wandb: Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_143227-0bqp45hz/logs
2025-04-10 14:33:05,936 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:33:05,936][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:33:05,936 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.08562092024337803
	config.input_dropout: 0.10660983319870264
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.4959246994628329
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: mean
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 43
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.0007238988819748813
	optimization_config.init_lr: 0.0028869438438458724
	optimization_config.lr_decay_power: 2.074981168091372
	optimization_config.lr_frac_warmup_steps: 0.007060358053721894
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.005852798653658708
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:33:05,936][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.08562092024337803
	config.input_dropout: 0.10660983319870264
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.4959246994628329
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: mean
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 43
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.0007238988819748813
	optimization_config.init_lr: 0.0028869438438458724
	optimization_config.lr_decay_power: 2.074981168091372
	optimization_config.lr_frac_warmup_steps: 0.007060358053721894
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.005852798653658708
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:33:05,948 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.08562092024337803 config.input_dropout=0.10660983319870264 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.4959246994628329 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=mean data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=43 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.0007238988819748813 optimization_config.init_lr=0.0028869438438458724 optimization_config.lr_decay_power=2.074981168091372 optimization_config.lr_frac_warmup_steps=0.007060358053721894 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.005852798653658708 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:33:05,948][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.08562092024337803 config.input_dropout=0.10660983319870264 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.4959246994628329 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=mean data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=43 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.0007238988819748813 optimization_config.init_lr=0.0028869438438458724 optimization_config.lr_decay_power=2.074981168091372 optimization_config.lr_frac_warmup_steps=0.007060358053721894 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.005852798653658708 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1
2025-04-10 14:33:10,961 - wandb.wandb_agent - INFO - Running runs: ['8v0c6657']
[2025-04-10 14:33:10,961][wandb.wandb_agent][INFO] - Running runs: ['8v0c6657']
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_143312-8v0c6657
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/8v0c6657
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.08562092024337803
Overwriting input_dropout in config from 0.4494236115512016 to 0.10660983319870264
Overwriting resid_dropout in config from 0.4939188761966135 to 0.4959246994628329
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'mean', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.08562092024337803
Overwriting input_dropout in config from 0.4494236115512016 to 0.10660983319870264
Overwriting resid_dropout in config from 0.4939188761966135 to 0.4959246994628329
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'mean', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.59it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/2 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] 
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.10it/s]
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.09it/s, v_num=6657]/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.
  warnings.warn(*args, **kwargs)

Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.74it/s, v_num=6657]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.74it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.70it/s][A

                                                                      [A
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.10it/s, v_num=6657]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.10it/s, v_num=6657]
Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.01it/s, v_num=6657]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.01it/s, v_num=6657]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.62it/s, v_num=6657]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.62it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.27it/s][A

                                                                      [A
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.08it/s, v_num=6657]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.08it/s, v_num=6657]
Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.12it/s, v_num=6657]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.12it/s, v_num=6657]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.76it/s, v_num=6657]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.76it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.74it/s][A

                                                                      [A
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.15it/s, v_num=6657]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.14it/s, v_num=6657]
Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.94it/s, v_num=6657]
Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.94it/s, v_num=6657]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.53it/s, v_num=6657]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.53it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.86it/s][A

                                                                      [A
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.04it/s, v_num=6657]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.04it/s, v_num=6657]
Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.90it/s, v_num=6657]
Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.90it/s, v_num=6657]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.48it/s, v_num=6657]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.48it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.72it/s][A

                                                                      [A
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.01it/s, v_num=6657]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.01it/s, v_num=6657]
Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.94it/s, v_num=6657]
Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.94it/s, v_num=6657]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.55it/s, v_num=6657]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.55it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.52it/s][A

                                                                      [A
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.04it/s, v_num=6657]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.04it/s, v_num=6657]
Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.94it/s, v_num=6657]
Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.94it/s, v_num=6657]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.53it/s, v_num=6657]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.53it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.28it/s][A

                                                                      [A
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.04it/s, v_num=6657]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.03it/s, v_num=6657]
Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.08it/s, v_num=6657]
Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.08it/s, v_num=6657]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.70it/s, v_num=6657]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.70it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.40it/s][A

                                                                      [A
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.11it/s, v_num=6657]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.11it/s, v_num=6657]
Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.96it/s, v_num=6657]
Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.95it/s, v_num=6657]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.56it/s, v_num=6657]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.56it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.25it/s][A

                                                                      [A
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.05it/s, v_num=6657]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.04it/s, v_num=6657]
Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.00it/s, v_num=6657]
Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.00it/s, v_num=6657]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.60it/s, v_num=6657]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.60it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.29it/s][A

                                                                      [A
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.06it/s, v_num=6657]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.06it/s, v_num=6657]
Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.96it/s, v_num=6657]
Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.96it/s, v_num=6657]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.55it/s, v_num=6657]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.55it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.33it/s][A

                                                                      [A
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.05it/s, v_num=6657]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.05it/s, v_num=6657]
Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.98it/s, v_num=6657]
Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.98it/s, v_num=6657]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.58it/s, v_num=6657]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.58it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.24it/s][A

                                                                      [A
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.05it/s, v_num=6657]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.05it/s, v_num=6657]
Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.99it/s, v_num=6657]
Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.98it/s, v_num=6657]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.59it/s, v_num=6657]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.59it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.26it/s][A

                                                                      [A
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.06it/s, v_num=6657]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.06it/s, v_num=6657]
Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.02it/s, v_num=6657]
Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.02it/s, v_num=6657]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.64it/s, v_num=6657]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.64it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.68it/s][A

                                                                      [A
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.08it/s, v_num=6657]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.08it/s, v_num=6657]
Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.93it/s, v_num=6657]
Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.93it/s, v_num=6657]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.51it/s, v_num=6657]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.51it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.66it/s][A

                                                                      [A
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.03it/s, v_num=6657]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.03it/s, v_num=6657]
Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]        
Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s, v_num=6657]
Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.96it/s, v_num=6657]
Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.96it/s, v_num=6657]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.57it/s, v_num=6657]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.57it/s, v_num=6657]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.48it/s][A

                                                                      [A
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.05it/s, v_num=6657]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.05it/s, v_num=6657]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.04it/s, v_num=6657]Restoring states from the checkpoint path at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/eneryield_ft_sweep/8v0c6657/checkpoints/epoch=5-val_loss=0.00-best_model.ckpt
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Loaded model weights from the checkpoint at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/eneryield_ft_sweep/8v0c6657/checkpoints/epoch=5-val_loss=0.00-best_model.ckpt
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:216: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.

/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/finetune_weights
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/held_out_0.parquet
/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/finetune_weights
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/held_out_0.parquet

Validation: |          | 0/? [00:00<?, ?it/s]
Validation:   0%|          | 0/1 [00:00<?, ?it/s]
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.55it/s]
Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.42it/s]Restoring states from the checkpoint path at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/eneryield_ft_sweep/8v0c6657/checkpoints/epoch=5-val_loss=0.00-best_model.ckpt
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Loaded model weights from the checkpoint at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/eneryield_ft_sweep/8v0c6657/checkpoints/epoch=5-val_loss=0.00-best_model.ckpt
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:216: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
          Validate metric                       DataLoader 0
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
             task_AUROC                    0.0007812500116415322
           task_accuracy                     0.999218761920929
             task_loss                      0.06284116208553314
           tuning_TTE_MSE                      34690.92578125
          tuning_TTE_MSLE                    8.048956871032715
         tuning_TTE_reg_NLL                  5.411491394042969
     tuning_event_label_cls_NLL             0.15902595221996307
 tuning_event_label_macro_accuracy           0.9248572587966919
 tuning_event_label_micro_accuracy           0.9248572587966919
 tuning_event_label_weighted_AUROC           0.8387596607208252
tuning_event_label_weighted_accuracy         0.7331403493881226
     tuning_event_type_cls_NLL              0.009529849514365196
  tuning_event_type_macro_accuracy                  0.0
  tuning_event_type_micro_accuracy                  0.0
  tuning_event_type_weighted_AUROC                  0.0
tuning_event_type_weighted_accuracy                 0.0
        tuning_feature_0_MSE                 0.2625778317451477
      tuning_feature_0_reg_NLL              -0.6013303995132446
       tuning_feature_10_MSE                 1.0309017896652222
     tuning_feature_10_reg_NLL               0.8120278716087341
       tuning_feature_11_MSE                 1.7518621683120728
     tuning_feature_11_reg_NLL               1.400679111480713
       tuning_feature_12_MSE                 1.4539973735809326
     tuning_feature_12_reg_NLL               1.1025935411453247
       tuning_feature_13_MSE                 2.602602005004883
     tuning_feature_13_reg_NLL               1.3599491119384766
       tuning_feature_14_MSE                 1.045659065246582
     tuning_feature_14_reg_NLL               0.8103621006011963
       tuning_feature_15_MSE                 1.4374070167541504
     tuning_feature_15_reg_NLL               1.2068463563919067
       tuning_feature_16_MSE                 1.0774481296539307
     tuning_feature_16_reg_NLL               1.092486023902893
       tuning_feature_17_MSE                 1.2666404247283936
     tuning_feature_17_reg_NLL               1.1430020332336426
       tuning_feature_18_MSE                 1.7417000532150269
     tuning_feature_18_reg_NLL               1.1213737726211548
       tuning_feature_19_MSE                 0.6096187233924866
     tuning_feature_19_reg_NLL               0.6346731185913086
        tuning_feature_1_MSE                 0.7461344599723816
      tuning_feature_1_reg_NLL               0.3892008662223816
       tuning_feature_20_MSE                 0.6323338150978088
     tuning_feature_20_reg_NLL               0.584843099117279
       tuning_feature_21_MSE                 0.5205034017562866
     tuning_feature_21_reg_NLL               0.5231050252914429
       tuning_feature_22_MSE                 12.903121948242188
     tuning_feature_22_reg_NLL               3.0107481479644775
       tuning_feature_23_MSE                 6.433587551116943
     tuning_feature_23_reg_NLL               2.1948490142822266
       tuning_feature_24_MSE                 16.674230575561523
     tuning_feature_24_reg_NLL               1.6158374547958374
        tuning_feature_2_MSE                 2.0468342304229736
      tuning_feature_2_reg_NLL              0.47843214869499207
        tuning_feature_3_MSE                 2.1636953353881836
      tuning_feature_3_reg_NLL               0.2789573669433594
        tuning_feature_4_MSE                 1.898971676826477
      tuning_feature_4_reg_NLL              0.21842174232006073
        tuning_feature_5_MSE                 0.6994795203208923
      tuning_feature_5_reg_NLL              0.02556241862475872
        tuning_feature_6_MSE                 1.0872803926467896
      tuning_feature_6_reg_NLL               1.0483940839767456
        tuning_feature_7_MSE                 1.6832425594329834
      tuning_feature_7_reg_NLL               1.3012795448303223
        tuning_feature_8_MSE                 1.5325348377227783
      tuning_feature_8_reg_NLL               1.2043057680130005
        tuning_feature_9_MSE                 1.6283550262451172
      tuning_feature_9_reg_NLL               1.2198535203933716
            tuning_loss                       29.8193416595459
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

Testing: |          | 0/? [00:00<?, ?it/s]
Testing:   0%|          | 0/1 [00:00<?, ?it/s]
Testing DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Testing DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.72it/s]
Testing DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s]wandb: Waiting for W&B process to finish... (success).
wandb: - 0.000 MB of 0.000 MB uploaded (0.000 MB deduped)
wandb: \ 0.000 MB of 0.000 MB uploaded (0.000 MB deduped)
wandb: 
wandb: Run history:
wandb:                                  epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                       held_out_TTE_MSE ‚ñÅ
wandb:                      held_out_TTE_MSLE ‚ñÅ
wandb:                   held_out_TTE_reg_NLL ‚ñÅ
wandb:           held_out_event_label_cls_NLL ‚ñÅ
wandb:    held_out_event_label_macro_accuracy ‚ñÅ
wandb:    held_out_event_label_micro_accuracy ‚ñÅ
wandb:    held_out_event_label_weighted_AUROC ‚ñÅ
wandb: held_out_event_label_weighted_accuracy ‚ñÅ
wandb:            held_out_event_type_cls_NLL ‚ñÅ
wandb:     held_out_event_type_macro_accuracy ‚ñÅ
wandb:     held_out_event_type_micro_accuracy ‚ñÅ
wandb:     held_out_event_type_weighted_AUROC ‚ñÅ
wandb:  held_out_event_type_weighted_accuracy ‚ñÅ
wandb:                 held_out_feature_0_MSE ‚ñÅ
wandb:             held_out_feature_0_reg_NLL ‚ñÅ
wandb:                held_out_feature_10_MSE ‚ñÅ
wandb:            held_out_feature_10_reg_NLL ‚ñÅ
wandb:                held_out_feature_11_MSE ‚ñÅ
wandb:            held_out_feature_11_reg_NLL ‚ñÅ
wandb:                held_out_feature_12_MSE ‚ñÅ
wandb:            held_out_feature_12_reg_NLL ‚ñÅ
wandb:                held_out_feature_13_MSE ‚ñÅ
wandb:            held_out_feature_13_reg_NLL ‚ñÅ
wandb:                held_out_feature_14_MSE ‚ñÅ
wandb:            held_out_feature_14_reg_NLL ‚ñÅ
wandb:                held_out_feature_15_MSE ‚ñÅ
wandb:            held_out_feature_15_reg_NLL ‚ñÅ
wandb:                held_out_feature_16_MSE ‚ñÅ
wandb:            held_out_feature_16_reg_NLL ‚ñÅ
wandb:                held_out_feature_17_MSE ‚ñÅ
wandb:            held_out_feature_17_reg_NLL ‚ñÅ
wandb:                held_out_feature_18_MSE ‚ñÅ
wandb:            held_out_feature_18_reg_NLL ‚ñÅ
wandb:                held_out_feature_19_MSE ‚ñÅ
wandb:            held_out_feature_19_reg_NLL ‚ñÅ
wandb:                 held_out_feature_1_MSE ‚ñÅ
wandb:             held_out_feature_1_reg_NLL ‚ñÅ
wandb:                held_out_feature_20_MSE ‚ñÅ
wandb:            held_out_feature_20_reg_NLL ‚ñÅ
wandb:                held_out_feature_21_MSE ‚ñÅ
wandb:            held_out_feature_21_reg_NLL ‚ñÅ
wandb:                held_out_feature_22_MSE ‚ñÅ
wandb:            held_out_feature_22_reg_NLL ‚ñÅ
wandb:                held_out_feature_23_MSE ‚ñÅ
wandb:            held_out_feature_23_reg_NLL ‚ñÅ
wandb:                held_out_feature_24_MSE ‚ñÅ
wandb:            held_out_feature_24_reg_NLL ‚ñÅ
wandb:                 held_out_feature_2_MSE ‚ñÅ
wandb:             held_out_feature_2_reg_NLL ‚ñÅ
wandb:                 held_out_feature_3_MSE ‚ñÅ
wandb:             held_out_feature_3_reg_NLL ‚ñÅ
wandb:                 held_out_feature_4_MSE ‚ñÅ
wandb:             held_out_feature_4_reg_NLL ‚ñÅ
wandb:                 held_out_feature_5_MSE ‚ñÅ
wandb:             held_out_feature_5_reg_NLL ‚ñÅ
wandb:                 held_out_feature_6_MSE ‚ñÅ
wandb:             held_out_feature_6_reg_NLL ‚ñÅ
wandb:                 held_out_feature_7_MSE ‚ñÅ
wandb:             held_out_feature_7_reg_NLL ‚ñÅ
wandb:                 held_out_feature_8_MSE ‚ñÅ
wandb:             held_out_feature_8_reg_NLL ‚ñÅ
wandb:                 held_out_feature_9_MSE ‚ñÅ
wandb:             held_out_feature_9_reg_NLL ‚ñÅ
wandb:                          held_out_loss ‚ñÅ
wandb:                             task_AUROC ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÅ‚ñÅ
wandb:                          task_accuracy ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñà
wandb:                              task_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:                    trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                         tuning_TTE_MSE ‚ñÜ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÑ
wandb:                        tuning_TTE_MSLE ‚ñà‚ñÉ‚ñÅ‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñá
wandb:                     tuning_TTE_reg_NLL ‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ
wandb:             tuning_event_label_cls_NLL ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÜ
wandb:      tuning_event_label_macro_accuracy ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñà‚ñÉ
wandb:      tuning_event_label_micro_accuracy ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñà‚ñÉ
wandb:      tuning_event_label_weighted_AUROC ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ
wandb:   tuning_event_label_weighted_accuracy ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñà‚ñÉ
wandb:              tuning_event_type_cls_NLL ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÜ
wandb:       tuning_event_type_macro_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       tuning_event_type_micro_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       tuning_event_type_weighted_AUROC ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:    tuning_event_type_weighted_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   tuning_feature_0_MSE ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñá‚ñÖ
wandb:               tuning_feature_0_reg_NLL ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÖ
wandb:                  tuning_feature_10_MSE ‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñà
wandb:              tuning_feature_10_reg_NLL ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÉ
wandb:                  tuning_feature_11_MSE ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÉ
wandb:              tuning_feature_11_reg_NLL ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñá‚ñÇ‚ñÅ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÉ
wandb:                  tuning_feature_12_MSE ‚ñà‚ñá‚ñÑ‚ñà‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÑ
wandb:              tuning_feature_12_reg_NLL ‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
wandb:                  tuning_feature_13_MSE ‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñá‚ñá‚ñá‚ñà‚ñÉ‚ñÖ
wandb:              tuning_feature_13_reg_NLL ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÅ
wandb:                  tuning_feature_14_MSE ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:              tuning_feature_14_reg_NLL ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÑ‚ñÅ
wandb:                  tuning_feature_15_MSE ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñà
wandb:              tuning_feature_15_reg_NLL ‚ñà‚ñá‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÖ
wandb:                  tuning_feature_16_MSE ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÜ
wandb:              tuning_feature_16_reg_NLL ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ
wandb:                  tuning_feature_17_MSE ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñá‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñà
wandb:              tuning_feature_17_reg_NLL ‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÅ‚ñÉ‚ñÜ
wandb:                  tuning_feature_18_MSE ‚ñÑ‚ñÇ‚ñÉ‚ñá‚ñÅ‚ñá‚ñá‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñà
wandb:              tuning_feature_18_reg_NLL ‚ñÑ‚ñÑ‚ñÉ‚ñà‚ñÇ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñá
wandb:                  tuning_feature_19_MSE ‚ñÑ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÖ
wandb:              tuning_feature_19_reg_NLL ‚ñÉ‚ñÇ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb:                   tuning_feature_1_MSE ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÇ‚ñà
wandb:               tuning_feature_1_reg_NLL ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÅ
wandb:                  tuning_feature_20_MSE ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ
wandb:              tuning_feature_20_reg_NLL ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÖ
wandb:                  tuning_feature_21_MSE ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:              tuning_feature_21_reg_NLL ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:                  tuning_feature_22_MSE ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb:              tuning_feature_22_reg_NLL ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÇ
wandb:                  tuning_feature_23_MSE ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÉ
wandb:              tuning_feature_23_reg_NLL ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÉ
wandb:                  tuning_feature_24_MSE ‚ñÜ‚ñá‚ñÑ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñà
wandb:              tuning_feature_24_reg_NLL ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÅ
wandb:                   tuning_feature_2_MSE ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñà
wandb:               tuning_feature_2_reg_NLL ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñà‚ñÜ
wandb:                   tuning_feature_3_MSE ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÖ
wandb:               tuning_feature_3_reg_NLL ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñá‚ñà‚ñÖ
wandb:                   tuning_feature_4_MSE ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñá
wandb:               tuning_feature_4_reg_NLL ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñÉ‚ñÖ‚ñÑ
wandb:                   tuning_feature_5_MSE ‚ñÉ‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ
wandb:               tuning_feature_5_reg_NLL ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ
wandb:                   tuning_feature_6_MSE ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñà
wandb:               tuning_feature_6_reg_NLL ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñá
wandb:                   tuning_feature_7_MSE ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñá
wandb:               tuning_feature_7_reg_NLL ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÑ
wandb:                   tuning_feature_8_MSE ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñá
wandb:               tuning_feature_8_reg_NLL ‚ñà‚ñá‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÜ
wandb:                   tuning_feature_9_MSE ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÖ
wandb:               tuning_feature_9_reg_NLL ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÖ
wandb:                            tuning_loss ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÅ
wandb: 
wandb: Run summary:
wandb:                                  epoch 16
wandb:                       held_out_TTE_MSE 40754.17188
wandb:                      held_out_TTE_MSLE 8.46719
wandb:                   held_out_TTE_reg_NLL 5.43162
wandb:           held_out_event_label_cls_NLL 0.17787
wandb:    held_out_event_label_macro_accuracy 0.95054
wandb:    held_out_event_label_micro_accuracy 0.95054
wandb:    held_out_event_label_weighted_AUROC 0.88673
wandb: held_out_event_label_weighted_accuracy 0.85451
wandb:            held_out_event_type_cls_NLL 0.01022
wandb:     held_out_event_type_macro_accuracy 0.0
wandb:     held_out_event_type_micro_accuracy 0.0
wandb:     held_out_event_type_weighted_AUROC 0.0
wandb:  held_out_event_type_weighted_accuracy 0.0
wandb:                 held_out_feature_0_MSE 1.20353
wandb:             held_out_feature_0_reg_NLL -0.38901
wandb:                held_out_feature_10_MSE 1.55094
wandb:            held_out_feature_10_reg_NLL 1.30192
wandb:                held_out_feature_11_MSE 2.47226
wandb:            held_out_feature_11_reg_NLL 1.60541
wandb:                held_out_feature_12_MSE 2.30922
wandb:            held_out_feature_12_reg_NLL 1.93926
wandb:                held_out_feature_13_MSE 3.16647
wandb:            held_out_feature_13_reg_NLL 2.20928
wandb:                held_out_feature_14_MSE 2.72831
wandb:            held_out_feature_14_reg_NLL 0.93244
wandb:                held_out_feature_15_MSE 1.49577
wandb:            held_out_feature_15_reg_NLL 1.32078
wandb:                held_out_feature_16_MSE 1.2655
wandb:            held_out_feature_16_reg_NLL 1.23533
wandb:                held_out_feature_17_MSE 1.40292
wandb:            held_out_feature_17_reg_NLL 1.26629
wandb:                held_out_feature_18_MSE 2.25054
wandb:            held_out_feature_18_reg_NLL 1.41706
wandb:                held_out_feature_19_MSE 1.04918
wandb:            held_out_feature_19_reg_NLL 0.84652
wandb:                 held_out_feature_1_MSE 1.96618
wandb:             held_out_feature_1_reg_NLL 0.04971
wandb:                held_out_feature_20_MSE 1.1879
wandb:            held_out_feature_20_reg_NLL 0.85253
wandb:                held_out_feature_21_MSE 0.97834
wandb:            held_out_feature_21_reg_NLL 0.83963
wandb:                held_out_feature_22_MSE 5.26238
wandb:            held_out_feature_22_reg_NLL 1.73398
wandb:                held_out_feature_23_MSE 1.77946
wandb:            held_out_feature_23_reg_NLL 1.38273
wandb:                held_out_feature_24_MSE 1.92842
wandb:            held_out_feature_24_reg_NLL 0.71739
wandb:                 held_out_feature_2_MSE 2.61769
wandb:             held_out_feature_2_reg_NLL 1.54724
wandb:                 held_out_feature_3_MSE 1.70709
wandb:             held_out_feature_3_reg_NLL 0.87254
wandb:                 held_out_feature_4_MSE 2.20634
wandb:             held_out_feature_4_reg_NLL 1.48457
wandb:                 held_out_feature_5_MSE 1.99781
wandb:             held_out_feature_5_reg_NLL 4.80245
wandb:                 held_out_feature_6_MSE 1.0292
wandb:             held_out_feature_6_reg_NLL 0.92943
wandb:                 held_out_feature_7_MSE 1.78332
wandb:             held_out_feature_7_reg_NLL 1.33969
wandb:                 held_out_feature_8_MSE 1.74836
wandb:             held_out_feature_8_reg_NLL 1.28081
wandb:                 held_out_feature_9_MSE 1.87693
wandb:             held_out_feature_9_reg_NLL 1.32294
wandb:                          held_out_loss 38.50146
wandb:                             task_AUROC 0.0002
wandb:                          task_accuracy 0.9998
wandb:                              task_loss 0.04081
wandb:                    trainer/global_step 32
wandb:                         tuning_TTE_MSE 34690.92578
wandb:                        tuning_TTE_MSLE 8.04896
wandb:                     tuning_TTE_reg_NLL 5.41149
wandb:             tuning_event_label_cls_NLL 0.15903
wandb:      tuning_event_label_macro_accuracy 0.92486
wandb:      tuning_event_label_micro_accuracy 0.92486
wandb:      tuning_event_label_weighted_AUROC 0.83876
wandb:   tuning_event_label_weighted_accuracy 0.73314
wandb:              tuning_event_type_cls_NLL 0.00953
wandb:       tuning_event_type_macro_accuracy 0.0
wandb:       tuning_event_type_micro_accuracy 0.0
wandb:       tuning_event_type_weighted_AUROC 0.0
wandb:    tuning_event_type_weighted_accuracy 0.0
wandb:                   tuning_feature_0_MSE 0.26258
wandb:               tuning_feature_0_reg_NLL -0.60133
wandb:                  tuning_feature_10_MSE 1.0309
wandb:              tuning_feature_10_reg_NLL 0.81203
wandb:                  tuning_feature_11_MSE 1.75186
wandb:              tuning_feature_11_reg_NLL 1.40068
wandb:                  tuning_feature_12_MSE 1.454
wandb:              tuning_feature_12_reg_NLL 1.10259
wandb:                  tuning_feature_13_MSE 2.6026
wandb:              tuning_feature_13_reg_NLL 1.35995
wandb:                  tuning_feature_14_MSE 1.04566
wandb:              tuning_feature_14_reg_NLL 0.81036
wandb:                  tuning_feature_15_MSE 1.43741
wandb:              tuning_feature_15_reg_NLL 1.20685
wandb:                  tuning_feature_16_MSE 1.07745
wandb:              tuning_feature_16_reg_NLL 1.09249
wandb:                  tuning_feature_17_MSE 1.26664
wandb:              tuning_feature_17_reg_NLL 1.143
wandb:                  tuning_feature_18_MSE 1.7417
wandb:              tuning_feature_18_reg_NLL 1.12137
wandb:                  tuning_feature_19_MSE 0.60962
wandb:              tuning_feature_19_reg_NLL 0.63467
wandb:                   tuning_feature_1_MSE 0.74613
wandb:               tuning_feature_1_reg_NLL 0.3892
wandb:                  tuning_feature_20_MSE 0.63233
wandb:              tuning_feature_20_reg_NLL 0.58484
wandb:                  tuning_feature_21_MSE 0.5205
wandb:              tuning_feature_21_reg_NLL 0.52311
wandb:                  tuning_feature_22_MSE 12.90312
wandb:              tuning_feature_22_reg_NLL 3.01075
wandb:                  tuning_feature_23_MSE 6.43359
wandb:              tuning_feature_23_reg_NLL 2.19485
wandb:                  tuning_feature_24_MSE 16.67423
wandb:              tuning_feature_24_reg_NLL 1.61584
wandb:                   tuning_feature_2_MSE 2.04683
wandb:               tuning_feature_2_reg_NLL 0.47843
wandb:                   tuning_feature_3_MSE 2.1637
wandb:               tuning_feature_3_reg_NLL 0.27896
wandb:                   tuning_feature_4_MSE 1.89897
wandb:               tuning_feature_4_reg_NLL 0.21842
wandb:                   tuning_feature_5_MSE 0.69948
wandb:               tuning_feature_5_reg_NLL 0.02556
wandb:                   tuning_feature_6_MSE 1.08728
wandb:               tuning_feature_6_reg_NLL 1.04839
wandb:                   tuning_feature_7_MSE 1.68324
wandb:               tuning_feature_7_reg_NLL 1.30128
wandb:                   tuning_feature_8_MSE 1.53253
wandb:               tuning_feature_8_reg_NLL 1.20431
wandb:                   tuning_feature_9_MSE 1.62836
wandb:               tuning_feature_9_reg_NLL 1.21985
wandb:                            tuning_loss 29.81934
wandb: 
wandb: üöÄ View run generative_event_stream_transformer at: https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/8v0c6657
wandb: Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_143312-8v0c6657/logs

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
             Test metric                           DataLoader 0
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
           held_out_TTE_MSE                        40754.171875
          held_out_TTE_MSLE                     8.467188835144043
         held_out_TTE_reg_NLL                   5.431624889373779
     held_out_event_label_cls_NLL              0.17786695063114166
 held_out_event_label_macro_accuracy            0.9505441188812256
 held_out_event_label_micro_accuracy            0.9505441784858704
 held_out_event_label_weighted_AUROC            0.8867337107658386
held_out_event_label_weighted_accuracy          0.8545117378234863
     held_out_event_type_cls_NLL               0.010219057090580463
  held_out_event_type_macro_accuracy                   0.0
  held_out_event_type_micro_accuracy                   0.0
  held_out_event_type_weighted_AUROC                   0.0
held_out_event_type_weighted_accuracy                  0.0
        held_out_feature_0_MSE                  1.203528881072998
      held_out_feature_0_reg_NLL               -0.3890053629875183
       held_out_feature_10_MSE                  1.5509443283081055
     held_out_feature_10_reg_NLL                1.301924467086792
       held_out_feature_11_MSE                  2.4722635746002197
     held_out_feature_11_reg_NLL                1.6054134368896484
       held_out_feature_12_MSE                  2.3092238903045654
     held_out_feature_12_reg_NLL                1.9392579793930054
       held_out_feature_13_MSE                  3.1664702892303467
     held_out_feature_13_reg_NLL                2.2092814445495605
       held_out_feature_14_MSE                  2.728311061859131
     held_out_feature_14_reg_NLL                0.9324418902397156
       held_out_feature_15_MSE                  1.4957687854766846
     held_out_feature_15_reg_NLL                1.320776343345642
       held_out_feature_16_MSE                  1.2655044794082642
     held_out_feature_16_reg_NLL                1.2353341579437256
       held_out_feature_17_MSE                   1.40292489528656
     held_out_feature_17_reg_NLL                1.2662923336029053
       held_out_feature_18_MSE                  2.250539779663086
     held_out_feature_18_reg_NLL                1.4170608520507812
       held_out_feature_19_MSE                  1.0491834878921509
     held_out_feature_19_reg_NLL                0.8465152382850647
        held_out_feature_1_MSE                  1.9661846160888672
      held_out_feature_1_reg_NLL               0.04970837011933327
       held_out_feature_20_MSE                  1.187902808189392
     held_out_feature_20_reg_NLL                0.8525314927101135
       held_out_feature_21_MSE                  0.9783432483673096
     held_out_feature_21_reg_NLL                0.8396333456039429
       held_out_feature_22_MSE                  5.262382984161377
     held_out_feature_22_reg_NLL                1.7339750528335571
       held_out_feature_23_MSE                  1.779457449913025
     held_out_feature_23_reg_NLL                1.3827300071716309
       held_out_feature_24_MSE                  1.9284236431121826
     held_out_feature_24_reg_NLL                0.7173925638198853
        held_out_feature_2_MSE                  2.6176905632019043
      held_out_feature_2_reg_NLL                1.5472447872161865
        held_out_feature_3_MSE                  1.707092523574829
      held_out_feature_3_reg_NLL                0.8725401163101196
        held_out_feature_4_MSE                  2.206341505050659
      held_out_feature_4_reg_NLL                1.4845683574676514
        held_out_feature_5_MSE                  1.9978073835372925
      held_out_feature_5_reg_NLL                4.802447319030762
        held_out_feature_6_MSE                  1.0292015075683594
      held_out_feature_6_reg_NLL                0.9294302463531494
        held_out_feature_7_MSE                  1.783318042755127
      held_out_feature_7_reg_NLL                1.3396854400634766
        held_out_feature_8_MSE                  1.7483559846878052
      held_out_feature_8_reg_NLL                1.2808122634887695
        held_out_feature_9_MSE                   1.87693452835083
      held_out_feature_9_reg_NLL                 1.32294499874115
            held_out_loss                       38.501461029052734
              task_AUROC                      0.00019531250291038305
            task_accuracy                       0.999804675579071
              task_loss                        0.040813371539115906
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Saving final metrics...
2025-04-10 14:34:02,663 - wandb.wandb_agent - INFO - Cleaning up finished run: 8v0c6657
[2025-04-10 14:34:02,663][wandb.wandb_agent][INFO] - Cleaning up finished run: 8v0c6657
2025-04-10 14:34:03,391 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:34:03,391][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:34:03,391 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.2160601000558467
	config.input_dropout: 0.022438785131736805
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.38266578175714655
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: cls
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 12
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.091317526698258
	optimization_config.init_lr: 7.81087942536352e-06
	optimization_config.lr_decay_power: 0.6118751766890639
	optimization_config.lr_frac_warmup_steps: 9.404909572458446e-06
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.009581313101110664
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:34:03,391][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.2160601000558467
	config.input_dropout: 0.022438785131736805
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.38266578175714655
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: cls
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 12
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.091317526698258
	optimization_config.init_lr: 7.81087942536352e-06
	optimization_config.lr_decay_power: 0.6118751766890639
	optimization_config.lr_frac_warmup_steps: 9.404909572458446e-06
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.009581313101110664
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:34:03,403 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.2160601000558467 config.input_dropout=0.022438785131736805 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.38266578175714655 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=cls data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=12 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.091317526698258 optimization_config.init_lr=7.81087942536352e-06 optimization_config.lr_decay_power=0.6118751766890639 optimization_config.lr_frac_warmup_steps=9.404909572458446e-06 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.009581313101110664 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:34:03,403][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.2160601000558467 config.input_dropout=0.022438785131736805 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.38266578175714655 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=cls data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=12 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.091317526698258 optimization_config.init_lr=7.81087942536352e-06 optimization_config.lr_decay_power=0.6118751766890639 optimization_config.lr_frac_warmup_steps=9.404909572458446e-06 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.009581313101110664 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1
2025-04-10 14:34:08,415 - wandb.wandb_agent - INFO - Running runs: ['metkhdnh']
[2025-04-10 14:34:08,415][wandb.wandb_agent][INFO] - Running runs: ['metkhdnh']
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_143410-metkhdnh
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/metkhdnh
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.2160601000558467
Overwriting input_dropout in config from 0.4494236115512016 to 0.022438785131736805
Overwriting resid_dropout in config from 0.4939188761966135 to 0.38266578175714655
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'cls', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.2160601000558467
Overwriting input_dropout in config from 0.4494236115512016 to 0.022438785131736805
Overwriting resid_dropout in config from 0.4939188761966135 to 0.38266578175714655
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'cls', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.60it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/7 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] /home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.
  warnings.warn(*args, **kwargs)

Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00<00:03,  1.85it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00<00:03,  1.85it/s, v_num=hdnh]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:01,  2.64it/s, v_num=hdnh]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:01,  2.63it/s, v_num=hdnh]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:01,  3.05it/s, v_num=hdnh]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:01,  3.05it/s, v_num=hdnh]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:00,  3.34it/s, v_num=hdnh]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:00,  3.34it/s, v_num=hdnh]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.54it/s, v_num=hdnh]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.53it/s, v_num=hdnh]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.67it/s, v_num=hdnh]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.67it/s, v_num=hdnh]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  3.77it/s, v_num=hdnh]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  3.77it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.42it/s][A

                                                                      [A
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.79it/s, v_num=hdnh]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.78it/s, v_num=hdnh]
Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s, v_num=hdnh]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s, v_num=hdnh]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.16it/s, v_num=hdnh]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.16it/s, v_num=hdnh]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.61it/s, v_num=hdnh]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.61it/s, v_num=hdnh]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.92it/s, v_num=hdnh]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.92it/s, v_num=hdnh]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.30it/s, v_num=hdnh]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.30it/s, v_num=hdnh]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.43it/s, v_num=hdnh]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.43it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.76it/s][A

                                                                      [A
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.62it/s, v_num=hdnh]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.62it/s, v_num=hdnh]
Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.39it/s, v_num=hdnh]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.39it/s, v_num=hdnh]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.11it/s, v_num=hdnh]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.11it/s, v_num=hdnh]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.85it/s, v_num=hdnh]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.85it/s, v_num=hdnh]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.08it/s, v_num=hdnh]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.08it/s, v_num=hdnh]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.23it/s, v_num=hdnh]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.23it/s, v_num=hdnh]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.37it/s, v_num=hdnh]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.36it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.24it/s][A

                                                                      [A
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.56it/s, v_num=hdnh]
Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.38it/s, v_num=hdnh]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.37it/s, v_num=hdnh]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.55it/s, v_num=hdnh]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.55it/s, v_num=hdnh]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.85it/s, v_num=hdnh]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.85it/s, v_num=hdnh]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.06it/s, v_num=hdnh]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.06it/s, v_num=hdnh]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.23it/s, v_num=hdnh]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.23it/s, v_num=hdnh]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.36it/s, v_num=hdnh]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.35it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.24it/s][A

                                                                      [A
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.58it/s, v_num=hdnh]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s, v_num=hdnh]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s, v_num=hdnh]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.19it/s, v_num=hdnh]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.19it/s, v_num=hdnh]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.65it/s, v_num=hdnh]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.65it/s, v_num=hdnh]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.94it/s, v_num=hdnh]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.94it/s, v_num=hdnh]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.26it/s, v_num=hdnh]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.26it/s, v_num=hdnh]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.38it/s, v_num=hdnh]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.38it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.70it/s][A

                                                                      [A
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.56it/s, v_num=hdnh]
Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 5:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 5:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 5:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.04it/s, v_num=hdnh]
Epoch 5:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.04it/s, v_num=hdnh]
Epoch 5:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.50it/s, v_num=hdnh]
Epoch 5:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.50it/s, v_num=hdnh]
Epoch 5:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.81it/s, v_num=hdnh]
Epoch 5:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.81it/s, v_num=hdnh]
Epoch 5:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.03it/s, v_num=hdnh]
Epoch 5:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.03it/s, v_num=hdnh]
Epoch 5:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.20it/s, v_num=hdnh]
Epoch 5:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.20it/s, v_num=hdnh]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.33it/s, v_num=hdnh]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.33it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.50it/s][A

                                                                      [A
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.53it/s, v_num=hdnh]
Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 6:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.28it/s, v_num=hdnh]
Epoch 6:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.28it/s, v_num=hdnh]
Epoch 6:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.98it/s, v_num=hdnh]
Epoch 6:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.98it/s, v_num=hdnh]
Epoch 6:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.43it/s, v_num=hdnh]
Epoch 6:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.43it/s, v_num=hdnh]
Epoch 6:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.74it/s, v_num=hdnh]
Epoch 6:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.74it/s, v_num=hdnh]
Epoch 6:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 6:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 6:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 6:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.12it/s, v_num=hdnh]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.22it/s][A

                                                                      [A
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.50it/s, v_num=hdnh]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.50it/s, v_num=hdnh]
Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 7:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s, v_num=hdnh]
Epoch 7:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s, v_num=hdnh]
Epoch 7:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.17it/s, v_num=hdnh]
Epoch 7:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.17it/s, v_num=hdnh]
Epoch 7:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.61it/s, v_num=hdnh]
Epoch 7:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.61it/s, v_num=hdnh]
Epoch 7:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.92it/s, v_num=hdnh]
Epoch 7:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.92it/s, v_num=hdnh]
Epoch 7:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.05it/s, v_num=hdnh]
Epoch 7:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.05it/s, v_num=hdnh]
Epoch 7:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.20it/s, v_num=hdnh]
Epoch 7:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.20it/s, v_num=hdnh]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.34it/s, v_num=hdnh]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.34it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.36it/s][A

                                                                      [A
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.55it/s, v_num=hdnh]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 8:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 8:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 8:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.01it/s, v_num=hdnh]
Epoch 8:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.01it/s, v_num=hdnh]
Epoch 8:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.45it/s, v_num=hdnh]
Epoch 8:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.44it/s, v_num=hdnh]
Epoch 8:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.76it/s, v_num=hdnh]
Epoch 8:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 8:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 8:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 8:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 8:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.27it/s, v_num=hdnh]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.10it/s][A

                                                                      [A
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 9:  14%|‚ñà‚ñç        | 1/7 [00:00<00:05,  1.19it/s, v_num=hdnh]
Epoch 9:  14%|‚ñà‚ñç        | 1/7 [00:00<00:05,  1.19it/s, v_num=hdnh]
Epoch 9:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.89it/s, v_num=hdnh]
Epoch 9:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.89it/s, v_num=hdnh]
Epoch 9:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.31it/s, v_num=hdnh]
Epoch 9:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.31it/s, v_num=hdnh]
Epoch 9:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.62it/s, v_num=hdnh]
Epoch 9:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.62it/s, v_num=hdnh]
Epoch 9:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.85it/s, v_num=hdnh]
Epoch 9:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.85it/s, v_num=hdnh]
Epoch 9:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.02it/s, v_num=hdnh]
Epoch 9:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.02it/s, v_num=hdnh]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.16it/s, v_num=hdnh]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.16it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.55it/s][A

                                                                      [A
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.45it/s, v_num=hdnh]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.45it/s, v_num=hdnh]
Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 10:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.38it/s, v_num=hdnh]
Epoch 10:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.38it/s, v_num=hdnh]
Epoch 10:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.01it/s, v_num=hdnh]
Epoch 10:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.01it/s, v_num=hdnh]
Epoch 10:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.45it/s, v_num=hdnh]
Epoch 10:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.45it/s, v_num=hdnh]
Epoch 10:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 10:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 10:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.99it/s, v_num=hdnh]
Epoch 10:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.99it/s, v_num=hdnh]
Epoch 10:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.16it/s, v_num=hdnh]
Epoch 10:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.16it/s, v_num=hdnh]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.29it/s, v_num=hdnh]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.29it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.19it/s][A

                                                                      [A
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 11:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.24it/s, v_num=hdnh]
Epoch 11:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.24it/s, v_num=hdnh]
Epoch 11:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.94it/s, v_num=hdnh]
Epoch 11:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.94it/s, v_num=hdnh]
Epoch 11:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 11:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 11:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.72it/s, v_num=hdnh]
Epoch 11:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.72it/s, v_num=hdnh]
Epoch 11:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.95it/s, v_num=hdnh]
Epoch 11:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.95it/s, v_num=hdnh]
Epoch 11:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.12it/s, v_num=hdnh]
Epoch 11:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.12it/s, v_num=hdnh]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.03it/s][A

                                                                      [A
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.50it/s, v_num=hdnh]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 12:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.28it/s, v_num=hdnh]
Epoch 12:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.28it/s, v_num=hdnh]
Epoch 12:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.99it/s, v_num=hdnh]
Epoch 12:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.99it/s, v_num=hdnh]
Epoch 12:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.42it/s, v_num=hdnh]
Epoch 12:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.42it/s, v_num=hdnh]
Epoch 12:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.73it/s, v_num=hdnh]
Epoch 12:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.73it/s, v_num=hdnh]
Epoch 12:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.94it/s, v_num=hdnh]
Epoch 12:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.93it/s, v_num=hdnh]
Epoch 12:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.05it/s, v_num=hdnh]
Epoch 12:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.05it/s, v_num=hdnh]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.20it/s, v_num=hdnh]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.20it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.41it/s][A

                                                                      [A
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.43it/s, v_num=hdnh]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.42it/s, v_num=hdnh]
Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 13:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.30it/s, v_num=hdnh]
Epoch 13:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.30it/s, v_num=hdnh]
Epoch 13:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.02it/s, v_num=hdnh]
Epoch 13:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.02it/s, v_num=hdnh]
Epoch 13:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.47it/s, v_num=hdnh]
Epoch 13:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.47it/s, v_num=hdnh]
Epoch 13:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.79it/s, v_num=hdnh]
Epoch 13:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.79it/s, v_num=hdnh]
Epoch 13:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.01it/s, v_num=hdnh]
Epoch 13:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.01it/s, v_num=hdnh]
Epoch 13:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.16it/s, v_num=hdnh]
Epoch 13:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.16it/s, v_num=hdnh]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.31it/s, v_num=hdnh]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.31it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.45it/s][A

                                                                      [A
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.53it/s, v_num=hdnh]
Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 14:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s, v_num=hdnh]
Epoch 14:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s, v_num=hdnh]
Epoch 14:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.19it/s, v_num=hdnh]
Epoch 14:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.19it/s, v_num=hdnh]
Epoch 14:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.61it/s, v_num=hdnh]
Epoch 14:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.61it/s, v_num=hdnh]
Epoch 14:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.88it/s, v_num=hdnh]
Epoch 14:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.88it/s, v_num=hdnh]
Epoch 14:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 14:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 14:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.25it/s, v_num=hdnh]
Epoch 14:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.24it/s, v_num=hdnh]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.37it/s, v_num=hdnh]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.37it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.56it/s][A

                                                                      [A
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.58it/s, v_num=hdnh]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.58it/s, v_num=hdnh]
Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 15:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.39it/s, v_num=hdnh]
Epoch 15:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.39it/s, v_num=hdnh]
Epoch 15:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.11it/s, v_num=hdnh]
Epoch 15:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.11it/s, v_num=hdnh]
Epoch 15:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.53it/s, v_num=hdnh]
Epoch 15:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.53it/s, v_num=hdnh]
Epoch 15:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.82it/s, v_num=hdnh]
Epoch 15:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.82it/s, v_num=hdnh]
Epoch 15:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.02it/s, v_num=hdnh]
Epoch 15:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.02it/s, v_num=hdnh]
Epoch 15:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.17it/s, v_num=hdnh]
Epoch 15:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.17it/s, v_num=hdnh]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.31it/s, v_num=hdnh]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.31it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.32it/s][A

                                                                      [A
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.55it/s, v_num=hdnh]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 16:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s, v_num=hdnh]
Epoch 16:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s, v_num=hdnh]
Epoch 16:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.21it/s, v_num=hdnh]
Epoch 16:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.21it/s, v_num=hdnh]
Epoch 16:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.63it/s, v_num=hdnh]
Epoch 16:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.63it/s, v_num=hdnh]
Epoch 16:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.93it/s, v_num=hdnh]
Epoch 16:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.93it/s, v_num=hdnh]
Epoch 16:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 16:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 16:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.30it/s, v_num=hdnh]
Epoch 16:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.30it/s, v_num=hdnh]
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.42it/s, v_num=hdnh]
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.42it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s][A

                                                                      [A
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.56it/s, v_num=hdnh]
Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 17:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 17:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.31it/s, v_num=hdnh]
Epoch 17:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.03it/s, v_num=hdnh]
Epoch 17:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.03it/s, v_num=hdnh]
Epoch 17:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.48it/s, v_num=hdnh]
Epoch 17:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.48it/s, v_num=hdnh]
Epoch 17:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.78it/s, v_num=hdnh]
Epoch 17:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.78it/s, v_num=hdnh]
Epoch 17:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.00it/s, v_num=hdnh]
Epoch 17:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.00it/s, v_num=hdnh]
Epoch 17:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.17it/s, v_num=hdnh]
Epoch 17:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.17it/s, v_num=hdnh]
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.30it/s, v_num=hdnh]
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.30it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.35it/s][A

                                                                      [A
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 18:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 18:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 18:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  2.00it/s, v_num=hdnh]
Epoch 18:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  2.00it/s, v_num=hdnh]
Epoch 18:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.46it/s, v_num=hdnh]
Epoch 18:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.46it/s, v_num=hdnh]
Epoch 18:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.78it/s, v_num=hdnh]
Epoch 18:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.78it/s, v_num=hdnh]
Epoch 18:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.01it/s, v_num=hdnh]
Epoch 18:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.01it/s, v_num=hdnh]
Epoch 18:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.18it/s, v_num=hdnh]
Epoch 18:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.18it/s, v_num=hdnh]
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.31it/s, v_num=hdnh]
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.31it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.50it/s][A

                                                                      [A
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.55it/s, v_num=hdnh]
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 19:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.30it/s, v_num=hdnh]
Epoch 19:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 19:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.95it/s, v_num=hdnh]
Epoch 19:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.95it/s, v_num=hdnh]
Epoch 19:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 19:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 19:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.71it/s, v_num=hdnh]
Epoch 19:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.71it/s, v_num=hdnh]
Epoch 19:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.94it/s, v_num=hdnh]
Epoch 19:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.94it/s, v_num=hdnh]
Epoch 19:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.11it/s, v_num=hdnh]
Epoch 19:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.11it/s, v_num=hdnh]
Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.25it/s, v_num=hdnh]
Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.25it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.13it/s][A

                                                                      [A
Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.50it/s, v_num=hdnh]
Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 20:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.30it/s, v_num=hdnh]
Epoch 20:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 20:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  2.00it/s, v_num=hdnh]
Epoch 20:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  2.00it/s, v_num=hdnh]
Epoch 20:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.44it/s, v_num=hdnh]
Epoch 20:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.44it/s, v_num=hdnh]
Epoch 20:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.74it/s, v_num=hdnh]
Epoch 20:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.74it/s, v_num=hdnh]
Epoch 20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.97it/s, v_num=hdnh]
Epoch 20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.97it/s, v_num=hdnh]
Epoch 20:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 20:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.28it/s, v_num=hdnh]
Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.28it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.96it/s][A

                                                                      [A
Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 21:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.39it/s, v_num=hdnh]
Epoch 21:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.39it/s, v_num=hdnh]
Epoch 21:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.13it/s, v_num=hdnh]
Epoch 21:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.12it/s, v_num=hdnh]
Epoch 21:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 21:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 21:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.87it/s, v_num=hdnh]
Epoch 21:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.87it/s, v_num=hdnh]
Epoch 21:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 21:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 21:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.25it/s, v_num=hdnh]
Epoch 21:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.25it/s, v_num=hdnh]
Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.38it/s, v_num=hdnh]
Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.38it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.44it/s][A

                                                                      [A
Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.56it/s, v_num=hdnh]
Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 22:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.31it/s, v_num=hdnh]
Epoch 22:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.31it/s, v_num=hdnh]
Epoch 22:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.01it/s, v_num=hdnh]
Epoch 22:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.01it/s, v_num=hdnh]
Epoch 22:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 22:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 22:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.70it/s, v_num=hdnh]
Epoch 22:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.70it/s, v_num=hdnh]
Epoch 22:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.94it/s, v_num=hdnh]
Epoch 22:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.94it/s, v_num=hdnh]
Epoch 22:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 22:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.24it/s, v_num=hdnh]
Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.24it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.11it/s][A

                                                                      [A
Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.48it/s, v_num=hdnh]
Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.47it/s, v_num=hdnh]
Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 23:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.33it/s, v_num=hdnh]
Epoch 23:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 23:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.04it/s, v_num=hdnh]
Epoch 23:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.04it/s, v_num=hdnh]
Epoch 23:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.48it/s, v_num=hdnh]
Epoch 23:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.48it/s, v_num=hdnh]
Epoch 23:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.79it/s, v_num=hdnh]
Epoch 23:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.79it/s, v_num=hdnh]
Epoch 23:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.01it/s, v_num=hdnh]
Epoch 23:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.01it/s, v_num=hdnh]
Epoch 23:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.17it/s, v_num=hdnh]
Epoch 23:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.17it/s, v_num=hdnh]
Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.30it/s, v_num=hdnh]
Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.30it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.36it/s][A

                                                                      [A
Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.53it/s, v_num=hdnh]
Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 24:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.37it/s, v_num=hdnh]
Epoch 24:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.37it/s, v_num=hdnh]
Epoch 24:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 24:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 24:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 24:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.55it/s, v_num=hdnh]
Epoch 24:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.86it/s, v_num=hdnh]
Epoch 24:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.86it/s, v_num=hdnh]
Epoch 24:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.08it/s, v_num=hdnh]
Epoch 24:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.08it/s, v_num=hdnh]
Epoch 24:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.24it/s, v_num=hdnh]
Epoch 24:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.24it/s, v_num=hdnh]
Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.36it/s, v_num=hdnh]
Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.36it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.77it/s][A

                                                                      [A
Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 25:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.36it/s, v_num=hdnh]
Epoch 25:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.36it/s, v_num=hdnh]
Epoch 25:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 25:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 25:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 25:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 25:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.86it/s, v_num=hdnh]
Epoch 25:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.86it/s, v_num=hdnh]
Epoch 25:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 25:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 25:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.22it/s, v_num=hdnh]
Epoch 25:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.22it/s, v_num=hdnh]
Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.36it/s, v_num=hdnh]
Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.35it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.52it/s][A

                                                                      [A
Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.58it/s, v_num=hdnh]
Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 26:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.28it/s, v_num=hdnh]
Epoch 26:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.27it/s, v_num=hdnh]
Epoch 26:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.98it/s, v_num=hdnh]
Epoch 26:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.97it/s, v_num=hdnh]
Epoch 26:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.43it/s, v_num=hdnh]
Epoch 26:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.43it/s, v_num=hdnh]
Epoch 26:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.73it/s, v_num=hdnh]
Epoch 26:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.73it/s, v_num=hdnh]
Epoch 26:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 26:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 26:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 26:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]
Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.33it/s][A

                                                                      [A
Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 27:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.35it/s, v_num=hdnh]
Epoch 27:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.35it/s, v_num=hdnh]
Epoch 27:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.08it/s, v_num=hdnh]
Epoch 27:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.08it/s, v_num=hdnh]
Epoch 27:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.54it/s, v_num=hdnh]
Epoch 27:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.54it/s, v_num=hdnh]
Epoch 27:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.85it/s, v_num=hdnh]
Epoch 27:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.85it/s, v_num=hdnh]
Epoch 27:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 27:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 27:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.25it/s, v_num=hdnh]
Epoch 27:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.25it/s, v_num=hdnh]
Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.03it/s, v_num=hdnh]
Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.03it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.17it/s][A

                                                                      [A
Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.37it/s, v_num=hdnh]
Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.37it/s, v_num=hdnh]
Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 28:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.24it/s, v_num=hdnh]
Epoch 28:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.24it/s, v_num=hdnh]
Epoch 28:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.94it/s, v_num=hdnh]
Epoch 28:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.94it/s, v_num=hdnh]
Epoch 28:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.35it/s, v_num=hdnh]
Epoch 28:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.35it/s, v_num=hdnh]
Epoch 28:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.65it/s, v_num=hdnh]
Epoch 28:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.65it/s, v_num=hdnh]
Epoch 28:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.88it/s, v_num=hdnh]
Epoch 28:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.88it/s, v_num=hdnh]
Epoch 28:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.05it/s, v_num=hdnh]
Epoch 28:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.05it/s, v_num=hdnh]
Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.19it/s, v_num=hdnh]
Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.19it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.32it/s][A

                                                                      [A
Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.46it/s, v_num=hdnh]
Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.45it/s, v_num=hdnh]
Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 29:  14%|‚ñà‚ñç        | 1/7 [00:00<00:05,  1.16it/s, v_num=hdnh]
Epoch 29:  14%|‚ñà‚ñç        | 1/7 [00:00<00:05,  1.16it/s, v_num=hdnh]
Epoch 29:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.82it/s, v_num=hdnh]
Epoch 29:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.82it/s, v_num=hdnh]
Epoch 29:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.28it/s, v_num=hdnh]
Epoch 29:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.28it/s, v_num=hdnh]
Epoch 29:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.60it/s, v_num=hdnh]
Epoch 29:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.59it/s, v_num=hdnh]
Epoch 29:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.84it/s, v_num=hdnh]
Epoch 29:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.84it/s, v_num=hdnh]
Epoch 29:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.00it/s, v_num=hdnh]
Epoch 29:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.00it/s, v_num=hdnh]
Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.14it/s, v_num=hdnh]
Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.14it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.59it/s][A

                                                                      [A
Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.44it/s, v_num=hdnh]
Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.43it/s, v_num=hdnh]
Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 30:  14%|‚ñà‚ñç        | 1/7 [00:00<00:05,  1.16it/s, v_num=hdnh]
Epoch 30:  14%|‚ñà‚ñç        | 1/7 [00:00<00:05,  1.15it/s, v_num=hdnh]
Epoch 30:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.82it/s, v_num=hdnh]
Epoch 30:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.82it/s, v_num=hdnh]
Epoch 30:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.27it/s, v_num=hdnh]
Epoch 30:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.26it/s, v_num=hdnh]
Epoch 30:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.58it/s, v_num=hdnh]
Epoch 30:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.57it/s, v_num=hdnh]
Epoch 30:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.81it/s, v_num=hdnh]
Epoch 30:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.81it/s, v_num=hdnh]
Epoch 30:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.99it/s, v_num=hdnh]
Epoch 30:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.99it/s, v_num=hdnh]
Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.13it/s, v_num=hdnh]
Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.13it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.40it/s][A

                                                                      [A
Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.44it/s, v_num=hdnh]
Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.43it/s, v_num=hdnh]
Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 31:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.34it/s, v_num=hdnh]
Epoch 31:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.34it/s, v_num=hdnh]
Epoch 31:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.08it/s, v_num=hdnh]
Epoch 31:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.07it/s, v_num=hdnh]
Epoch 31:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.50it/s, v_num=hdnh]
Epoch 31:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.50it/s, v_num=hdnh]
Epoch 31:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 31:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 31:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.97it/s, v_num=hdnh]
Epoch 31:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.97it/s, v_num=hdnh]
Epoch 31:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 31:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]
Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.05it/s][A

                                                                      [A
Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.46it/s, v_num=hdnh]
Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.46it/s, v_num=hdnh]
Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 32:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.30it/s, v_num=hdnh]
Epoch 32:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.30it/s, v_num=hdnh]
Epoch 32:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.00it/s, v_num=hdnh]
Epoch 32:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.00it/s, v_num=hdnh]
Epoch 32:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.45it/s, v_num=hdnh]
Epoch 32:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.45it/s, v_num=hdnh]
Epoch 32:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 32:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 32:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.97it/s, v_num=hdnh]
Epoch 32:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.97it/s, v_num=hdnh]
Epoch 32:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 32:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.28it/s, v_num=hdnh]
Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.28it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.54it/s][A

                                                                      [A
Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.53it/s, v_num=hdnh]
Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 33:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s, v_num=hdnh]
Epoch 33:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s, v_num=hdnh]
Epoch 33:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.18it/s, v_num=hdnh]
Epoch 33:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.18it/s, v_num=hdnh]
Epoch 33:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.62it/s, v_num=hdnh]
Epoch 33:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.62it/s, v_num=hdnh]
Epoch 33:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.91it/s, v_num=hdnh]
Epoch 33:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.91it/s, v_num=hdnh]
Epoch 33:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 33:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.12it/s, v_num=hdnh]
Epoch 33:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.28it/s, v_num=hdnh]
Epoch 33:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.28it/s, v_num=hdnh]
Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.39it/s, v_num=hdnh]
Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.39it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.23it/s][A

                                                                      [A
Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.60it/s, v_num=hdnh]
Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.59it/s, v_num=hdnh]
Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 34:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 34:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 34:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.99it/s, v_num=hdnh]
Epoch 34:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.99it/s, v_num=hdnh]
Epoch 34:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.44it/s, v_num=hdnh]
Epoch 34:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.44it/s, v_num=hdnh]
Epoch 34:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 34:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 34:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.98it/s, v_num=hdnh]
Epoch 34:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.98it/s, v_num=hdnh]
Epoch 34:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 34:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]
Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.37it/s][A

                                                                      [A
Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.50it/s, v_num=hdnh]
Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 35:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.25it/s, v_num=hdnh]
Epoch 35:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.25it/s, v_num=hdnh]
Epoch 35:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.95it/s, v_num=hdnh]
Epoch 35:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.95it/s, v_num=hdnh]
Epoch 35:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 35:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 35:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.71it/s, v_num=hdnh]
Epoch 35:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.71it/s, v_num=hdnh]
Epoch 35:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.93it/s, v_num=hdnh]
Epoch 35:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.93it/s, v_num=hdnh]
Epoch 35:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.10it/s, v_num=hdnh]
Epoch 35:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.23it/s, v_num=hdnh]
Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.23it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.51it/s][A

                                                                      [A
Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.47it/s, v_num=hdnh]
Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.46it/s, v_num=hdnh]
Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 36:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 36:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 36:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.02it/s, v_num=hdnh]
Epoch 36:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.02it/s, v_num=hdnh]
Epoch 36:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.46it/s, v_num=hdnh]
Epoch 36:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.46it/s, v_num=hdnh]
Epoch 36:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.76it/s, v_num=hdnh]
Epoch 36:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.76it/s, v_num=hdnh]
Epoch 36:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.98it/s, v_num=hdnh]
Epoch 36:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.97it/s, v_num=hdnh]
Epoch 36:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 36:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.29it/s, v_num=hdnh]
Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.29it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.48it/s][A

                                                                      [A
Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 37:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 37:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.31it/s, v_num=hdnh]
Epoch 37:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.96it/s, v_num=hdnh]
Epoch 37:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.96it/s, v_num=hdnh]
Epoch 37:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.41it/s, v_num=hdnh]
Epoch 37:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.41it/s, v_num=hdnh]
Epoch 37:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.72it/s, v_num=hdnh]
Epoch 37:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.72it/s, v_num=hdnh]
Epoch 37:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.92it/s, v_num=hdnh]
Epoch 37:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.92it/s, v_num=hdnh]
Epoch 37:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 37:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.24it/s, v_num=hdnh]
Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.23it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.00it/s][A

                                                                      [A
Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.48it/s, v_num=hdnh]
Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.47it/s, v_num=hdnh]
Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 38:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.39it/s, v_num=hdnh]
Epoch 38:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.39it/s, v_num=hdnh]
Epoch 38:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 38:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 38:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.55it/s, v_num=hdnh]
Epoch 38:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.55it/s, v_num=hdnh]
Epoch 38:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.85it/s, v_num=hdnh]
Epoch 38:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.85it/s, v_num=hdnh]
Epoch 38:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 38:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 38:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.23it/s, v_num=hdnh]
Epoch 38:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.23it/s, v_num=hdnh]
Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.35it/s, v_num=hdnh]
Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.35it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.22it/s][A

                                                                      [A
Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.56it/s, v_num=hdnh]
Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.55it/s, v_num=hdnh]
Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 39:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.24it/s, v_num=hdnh]
Epoch 39:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.24it/s, v_num=hdnh]
Epoch 39:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.92it/s, v_num=hdnh]
Epoch 39:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.92it/s, v_num=hdnh]
Epoch 39:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.35it/s, v_num=hdnh]
Epoch 39:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.35it/s, v_num=hdnh]
Epoch 39:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.66it/s, v_num=hdnh]
Epoch 39:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.66it/s, v_num=hdnh]
Epoch 39:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.89it/s, v_num=hdnh]
Epoch 39:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.89it/s, v_num=hdnh]
Epoch 39:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.06it/s, v_num=hdnh]
Epoch 39:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.06it/s, v_num=hdnh]
Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.19it/s, v_num=hdnh]
Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.19it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.15it/s][A

                                                                      [A
Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.47it/s, v_num=hdnh]
Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.46it/s, v_num=hdnh]
Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 40:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 40:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 40:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.95it/s, v_num=hdnh]
Epoch 40:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.95it/s, v_num=hdnh]
Epoch 40:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.41it/s, v_num=hdnh]
Epoch 40:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.41it/s, v_num=hdnh]
Epoch 40:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.73it/s, v_num=hdnh]
Epoch 40:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.73it/s, v_num=hdnh]
Epoch 40:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 40:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 40:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.12it/s, v_num=hdnh]
Epoch 40:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.12it/s, v_num=hdnh]
Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.24it/s, v_num=hdnh]
Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.24it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.64it/s][A

                                                                      [A
Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 41:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.38it/s, v_num=hdnh]
Epoch 41:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.38it/s, v_num=hdnh]
Epoch 41:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.08it/s, v_num=hdnh]
Epoch 41:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.08it/s, v_num=hdnh]
Epoch 41:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.50it/s, v_num=hdnh]
Epoch 41:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.50it/s, v_num=hdnh]
Epoch 41:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.81it/s, v_num=hdnh]
Epoch 41:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.81it/s, v_num=hdnh]
Epoch 41:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.03it/s, v_num=hdnh]
Epoch 41:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.03it/s, v_num=hdnh]
Epoch 41:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.20it/s, v_num=hdnh]
Epoch 41:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.20it/s, v_num=hdnh]
Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.33it/s, v_num=hdnh]
Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.33it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.68it/s][A

                                                                      [A
Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.58it/s, v_num=hdnh]
Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 42:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s, v_num=hdnh]
Epoch 42:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s, v_num=hdnh]
Epoch 42:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.18it/s, v_num=hdnh]
Epoch 42:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.18it/s, v_num=hdnh]
Epoch 42:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.63it/s, v_num=hdnh]
Epoch 42:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.63it/s, v_num=hdnh]
Epoch 42:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.93it/s, v_num=hdnh]
Epoch 42:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.93it/s, v_num=hdnh]
Epoch 42:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 42:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 42:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.30it/s, v_num=hdnh]
Epoch 42:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.30it/s, v_num=hdnh]
Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.42it/s, v_num=hdnh]
Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.42it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.48it/s][A

                                                                      [A
Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.60it/s, v_num=hdnh]
Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.59it/s, v_num=hdnh]
Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 43:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.38it/s, v_num=hdnh]
Epoch 43:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.38it/s, v_num=hdnh]
Epoch 43:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.12it/s, v_num=hdnh]
Epoch 43:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.12it/s, v_num=hdnh]
Epoch 43:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.58it/s, v_num=hdnh]
Epoch 43:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.58it/s, v_num=hdnh]
Epoch 43:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.90it/s, v_num=hdnh]
Epoch 43:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.90it/s, v_num=hdnh]
Epoch 43:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.10it/s, v_num=hdnh]
Epoch 43:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.10it/s, v_num=hdnh]
Epoch 43:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.26it/s, v_num=hdnh]
Epoch 43:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.26it/s, v_num=hdnh]
Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.40it/s, v_num=hdnh]
Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.40it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.06it/s][A

                                                                      [A
Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.60it/s, v_num=hdnh]
Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.59it/s, v_num=hdnh]
Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 44:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.28it/s, v_num=hdnh]
Epoch 44:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.28it/s, v_num=hdnh]
Epoch 44:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.99it/s, v_num=hdnh]
Epoch 44:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.99it/s, v_num=hdnh]
Epoch 44:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.44it/s, v_num=hdnh]
Epoch 44:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.44it/s, v_num=hdnh]
Epoch 44:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 44:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 44:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.98it/s, v_num=hdnh]
Epoch 44:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.98it/s, v_num=hdnh]
Epoch 44:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 44:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.29it/s, v_num=hdnh]
Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.29it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.51it/s][A

                                                                      [A
Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.53it/s, v_num=hdnh]
Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.53it/s, v_num=hdnh]
Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 45:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.37it/s, v_num=hdnh]
Epoch 45:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.37it/s, v_num=hdnh]
Epoch 45:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 45:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.09it/s, v_num=hdnh]
Epoch 45:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.53it/s, v_num=hdnh]
Epoch 45:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.53it/s, v_num=hdnh]
Epoch 45:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.83it/s, v_num=hdnh]
Epoch 45:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.83it/s, v_num=hdnh]
Epoch 45:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.05it/s, v_num=hdnh]
Epoch 45:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.05it/s, v_num=hdnh]
Epoch 45:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.22it/s, v_num=hdnh]
Epoch 45:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.22it/s, v_num=hdnh]
Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.34it/s, v_num=hdnh]
Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.34it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.10it/s][A

                                                                      [A
Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 46:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.26it/s, v_num=hdnh]
Epoch 46:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.26it/s, v_num=hdnh]
Epoch 46:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.90it/s, v_num=hdnh]
Epoch 46:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.90it/s, v_num=hdnh]
Epoch 46:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.33it/s, v_num=hdnh]
Epoch 46:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.33it/s, v_num=hdnh]
Epoch 46:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.65it/s, v_num=hdnh]
Epoch 46:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.65it/s, v_num=hdnh]
Epoch 46:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.89it/s, v_num=hdnh]
Epoch 46:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.89it/s, v_num=hdnh]
Epoch 46:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 46:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.21it/s, v_num=hdnh]
Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.21it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.57it/s][A

                                                                      [A
Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.48it/s, v_num=hdnh]
Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 47:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.23it/s, v_num=hdnh]
Epoch 47:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.23it/s, v_num=hdnh]
Epoch 47:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.93it/s, v_num=hdnh]
Epoch 47:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.92it/s, v_num=hdnh]
Epoch 47:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.37it/s, v_num=hdnh]
Epoch 47:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.37it/s, v_num=hdnh]
Epoch 47:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.68it/s, v_num=hdnh]
Epoch 47:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.67it/s, v_num=hdnh]
Epoch 47:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.91it/s, v_num=hdnh]
Epoch 47:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.91it/s, v_num=hdnh]
Epoch 47:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 47:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.22it/s, v_num=hdnh]
Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.22it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.31it/s][A

                                                                      [A
Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 48:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.34it/s, v_num=hdnh]
Epoch 48:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.34it/s, v_num=hdnh]
Epoch 48:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.06it/s, v_num=hdnh]
Epoch 48:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.06it/s, v_num=hdnh]
Epoch 48:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.50it/s, v_num=hdnh]
Epoch 48:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.50it/s, v_num=hdnh]
Epoch 48:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.80it/s, v_num=hdnh]
Epoch 48:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.80it/s, v_num=hdnh]
Epoch 48:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.02it/s, v_num=hdnh]
Epoch 48:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.02it/s, v_num=hdnh]
Epoch 48:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.17it/s, v_num=hdnh]
Epoch 48:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.17it/s, v_num=hdnh]
Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.29it/s, v_num=hdnh]
Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.29it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.18it/s][A

                                                                      [A
Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 49:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 49:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 49:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.03it/s, v_num=hdnh]
Epoch 49:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.02it/s, v_num=hdnh]
Epoch 49:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.44it/s, v_num=hdnh]
Epoch 49:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.44it/s, v_num=hdnh]
Epoch 49:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.70it/s, v_num=hdnh]
Epoch 49:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.70it/s, v_num=hdnh]
Epoch 49:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.90it/s, v_num=hdnh]
Epoch 49:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.90it/s, v_num=hdnh]
Epoch 49:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 49:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.20it/s, v_num=hdnh]
Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.20it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.75it/s][A

                                                                      [A
Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.42it/s, v_num=hdnh]
Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.41it/s, v_num=hdnh]
Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 50:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.27it/s, v_num=hdnh]
Epoch 50:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.27it/s, v_num=hdnh]
Epoch 50:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.97it/s, v_num=hdnh]
Epoch 50:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.97it/s, v_num=hdnh]
Epoch 50:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 50:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 50:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.70it/s, v_num=hdnh]
Epoch 50:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.70it/s, v_num=hdnh]
Epoch 50:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.93it/s, v_num=hdnh]
Epoch 50:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.93it/s, v_num=hdnh]
Epoch 50:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.11it/s, v_num=hdnh]
Epoch 50:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.11it/s, v_num=hdnh]
Epoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.25it/s, v_num=hdnh]
Epoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.25it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.26it/s][A

                                                                      [A
Epoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 51:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s, v_num=hdnh]
Epoch 51:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s, v_num=hdnh]
Epoch 51:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.17it/s, v_num=hdnh]
Epoch 51:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.16it/s, v_num=hdnh]
Epoch 51:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.14it/s, v_num=hdnh]
Epoch 51:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.13it/s, v_num=hdnh]
Epoch 51:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.45it/s, v_num=hdnh]
Epoch 51:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.45it/s, v_num=hdnh]
Epoch 51:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.69it/s, v_num=hdnh]
Epoch 51:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.69it/s, v_num=hdnh]
Epoch 51:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.88it/s, v_num=hdnh]
Epoch 51:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.88it/s, v_num=hdnh]
Epoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.03it/s, v_num=hdnh]
Epoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.03it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.49it/s][A

                                                                      [A
Epoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.38it/s, v_num=hdnh]
Epoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.37it/s, v_num=hdnh]
Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 52:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.36it/s, v_num=hdnh]
Epoch 52:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.36it/s, v_num=hdnh]
Epoch 52:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.06it/s, v_num=hdnh]
Epoch 52:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.06it/s, v_num=hdnh]
Epoch 52:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.51it/s, v_num=hdnh]
Epoch 52:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.51it/s, v_num=hdnh]
Epoch 52:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.81it/s, v_num=hdnh]
Epoch 52:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.81it/s, v_num=hdnh]
Epoch 52:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.04it/s, v_num=hdnh]
Epoch 52:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.04it/s, v_num=hdnh]
Epoch 52:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.20it/s, v_num=hdnh]
Epoch 52:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.20it/s, v_num=hdnh]
Epoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.33it/s, v_num=hdnh]
Epoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.32it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.56it/s][A

                                                                      [A
Epoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.56it/s, v_num=hdnh]
Epoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.55it/s, v_num=hdnh]
Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 53:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.28it/s, v_num=hdnh]
Epoch 53:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.28it/s, v_num=hdnh]
Epoch 53:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.98it/s, v_num=hdnh]
Epoch 53:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.98it/s, v_num=hdnh]
Epoch 53:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.43it/s, v_num=hdnh]
Epoch 53:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.43it/s, v_num=hdnh]
Epoch 53:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.73it/s, v_num=hdnh]
Epoch 53:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.73it/s, v_num=hdnh]
Epoch 53:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.95it/s, v_num=hdnh]
Epoch 53:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.95it/s, v_num=hdnh]
Epoch 53:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.10it/s, v_num=hdnh]
Epoch 53:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.10it/s, v_num=hdnh]
Epoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.21it/s, v_num=hdnh]
Epoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.21it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.33it/s][A

                                                                      [A
Epoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.48it/s, v_num=hdnh]
Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 54:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.24it/s, v_num=hdnh]
Epoch 54:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.23it/s, v_num=hdnh]
Epoch 54:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.88it/s, v_num=hdnh]
Epoch 54:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.88it/s, v_num=hdnh]
Epoch 54:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.26it/s, v_num=hdnh]
Epoch 54:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.26it/s, v_num=hdnh]
Epoch 54:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 54:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 54:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.79it/s, v_num=hdnh]
Epoch 54:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.79it/s, v_num=hdnh]
Epoch 54:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.96it/s, v_num=hdnh]
Epoch 54:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.96it/s, v_num=hdnh]
Epoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.10it/s, v_num=hdnh]
Epoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.10it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.21it/s][A

                                                                      [A
Epoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.40it/s, v_num=hdnh]
Epoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.40it/s, v_num=hdnh]
Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 55:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 55:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 55:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.95it/s, v_num=hdnh]
Epoch 55:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.95it/s, v_num=hdnh]
Epoch 55:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.39it/s, v_num=hdnh]
Epoch 55:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.39it/s, v_num=hdnh]
Epoch 55:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.71it/s, v_num=hdnh]
Epoch 55:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.71it/s, v_num=hdnh]
Epoch 55:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.95it/s, v_num=hdnh]
Epoch 55:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.95it/s, v_num=hdnh]
Epoch 55:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 55:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.12it/s, v_num=hdnh]
Epoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]
Epoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.25it/s][A

                                                                      [A
Epoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 56:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.27it/s, v_num=hdnh]
Epoch 56:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.26it/s, v_num=hdnh]
Epoch 56:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.97it/s, v_num=hdnh]
Epoch 56:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.97it/s, v_num=hdnh]
Epoch 56:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.42it/s, v_num=hdnh]
Epoch 56:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.41it/s, v_num=hdnh]
Epoch 56:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.73it/s, v_num=hdnh]
Epoch 56:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.73it/s, v_num=hdnh]
Epoch 56:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 56:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 56:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.12it/s, v_num=hdnh]
Epoch 56:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.12it/s, v_num=hdnh]
Epoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]
Epoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.13it/s][A

                                                                      [A
Epoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.50it/s, v_num=hdnh]
Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 57:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.25it/s, v_num=hdnh]
Epoch 57:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.25it/s, v_num=hdnh]
Epoch 57:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.94it/s, v_num=hdnh]
Epoch 57:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.94it/s, v_num=hdnh]
Epoch 57:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 57:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.40it/s, v_num=hdnh]
Epoch 57:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.71it/s, v_num=hdnh]
Epoch 57:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.71it/s, v_num=hdnh]
Epoch 57:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.94it/s, v_num=hdnh]
Epoch 57:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.94it/s, v_num=hdnh]
Epoch 57:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.11it/s, v_num=hdnh]
Epoch 57:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.10it/s, v_num=hdnh]
Epoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.25it/s, v_num=hdnh]
Epoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.25it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.43it/s][A

                                                                      [A
Epoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.50it/s, v_num=hdnh]
Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 58:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.34it/s, v_num=hdnh]
Epoch 58:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.34it/s, v_num=hdnh]
Epoch 58:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.07it/s, v_num=hdnh]
Epoch 58:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.07it/s, v_num=hdnh]
Epoch 58:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.48it/s, v_num=hdnh]
Epoch 58:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.48it/s, v_num=hdnh]
Epoch 58:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.74it/s, v_num=hdnh]
Epoch 58:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.74it/s, v_num=hdnh]
Epoch 58:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.97it/s, v_num=hdnh]
Epoch 58:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.97it/s, v_num=hdnh]
Epoch 58:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 58:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.27it/s, v_num=hdnh]
Epoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.27it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.87it/s][A

                                                                      [A
Epoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.46it/s, v_num=hdnh]
Epoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.45it/s, v_num=hdnh]
Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 59:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 59:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 59:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.98it/s, v_num=hdnh]
Epoch 59:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.98it/s, v_num=hdnh]
Epoch 59:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.43it/s, v_num=hdnh]
Epoch 59:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.43it/s, v_num=hdnh]
Epoch 59:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.74it/s, v_num=hdnh]
Epoch 59:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.74it/s, v_num=hdnh]
Epoch 59:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 59:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 59:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 59:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.27it/s, v_num=hdnh]
Epoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.27it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.34it/s][A

                                                                      [A
Epoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 60:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.31it/s, v_num=hdnh]
Epoch 60:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.31it/s, v_num=hdnh]
Epoch 60:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.03it/s, v_num=hdnh]
Epoch 60:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.02it/s, v_num=hdnh]
Epoch 60:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.47it/s, v_num=hdnh]
Epoch 60:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.47it/s, v_num=hdnh]
Epoch 60:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.78it/s, v_num=hdnh]
Epoch 60:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.78it/s, v_num=hdnh]
Epoch 60:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.01it/s, v_num=hdnh]
Epoch 60:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.01it/s, v_num=hdnh]
Epoch 60:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.18it/s, v_num=hdnh]
Epoch 60:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.17it/s, v_num=hdnh]
Epoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.31it/s, v_num=hdnh]
Epoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.31it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.37it/s][A

                                                                      [A
Epoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 61:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.41it/s, v_num=hdnh]
Epoch 61:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.41it/s, v_num=hdnh]
Epoch 61:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.14it/s, v_num=hdnh]
Epoch 61:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.14it/s, v_num=hdnh]
Epoch 61:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.57it/s, v_num=hdnh]
Epoch 61:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 61:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.86it/s, v_num=hdnh]
Epoch 61:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.86it/s, v_num=hdnh]
Epoch 61:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 61:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 61:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.25it/s, v_num=hdnh]
Epoch 61:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.25it/s, v_num=hdnh]
Epoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.39it/s, v_num=hdnh]
Epoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.39it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.12it/s][A

                                                                      [A
Epoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.58it/s, v_num=hdnh]
Epoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 62:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.30it/s, v_num=hdnh]
Epoch 62:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 62:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.00it/s, v_num=hdnh]
Epoch 62:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  2.00it/s, v_num=hdnh]
Epoch 62:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.44it/s, v_num=hdnh]
Epoch 62:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.44it/s, v_num=hdnh]
Epoch 62:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 62:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.75it/s, v_num=hdnh]
Epoch 62:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 62:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.96it/s, v_num=hdnh]
Epoch 62:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 62:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.27it/s, v_num=hdnh]
Epoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.27it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.56it/s][A

                                                                      [A
Epoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.53it/s, v_num=hdnh]
Epoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 63:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.25it/s, v_num=hdnh]
Epoch 63:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.25it/s, v_num=hdnh]
Epoch 63:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.95it/s, v_num=hdnh]
Epoch 63:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.94it/s, v_num=hdnh]
Epoch 63:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.38it/s, v_num=hdnh]
Epoch 63:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.38it/s, v_num=hdnh]
Epoch 63:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.70it/s, v_num=hdnh]
Epoch 63:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.70it/s, v_num=hdnh]
Epoch 63:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.95it/s, v_num=hdnh]
Epoch 63:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.95it/s, v_num=hdnh]
Epoch 63:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 63:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]
Epoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.26it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.69it/s][A

                                                                      [A
Epoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.51it/s, v_num=hdnh]
Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 64:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 64:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.29it/s, v_num=hdnh]
Epoch 64:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.02it/s, v_num=hdnh]
Epoch 64:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.02it/s, v_num=hdnh]
Epoch 64:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.47it/s, v_num=hdnh]
Epoch 64:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.47it/s, v_num=hdnh]
Epoch 64:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.77it/s, v_num=hdnh]
Epoch 64:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.77it/s, v_num=hdnh]
Epoch 64:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.95it/s, v_num=hdnh]
Epoch 64:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.95it/s, v_num=hdnh]
Epoch 64:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 64:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.13it/s, v_num=hdnh]
Epoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.28it/s, v_num=hdnh]
Epoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.28it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.69it/s][A

                                                                      [A
Epoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.53it/s, v_num=hdnh]
Epoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 65:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s, v_num=hdnh]
Epoch 65:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s, v_num=hdnh]
Epoch 65:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 65:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 65:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.57it/s, v_num=hdnh]
Epoch 65:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.57it/s, v_num=hdnh]
Epoch 65:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.87it/s, v_num=hdnh]
Epoch 65:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.87it/s, v_num=hdnh]
Epoch 65:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.10it/s, v_num=hdnh]
Epoch 65:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 65:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.25it/s, v_num=hdnh]
Epoch 65:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.25it/s, v_num=hdnh]
Epoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.38it/s, v_num=hdnh]
Epoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.38it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.67it/s][A

                                                                      [A
Epoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.58it/s, v_num=hdnh]
Epoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 66:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.30it/s, v_num=hdnh]
Epoch 66:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.30it/s, v_num=hdnh]
Epoch 66:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.97it/s, v_num=hdnh]
Epoch 66:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.97it/s, v_num=hdnh]
Epoch 66:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.41it/s, v_num=hdnh]
Epoch 66:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.41it/s, v_num=hdnh]
Epoch 66:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.70it/s, v_num=hdnh]
Epoch 66:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.69it/s, v_num=hdnh]
Epoch 66:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.92it/s, v_num=hdnh]
Epoch 66:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.92it/s, v_num=hdnh]
Epoch 66:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.10it/s, v_num=hdnh]
Epoch 66:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.10it/s, v_num=hdnh]
Epoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.23it/s, v_num=hdnh]
Epoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.23it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.44it/s][A

                                                                      [A
Epoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.50it/s, v_num=hdnh]
Epoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.50it/s, v_num=hdnh]
Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 67:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.30it/s, v_num=hdnh]
Epoch 67:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.30it/s, v_num=hdnh]
Epoch 67:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.00it/s, v_num=hdnh]
Epoch 67:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.00it/s, v_num=hdnh]
Epoch 67:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.46it/s, v_num=hdnh]
Epoch 67:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.45it/s, v_num=hdnh]
Epoch 67:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.77it/s, v_num=hdnh]
Epoch 67:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.77it/s, v_num=hdnh]
Epoch 67:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.99it/s, v_num=hdnh]
Epoch 67:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.99it/s, v_num=hdnh]
Epoch 67:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 67:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.15it/s, v_num=hdnh]
Epoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.24it/s, v_num=hdnh]
Epoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.24it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.43it/s][A

                                                                      [A
Epoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.47it/s, v_num=hdnh]
Epoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.47it/s, v_num=hdnh]
Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 68:  14%|‚ñà‚ñç        | 1/7 [00:00<00:05,  1.19it/s, v_num=hdnh]
Epoch 68:  14%|‚ñà‚ñç        | 1/7 [00:00<00:05,  1.19it/s, v_num=hdnh]
Epoch 68:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.84it/s, v_num=hdnh]
Epoch 68:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.84it/s, v_num=hdnh]
Epoch 68:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.27it/s, v_num=hdnh]
Epoch 68:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.27it/s, v_num=hdnh]
Epoch 68:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.60it/s, v_num=hdnh]
Epoch 68:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.60it/s, v_num=hdnh]
Epoch 68:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.83it/s, v_num=hdnh]
Epoch 68:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.83it/s, v_num=hdnh]
Epoch 68:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.00it/s, v_num=hdnh]
Epoch 68:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.00it/s, v_num=hdnh]
Epoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.15it/s, v_num=hdnh]
Epoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.15it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.34it/s][A

                                                                      [A
Epoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.45it/s, v_num=hdnh]
Epoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.44it/s, v_num=hdnh]
Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 69:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.39it/s, v_num=hdnh]
Epoch 69:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.38it/s, v_num=hdnh]
Epoch 69:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.12it/s, v_num=hdnh]
Epoch 69:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.11it/s, v_num=hdnh]
Epoch 69:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 69:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 69:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.86it/s, v_num=hdnh]
Epoch 69:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.86it/s, v_num=hdnh]
Epoch 69:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.08it/s, v_num=hdnh]
Epoch 69:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.08it/s, v_num=hdnh]
Epoch 69:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.25it/s, v_num=hdnh]
Epoch 69:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.25it/s, v_num=hdnh]
Epoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.39it/s, v_num=hdnh]
Epoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.39it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.41it/s][A

                                                                      [A
Epoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.60it/s, v_num=hdnh]
Epoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.59it/s, v_num=hdnh]
Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 70:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.37it/s, v_num=hdnh]
Epoch 70:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.37it/s, v_num=hdnh]
Epoch 70:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 70:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.10it/s, v_num=hdnh]
Epoch 70:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.55it/s, v_num=hdnh]
Epoch 70:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.55it/s, v_num=hdnh]
Epoch 70:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.85it/s, v_num=hdnh]
Epoch 70:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.85it/s, v_num=hdnh]
Epoch 70:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 70:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.07it/s, v_num=hdnh]
Epoch 70:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.24it/s, v_num=hdnh]
Epoch 70:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.23it/s, v_num=hdnh]
Epoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.37it/s, v_num=hdnh]
Epoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.37it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.69it/s][A

                                                                      [A
Epoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.58it/s, v_num=hdnh]
Epoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 71:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.35it/s, v_num=hdnh]
Epoch 71:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.35it/s, v_num=hdnh]
Epoch 71:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.08it/s, v_num=hdnh]
Epoch 71:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.08it/s, v_num=hdnh]
Epoch 71:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.54it/s, v_num=hdnh]
Epoch 71:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.53it/s, v_num=hdnh]
Epoch 71:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.78it/s, v_num=hdnh]
Epoch 71:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.78it/s, v_num=hdnh]
Epoch 71:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.00it/s, v_num=hdnh]
Epoch 71:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.00it/s, v_num=hdnh]
Epoch 71:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.16it/s, v_num=hdnh]
Epoch 71:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.16it/s, v_num=hdnh]
Epoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.30it/s, v_num=hdnh]
Epoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.30it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.51it/s][A

                                                                      [A
Epoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.53it/s, v_num=hdnh]
Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 72:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.25it/s, v_num=hdnh]
Epoch 72:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.25it/s, v_num=hdnh]
Epoch 72:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.95it/s, v_num=hdnh]
Epoch 72:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.95it/s, v_num=hdnh]
Epoch 72:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.39it/s, v_num=hdnh]
Epoch 72:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.39it/s, v_num=hdnh]
Epoch 72:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.68it/s, v_num=hdnh]
Epoch 72:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.68it/s, v_num=hdnh]
Epoch 72:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.91it/s, v_num=hdnh]
Epoch 72:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.91it/s, v_num=hdnh]
Epoch 72:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.08it/s, v_num=hdnh]
Epoch 72:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.08it/s, v_num=hdnh]
Epoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.22it/s, v_num=hdnh]
Epoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.22it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.37it/s][A

                                                                      [A
Epoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.49it/s, v_num=hdnh]
Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 73:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.25it/s, v_num=hdnh]
Epoch 73:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.25it/s, v_num=hdnh]
Epoch 73:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.94it/s, v_num=hdnh]
Epoch 73:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.94it/s, v_num=hdnh]
Epoch 73:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.39it/s, v_num=hdnh]
Epoch 73:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.39it/s, v_num=hdnh]
Epoch 73:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.71it/s, v_num=hdnh]
Epoch 73:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.71it/s, v_num=hdnh]
Epoch 73:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.94it/s, v_num=hdnh]
Epoch 73:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.94it/s, v_num=hdnh]
Epoch 73:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.10it/s, v_num=hdnh]
Epoch 73:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.10it/s, v_num=hdnh]
Epoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.21it/s, v_num=hdnh]
Epoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.20it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.47it/s][A

                                                                      [A
Epoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.46it/s, v_num=hdnh]
Epoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.45it/s, v_num=hdnh]
Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 74:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s, v_num=hdnh]
Epoch 74:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s, v_num=hdnh]
Epoch 74:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.17it/s, v_num=hdnh]
Epoch 74:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.17it/s, v_num=hdnh]
Epoch 74:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.63it/s, v_num=hdnh]
Epoch 74:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.62it/s, v_num=hdnh]
Epoch 74:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.93it/s, v_num=hdnh]
Epoch 74:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.93it/s, v_num=hdnh]
Epoch 74:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 74:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.09it/s, v_num=hdnh]
Epoch 74:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.26it/s, v_num=hdnh]
Epoch 74:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.26it/s, v_num=hdnh]
Epoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.38it/s, v_num=hdnh]
Epoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.38it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.53it/s][A

                                                                      [A
Epoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.59it/s, v_num=hdnh]
Epoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.59it/s, v_num=hdnh]
Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 75:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 75:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 75:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.02it/s, v_num=hdnh]
Epoch 75:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.02it/s, v_num=hdnh]
Epoch 75:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.48it/s, v_num=hdnh]
Epoch 75:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.47it/s, v_num=hdnh]
Epoch 75:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.78it/s, v_num=hdnh]
Epoch 75:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.78it/s, v_num=hdnh]
Epoch 75:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.99it/s, v_num=hdnh]
Epoch 75:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.99it/s, v_num=hdnh]
Epoch 75:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.17it/s, v_num=hdnh]
Epoch 75:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.17it/s, v_num=hdnh]
Epoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.29it/s, v_num=hdnh]
Epoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.28it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.40it/s][A

                                                                      [A
Epoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.53it/s, v_num=hdnh]
Epoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.52it/s, v_num=hdnh]
Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 76:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.39it/s, v_num=hdnh]
Epoch 76:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.39it/s, v_num=hdnh]
Epoch 76:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.11it/s, v_num=hdnh]
Epoch 76:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.11it/s, v_num=hdnh]
Epoch 76:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 76:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.56it/s, v_num=hdnh]
Epoch 76:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.83it/s, v_num=hdnh]
Epoch 76:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.83it/s, v_num=hdnh]
Epoch 76:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.04it/s, v_num=hdnh]
Epoch 76:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.04it/s, v_num=hdnh]
Epoch 76:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.19it/s, v_num=hdnh]
Epoch 76:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.19it/s, v_num=hdnh]
Epoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.29it/s, v_num=hdnh]
Epoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.29it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s][A

                                                                      [A
Epoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.48it/s, v_num=hdnh]
Epoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.47it/s, v_num=hdnh]
Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 77:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.22it/s, v_num=hdnh]
Epoch 77:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.21it/s, v_num=hdnh]
Epoch 77:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.89it/s, v_num=hdnh]
Epoch 77:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.89it/s, v_num=hdnh]
Epoch 77:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.30it/s, v_num=hdnh]
Epoch 77:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.30it/s, v_num=hdnh]
Epoch 77:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.59it/s, v_num=hdnh]
Epoch 77:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.59it/s, v_num=hdnh]
Epoch 77:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.80it/s, v_num=hdnh]
Epoch 77:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.80it/s, v_num=hdnh]
Epoch 77:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.95it/s, v_num=hdnh]
Epoch 77:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.95it/s, v_num=hdnh]
Epoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.09it/s, v_num=hdnh]
Epoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.09it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.57it/s][A

                                                                      [A
Epoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.40it/s, v_num=hdnh]
Epoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.40it/s, v_num=hdnh]
Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 78:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.35it/s, v_num=hdnh]
Epoch 78:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.35it/s, v_num=hdnh]
Epoch 78:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.06it/s, v_num=hdnh]
Epoch 78:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.06it/s, v_num=hdnh]
Epoch 78:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.50it/s, v_num=hdnh]
Epoch 78:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.50it/s, v_num=hdnh]
Epoch 78:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.81it/s, v_num=hdnh]
Epoch 78:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.81it/s, v_num=hdnh]
Epoch 78:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.03it/s, v_num=hdnh]
Epoch 78:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.03it/s, v_num=hdnh]
Epoch 78:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.20it/s, v_num=hdnh]
Epoch 78:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.20it/s, v_num=hdnh]
Epoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.33it/s, v_num=hdnh]
Epoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.33it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.21it/s][A

                                                                      [A
Epoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.54it/s, v_num=hdnh]
Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 79:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.33it/s, v_num=hdnh]
Epoch 79:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.32it/s, v_num=hdnh]
Epoch 79:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.04it/s, v_num=hdnh]
Epoch 79:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.04it/s, v_num=hdnh]
Epoch 79:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.49it/s, v_num=hdnh]
Epoch 79:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.48it/s, v_num=hdnh]
Epoch 79:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.81it/s, v_num=hdnh]
Epoch 79:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.81it/s, v_num=hdnh]
Epoch 79:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.04it/s, v_num=hdnh]
Epoch 79:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.04it/s, v_num=hdnh]
Epoch 79:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.21it/s, v_num=hdnh]
Epoch 79:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.21it/s, v_num=hdnh]
Epoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.34it/s, v_num=hdnh]
Epoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.34it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.46it/s][A

                                                                      [A
Epoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.58it/s, v_num=hdnh]
Epoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=hdnh]
Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]        
Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=hdnh]
Epoch 80:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s, v_num=hdnh]
Epoch 80:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s, v_num=hdnh]
Epoch 80:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.15it/s, v_num=hdnh]
Epoch 80:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.15it/s, v_num=hdnh]
Epoch 80:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.59it/s, v_num=hdnh]
Epoch 80:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.59it/s, v_num=hdnh]
Epoch 80:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.92it/s, v_num=hdnh]
Epoch 80:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.92it/s, v_num=hdnh]
Epoch 80:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 80:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.14it/s, v_num=hdnh]
Epoch 80:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.29it/s, v_num=hdnh]
Epoch 80:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.29it/s, v_num=hdnh]
Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.43it/s, v_num=hdnh]
Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.43it/s, v_num=hdnh]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.54it/s][A

                                                                      [A
Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.60it/s, v_num=hdnh]
Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.59it/s, v_num=hdnh]
Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.50it/s, v_num=hdnh]Restoring states from the checkpoint path at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/eneryield_ft_sweep/metkhdnh/checkpoints/epoch=70-val_loss=0.00-best_model.ckpt
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Loaded model weights from the checkpoint at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/eneryield_ft_sweep/metkhdnh/checkpoints/epoch=70-val_loss=0.00-best_model.ckpt
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:216: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.

/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/finetune_weights
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/held_out_0.parquet
/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/finetune_weights
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/held_out_0.parquet

Validation: |          | 0/? [00:00<?, ?it/s]
Validation:   0%|          | 0/1 [00:00<?, ?it/s]
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.72it/s]
Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.02it/s]Restoring states from the checkpoint path at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/eneryield_ft_sweep/metkhdnh/checkpoints/epoch=70-val_loss=0.00-best_model.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
Loaded model weights from the checkpoint at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/eneryield_ft_sweep/metkhdnh/checkpoints/epoch=70-val_loss=0.00-best_model.ckpt
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:216: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
          Validate metric                       DataLoader 0
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
             task_AUROC                    0.0007812500116415322
           task_accuracy                        0.9990234375
             task_loss                      0.14980405569076538
           tuning_TTE_MSE                       32284.828125
          tuning_TTE_MSLE                    6.6887969970703125
         tuning_TTE_reg_NLL                  5.549214839935303
     tuning_event_label_cls_NLL             0.16291148960590363
 tuning_event_label_macro_accuracy           0.9256404638290405
 tuning_event_label_micro_accuracy           0.9256405234336853
 tuning_event_label_weighted_AUROC           0.7777493000030518
tuning_event_label_weighted_accuracy         0.7329142689704895
     tuning_event_type_cls_NLL              0.009530010633170605
  tuning_event_type_macro_accuracy                  0.0
  tuning_event_type_micro_accuracy                  0.0
  tuning_event_type_weighted_AUROC                  0.0
tuning_event_type_weighted_accuracy                 0.0
        tuning_feature_0_MSE                0.14715929329395294
      tuning_feature_0_reg_NLL              -0.45214155316352844
       tuning_feature_10_MSE                 0.5846652984619141
     tuning_feature_10_reg_NLL               0.6943283081054688
       tuning_feature_11_MSE                 1.6288853883743286
     tuning_feature_11_reg_NLL               1.2702269554138184
       tuning_feature_12_MSE                 1.563703179359436
     tuning_feature_12_reg_NLL               1.1630198955535889
       tuning_feature_13_MSE                 2.2298595905303955
     tuning_feature_13_reg_NLL               1.440430760383606
       tuning_feature_14_MSE                 0.5994760990142822
     tuning_feature_14_reg_NLL               0.720487117767334
       tuning_feature_15_MSE                 1.2945833206176758
     tuning_feature_15_reg_NLL               1.2261385917663574
       tuning_feature_16_MSE                 1.0213450193405151
     tuning_feature_16_reg_NLL                1.11077880859375
       tuning_feature_17_MSE                 1.1385043859481812
     tuning_feature_17_reg_NLL               1.1493875980377197
       tuning_feature_18_MSE                 1.2052122354507446
     tuning_feature_18_reg_NLL               0.9657449126243591
       tuning_feature_19_MSE                 0.4874087870121002
     tuning_feature_19_reg_NLL               0.5285992622375488
        tuning_feature_1_MSE                 0.582161545753479
      tuning_feature_1_reg_NLL               1.1384005546569824
       tuning_feature_20_MSE                 0.4409639537334442
     tuning_feature_20_reg_NLL               0.4395136833190918
       tuning_feature_21_MSE                 0.4441847503185272
     tuning_feature_21_reg_NLL               0.4357278048992157
       tuning_feature_22_MSE                 7.4471354484558105
     tuning_feature_22_reg_NLL               3.7803385257720947
       tuning_feature_23_MSE                 6.532095432281494
     tuning_feature_23_reg_NLL               1.1956979036331177
       tuning_feature_24_MSE                 16.010847091674805
     tuning_feature_24_reg_NLL               2.3883869647979736
        tuning_feature_2_MSE                 1.642295479774475
      tuning_feature_2_reg_NLL              0.23576605319976807
        tuning_feature_3_MSE                 1.9370087385177612
      tuning_feature_3_reg_NLL               0.2848663032054901
        tuning_feature_4_MSE                 1.5651023387908936
      tuning_feature_4_reg_NLL              -0.1536693572998047
        tuning_feature_5_MSE                 0.7329609990119934
      tuning_feature_5_reg_NLL              0.18043889105319977
        tuning_feature_6_MSE                 0.8669325709342957
      tuning_feature_6_reg_NLL               0.9939165711402893
        tuning_feature_7_MSE                 1.4529920816421509
      tuning_feature_7_reg_NLL               1.3375072479248047
        tuning_feature_8_MSE                 1.3018429279327393
      tuning_feature_8_reg_NLL               1.2476483583450317
        tuning_feature_9_MSE                 1.578873872756958
      tuning_feature_9_reg_NLL               1.2546621561050415
            tuning_loss                      30.447662353515625
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

Testing: |          | 0/? [00:00<?, ?it/s]
Testing:   0%|          | 0/1 [00:00<?, ?it/s]
Testing DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Testing DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.47it/s]
Testing DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.40it/s]wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                       held_out_TTE_MSE ‚ñÅ
wandb:                      held_out_TTE_MSLE ‚ñÅ
wandb:                   held_out_TTE_reg_NLL ‚ñÅ
wandb:           held_out_event_label_cls_NLL ‚ñÅ
wandb:    held_out_event_label_macro_accuracy ‚ñÅ
wandb:    held_out_event_label_micro_accuracy ‚ñÅ
wandb:    held_out_event_label_weighted_AUROC ‚ñÅ
wandb: held_out_event_label_weighted_accuracy ‚ñÅ
wandb:            held_out_event_type_cls_NLL ‚ñÅ
wandb:     held_out_event_type_macro_accuracy ‚ñÅ
wandb:     held_out_event_type_micro_accuracy ‚ñÅ
wandb:     held_out_event_type_weighted_AUROC ‚ñÅ
wandb:  held_out_event_type_weighted_accuracy ‚ñÅ
wandb:                 held_out_feature_0_MSE ‚ñÅ
wandb:             held_out_feature_0_reg_NLL ‚ñÅ
wandb:                held_out_feature_10_MSE ‚ñÅ
wandb:            held_out_feature_10_reg_NLL ‚ñÅ
wandb:                held_out_feature_11_MSE ‚ñÅ
wandb:            held_out_feature_11_reg_NLL ‚ñÅ
wandb:                held_out_feature_12_MSE ‚ñÅ
wandb:            held_out_feature_12_reg_NLL ‚ñÅ
wandb:                held_out_feature_13_MSE ‚ñÅ
wandb:            held_out_feature_13_reg_NLL ‚ñÅ
wandb:                held_out_feature_14_MSE ‚ñÅ
wandb:            held_out_feature_14_reg_NLL ‚ñÅ
wandb:                held_out_feature_15_MSE ‚ñÅ
wandb:            held_out_feature_15_reg_NLL ‚ñÅ
wandb:                held_out_feature_16_MSE ‚ñÅ
wandb:            held_out_feature_16_reg_NLL ‚ñÅ
wandb:                held_out_feature_17_MSE ‚ñÅ
wandb:            held_out_feature_17_reg_NLL ‚ñÅ
wandb:                held_out_feature_18_MSE ‚ñÅ
wandb:            held_out_feature_18_reg_NLL ‚ñÅ
wandb:                held_out_feature_19_MSE ‚ñÅ
wandb:            held_out_feature_19_reg_NLL ‚ñÅ
wandb:                 held_out_feature_1_MSE ‚ñÅ
wandb:             held_out_feature_1_reg_NLL ‚ñÅ
wandb:                held_out_feature_20_MSE ‚ñÅ
wandb:            held_out_feature_20_reg_NLL ‚ñÅ
wandb:                held_out_feature_21_MSE ‚ñÅ
wandb:            held_out_feature_21_reg_NLL ‚ñÅ
wandb:                held_out_feature_22_MSE ‚ñÅ
wandb:            held_out_feature_22_reg_NLL ‚ñÅ
wandb:                held_out_feature_23_MSE ‚ñÅ
wandb:            held_out_feature_23_reg_NLL ‚ñÅ
wandb:                held_out_feature_24_MSE ‚ñÅ
wandb:            held_out_feature_24_reg_NLL ‚ñÅ
wandb:                 held_out_feature_2_MSE ‚ñÅ
wandb:             held_out_feature_2_reg_NLL ‚ñÅ
wandb:                 held_out_feature_3_MSE ‚ñÅ
wandb:             held_out_feature_3_reg_NLL ‚ñÅ
wandb:                 held_out_feature_4_MSE ‚ñÅ
wandb:             held_out_feature_4_reg_NLL ‚ñÅ
wandb:                 held_out_feature_5_MSE ‚ñÅ
wandb:             held_out_feature_5_reg_NLL ‚ñÅ
wandb:                 held_out_feature_6_MSE ‚ñÅ
wandb:             held_out_feature_6_reg_NLL ‚ñÅ
wandb:                 held_out_feature_7_MSE ‚ñÅ
wandb:             held_out_feature_7_reg_NLL ‚ñÅ
wandb:                 held_out_feature_8_MSE ‚ñÅ
wandb:             held_out_feature_8_reg_NLL ‚ñÅ
wandb:                 held_out_feature_9_MSE ‚ñÅ
wandb:             held_out_feature_9_reg_NLL ‚ñÅ
wandb:                          held_out_loss ‚ñÅ
wandb:                               lr-AdamW ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:                             task_AUROC ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ
wandb:                          task_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                              task_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:                             train_loss ‚ñÇ‚ñÉ‚ñà‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ
wandb:                    trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                         tuning_TTE_MSE ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÇ
wandb:                        tuning_TTE_MSLE ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:                     tuning_TTE_reg_NLL ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:             tuning_event_label_cls_NLL ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      tuning_event_label_macro_accuracy ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      tuning_event_label_micro_accuracy ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      tuning_event_label_weighted_AUROC ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   tuning_event_label_weighted_accuracy ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:              tuning_event_type_cls_NLL ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:       tuning_event_type_macro_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       tuning_event_type_micro_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       tuning_event_type_weighted_AUROC ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:    tuning_event_type_weighted_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   tuning_feature_0_MSE ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÇ
wandb:               tuning_feature_0_reg_NLL ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:                  tuning_feature_10_MSE ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ
wandb:              tuning_feature_10_reg_NLL ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  tuning_feature_11_MSE ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÉ‚ñá‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÉ
wandb:              tuning_feature_11_reg_NLL ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:                  tuning_feature_12_MSE ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÑ
wandb:              tuning_feature_12_reg_NLL ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:                  tuning_feature_13_MSE ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÅ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÜ‚ñÖ‚ñÇ
wandb:              tuning_feature_13_reg_NLL ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ
wandb:                  tuning_feature_14_MSE ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ
wandb:              tuning_feature_14_reg_NLL ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  tuning_feature_15_MSE ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÖ
wandb:              tuning_feature_15_reg_NLL ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                  tuning_feature_16_MSE ‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ
wandb:              tuning_feature_16_reg_NLL ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  tuning_feature_17_MSE ‚ñà‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ
wandb:              tuning_feature_17_reg_NLL ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  tuning_feature_18_MSE ‚ñÖ‚ñÖ‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñÅ‚ñá‚ñá‚ñá‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñÑ
wandb:              tuning_feature_18_reg_NLL ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                  tuning_feature_19_MSE ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ
wandb:              tuning_feature_19_reg_NLL ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   tuning_feature_1_MSE ‚ñÜ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñá‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñá
wandb:               tuning_feature_1_reg_NLL ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:                  tuning_feature_20_MSE ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñá‚ñÇ‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñà‚ñÖ‚ñÉ
wandb:              tuning_feature_20_reg_NLL ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  tuning_feature_21_MSE ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb:              tuning_feature_21_reg_NLL ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  tuning_feature_22_MSE ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñà
wandb:              tuning_feature_22_reg_NLL ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  tuning_feature_23_MSE ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñá‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÑ
wandb:              tuning_feature_23_reg_NLL ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ
wandb:                  tuning_feature_24_MSE ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñá‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñá‚ñÑ‚ñà‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñá
wandb:              tuning_feature_24_reg_NLL ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ
wandb:                   tuning_feature_2_MSE ‚ñÉ‚ñÅ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ
wandb:               tuning_feature_2_reg_NLL ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                   tuning_feature_3_MSE ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñá‚ñÅ‚ñÖ‚ñÑ‚ñá‚ñà‚ñÉ‚ñÖ‚ñÖ‚ñÜ
wandb:               tuning_feature_3_reg_NLL ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                   tuning_feature_4_MSE ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÖ
wandb:               tuning_feature_4_reg_NLL ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                   tuning_feature_5_MSE ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ
wandb:               tuning_feature_5_reg_NLL ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:                   tuning_feature_6_MSE ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ
wandb:               tuning_feature_6_reg_NLL ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   tuning_feature_7_MSE ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ
wandb:               tuning_feature_7_reg_NLL ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   tuning_feature_8_MSE ‚ñÉ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ
wandb:               tuning_feature_8_reg_NLL ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                   tuning_feature_9_MSE ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÅ‚ñà‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÑ
wandb:               tuning_feature_9_reg_NLL ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                            tuning_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                                  epoch 81
wandb:                       held_out_TTE_MSE 43413.27734
wandb:                      held_out_TTE_MSLE 8.25252
wandb:                   held_out_TTE_reg_NLL 5.55797
wandb:           held_out_event_label_cls_NLL 0.17479
wandb:    held_out_event_label_macro_accuracy 0.94561
wandb:    held_out_event_label_micro_accuracy 0.94561
wandb:    held_out_event_label_weighted_AUROC 0.87277
wandb: held_out_event_label_weighted_accuracy 0.85132
wandb:            held_out_event_type_cls_NLL 0.02016
wandb:     held_out_event_type_macro_accuracy 0.0
wandb:     held_out_event_type_micro_accuracy 0.0
wandb:     held_out_event_type_weighted_AUROC 0.0
wandb:  held_out_event_type_weighted_accuracy 0.0
wandb:                 held_out_feature_0_MSE 1.16588
wandb:             held_out_feature_0_reg_NLL -0.46419
wandb:                held_out_feature_10_MSE 1.02352
wandb:            held_out_feature_10_reg_NLL 1.66824
wandb:                held_out_feature_11_MSE 2.24425
wandb:            held_out_feature_11_reg_NLL 1.64216
wandb:                held_out_feature_12_MSE 2.78026
wandb:            held_out_feature_12_reg_NLL 1.90091
wandb:                held_out_feature_13_MSE 2.84573
wandb:            held_out_feature_13_reg_NLL 2.40351
wandb:                held_out_feature_14_MSE 2.48719
wandb:            held_out_feature_14_reg_NLL 1.44173
wandb:                held_out_feature_15_MSE 1.3696
wandb:            held_out_feature_15_reg_NLL 1.33146
wandb:                held_out_feature_16_MSE 1.23157
wandb:            held_out_feature_16_reg_NLL 1.268
wandb:                held_out_feature_17_MSE 1.29261
wandb:            held_out_feature_17_reg_NLL 1.27757
wandb:                held_out_feature_18_MSE 2.07791
wandb:            held_out_feature_18_reg_NLL 1.43951
wandb:                held_out_feature_19_MSE 0.86551
wandb:            held_out_feature_19_reg_NLL 0.79214
wandb:                 held_out_feature_1_MSE 1.8523
wandb:             held_out_feature_1_reg_NLL 0.50344
wandb:                held_out_feature_20_MSE 0.7875
wandb:            held_out_feature_20_reg_NLL 0.77721
wandb:                held_out_feature_21_MSE 0.79028
wandb:            held_out_feature_21_reg_NLL 0.75872
wandb:                held_out_feature_22_MSE 0.68117
wandb:            held_out_feature_22_reg_NLL 0.73375
wandb:                held_out_feature_23_MSE 1.88789
wandb:            held_out_feature_23_reg_NLL 0.99137
wandb:                held_out_feature_24_MSE 1.42989
wandb:            held_out_feature_24_reg_NLL 0.47558
wandb:                 held_out_feature_2_MSE 1.70207
wandb:             held_out_feature_2_reg_NLL 1.54391
wandb:                 held_out_feature_3_MSE 1.26465
wandb:             held_out_feature_3_reg_NLL 1.01631
wandb:                 held_out_feature_4_MSE 1.54597
wandb:             held_out_feature_4_reg_NLL 1.07086
wandb:                 held_out_feature_5_MSE 1.88141
wandb:             held_out_feature_5_reg_NLL 2.48092
wandb:                 held_out_feature_6_MSE 0.73173
wandb:             held_out_feature_6_reg_NLL 0.89373
wandb:                 held_out_feature_7_MSE 1.79774
wandb:             held_out_feature_7_reg_NLL 1.4004
wandb:                 held_out_feature_8_MSE 1.35037
wandb:             held_out_feature_8_reg_NLL 1.2474
wandb:                 held_out_feature_9_MSE 1.81695
wandb:             held_out_feature_9_reg_NLL 1.32643
wandb:                          held_out_loss 35.78798
wandb:                               lr-AdamW 1e-05
wandb:                             task_AUROC 0.0002
wandb:                          task_accuracy 0.99902
wandb:                              task_loss 0.11397
wandb:                             train_loss 21.7122
wandb:                    trainer/global_step 567
wandb:                         tuning_TTE_MSE 32284.82812
wandb:                        tuning_TTE_MSLE 6.6888
wandb:                     tuning_TTE_reg_NLL 5.54921
wandb:             tuning_event_label_cls_NLL 0.16291
wandb:      tuning_event_label_macro_accuracy 0.92564
wandb:      tuning_event_label_micro_accuracy 0.92564
wandb:      tuning_event_label_weighted_AUROC 0.77775
wandb:   tuning_event_label_weighted_accuracy 0.73291
wandb:              tuning_event_type_cls_NLL 0.00953
wandb:       tuning_event_type_macro_accuracy 0.0
wandb:       tuning_event_type_micro_accuracy 0.0
wandb:       tuning_event_type_weighted_AUROC 0.0
wandb:    tuning_event_type_weighted_accuracy 0.0
wandb:                   tuning_feature_0_MSE 0.14716
wandb:               tuning_feature_0_reg_NLL -0.45214
wandb:                  tuning_feature_10_MSE 0.58467
wandb:              tuning_feature_10_reg_NLL 0.69433
wandb:                  tuning_feature_11_MSE 1.62889
wandb:              tuning_feature_11_reg_NLL 1.27023
wandb:                  tuning_feature_12_MSE 1.5637
wandb:              tuning_feature_12_reg_NLL 1.16302
wandb:                  tuning_feature_13_MSE 2.22986
wandb:              tuning_feature_13_reg_NLL 1.44043
wandb:                  tuning_feature_14_MSE 0.59948
wandb:              tuning_feature_14_reg_NLL 0.72049
wandb:                  tuning_feature_15_MSE 1.29458
wandb:              tuning_feature_15_reg_NLL 1.22614
wandb:                  tuning_feature_16_MSE 1.02135
wandb:              tuning_feature_16_reg_NLL 1.11078
wandb:                  tuning_feature_17_MSE 1.1385
wandb:              tuning_feature_17_reg_NLL 1.14939
wandb:                  tuning_feature_18_MSE 1.20521
wandb:              tuning_feature_18_reg_NLL 0.96574
wandb:                  tuning_feature_19_MSE 0.48741
wandb:              tuning_feature_19_reg_NLL 0.5286
wandb:                   tuning_feature_1_MSE 0.58216
wandb:               tuning_feature_1_reg_NLL 1.1384
wandb:                  tuning_feature_20_MSE 0.44096
wandb:              tuning_feature_20_reg_NLL 0.43951
wandb:                  tuning_feature_21_MSE 0.44418
wandb:              tuning_feature_21_reg_NLL 0.43573
wandb:                  tuning_feature_22_MSE 7.44714
wandb:              tuning_feature_22_reg_NLL 3.78034
wandb:                  tuning_feature_23_MSE 6.5321
wandb:              tuning_feature_23_reg_NLL 1.1957
wandb:                  tuning_feature_24_MSE 16.01085
wandb:              tuning_feature_24_reg_NLL 2.38839
wandb:                   tuning_feature_2_MSE 1.6423
wandb:               tuning_feature_2_reg_NLL 0.23577
wandb:                   tuning_feature_3_MSE 1.93701
wandb:               tuning_feature_3_reg_NLL 0.28487
wandb:                   tuning_feature_4_MSE 1.5651
wandb:               tuning_feature_4_reg_NLL -0.15367
wandb:                   tuning_feature_5_MSE 0.73296
wandb:               tuning_feature_5_reg_NLL 0.18044
wandb:                   tuning_feature_6_MSE 0.86693
wandb:               tuning_feature_6_reg_NLL 0.99392
wandb:                   tuning_feature_7_MSE 1.45299
wandb:               tuning_feature_7_reg_NLL 1.33751
wandb:                   tuning_feature_8_MSE 1.30184
wandb:               tuning_feature_8_reg_NLL 1.24765
wandb:                   tuning_feature_9_MSE 1.57887
wandb:               tuning_feature_9_reg_NLL 1.25466
wandb:                            tuning_loss 30.44766
wandb: 
wandb: üöÄ View run generative_event_stream_transformer at: https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/metkhdnh
wandb: Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_143410-metkhdnh/logs

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
             Test metric                           DataLoader 0
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
           held_out_TTE_MSE                       43413.27734375
          held_out_TTE_MSLE                     8.252518653869629
         held_out_TTE_reg_NLL                   5.557973384857178
     held_out_event_label_cls_NLL              0.17478978633880615
 held_out_event_label_macro_accuracy            0.9456053972244263
 held_out_event_label_micro_accuracy            0.945605456829071
 held_out_event_label_weighted_AUROC            0.8727715015411377
held_out_event_label_weighted_accuracy          0.8513224124908447
     held_out_event_type_cls_NLL               0.020161205902695656
  held_out_event_type_macro_accuracy                   0.0
  held_out_event_type_micro_accuracy                   0.0
  held_out_event_type_weighted_AUROC                   0.0
held_out_event_type_weighted_accuracy                  0.0
        held_out_feature_0_MSE                  1.1658846139907837
      held_out_feature_0_reg_NLL               -0.46418824791908264
       held_out_feature_10_MSE                  1.0235240459442139
     held_out_feature_10_reg_NLL                1.6682368516921997
       held_out_feature_11_MSE                  2.2442545890808105
     held_out_feature_11_reg_NLL                1.642163872718811
       held_out_feature_12_MSE                  2.780256748199463
     held_out_feature_12_reg_NLL                1.900909423828125
       held_out_feature_13_MSE                  2.8457300662994385
     held_out_feature_13_reg_NLL                2.4035146236419678
       held_out_feature_14_MSE                   2.48718523979187
     held_out_feature_14_reg_NLL                1.4417318105697632
       held_out_feature_15_MSE                  1.3696026802062988
     held_out_feature_15_reg_NLL                1.3314599990844727
       held_out_feature_16_MSE                  1.2315679788589478
     held_out_feature_16_reg_NLL                1.2680000066757202
       held_out_feature_17_MSE                  1.2926054000854492
     held_out_feature_17_reg_NLL                1.2775726318359375
       held_out_feature_18_MSE                  2.0779051780700684
     held_out_feature_18_reg_NLL                1.4395147562026978
       held_out_feature_19_MSE                  0.8655107021331787
     held_out_feature_19_reg_NLL                0.7921369671821594
        held_out_feature_1_MSE                  1.8522988557815552
      held_out_feature_1_reg_NLL                0.5034422278404236
       held_out_feature_20_MSE                  0.7875025868415833
     held_out_feature_20_reg_NLL                0.7772088646888733
       held_out_feature_21_MSE                  0.7902764678001404
     held_out_feature_21_reg_NLL                0.758721649646759
       held_out_feature_22_MSE                  0.6811714172363281
     held_out_feature_22_reg_NLL                0.7337455749511719
       held_out_feature_23_MSE                  1.8878881931304932
     held_out_feature_23_reg_NLL                 0.99136883020401
       held_out_feature_24_MSE                  1.4298938512802124
     held_out_feature_24_reg_NLL                0.4755821228027344
        held_out_feature_2_MSE                  1.7020748853683472
      held_out_feature_2_reg_NLL                1.5439141988754272
        held_out_feature_3_MSE                  1.2646540403366089
      held_out_feature_3_reg_NLL                1.0163073539733887
        held_out_feature_4_MSE                  1.545974850654602
      held_out_feature_4_reg_NLL                 1.07086181640625
        held_out_feature_5_MSE                  1.881410837173462
      held_out_feature_5_reg_NLL                2.480921983718872
        held_out_feature_6_MSE                  0.7317325472831726
      held_out_feature_6_reg_NLL                0.893730103969574
        held_out_feature_7_MSE                  1.797735333442688
      held_out_feature_7_reg_NLL                1.400403380393982
        held_out_feature_8_MSE                  1.3503704071044922
      held_out_feature_8_reg_NLL                1.247397541999817
        held_out_feature_9_MSE                  1.8169512748718262
      held_out_feature_9_reg_NLL                1.3264259099960327
            held_out_loss                       35.78798294067383
              task_AUROC                      0.00019531250291038305
            task_accuracy                          0.9990234375
              task_loss                        0.11397146433591843
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Saving final metrics...
2025-04-10 14:38:26,921 - wandb.wandb_agent - INFO - Cleaning up finished run: metkhdnh
[2025-04-10 14:38:26,921][wandb.wandb_agent][INFO] - Cleaning up finished run: metkhdnh
2025-04-10 14:38:27,389 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:38:27,389][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:38:27,389 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.2951597625909382
	config.input_dropout: 0.4659420631118019
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.3732504848764159
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: last
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 40
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.27495225983076566
	optimization_config.init_lr: 1.4437759099424898e-06
	optimization_config.lr_decay_power: 2.1036180956002903
	optimization_config.lr_frac_warmup_steps: 5.015833820841619e-05
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.0009132692834446936
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:38:27,389][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.2951597625909382
	config.input_dropout: 0.4659420631118019
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.3732504848764159
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: last
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 40
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.27495225983076566
	optimization_config.init_lr: 1.4437759099424898e-06
	optimization_config.lr_decay_power: 2.1036180956002903
	optimization_config.lr_frac_warmup_steps: 5.015833820841619e-05
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.0009132692834446936
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:38:27,397 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.2951597625909382 config.input_dropout=0.4659420631118019 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.3732504848764159 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=last data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=40 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.27495225983076566 optimization_config.init_lr=1.4437759099424898e-06 optimization_config.lr_decay_power=2.1036180956002903 optimization_config.lr_frac_warmup_steps=5.015833820841619e-05 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.0009132692834446936 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:38:27,397][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.2951597625909382 config.input_dropout=0.4659420631118019 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.3732504848764159 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=last data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=40 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.27495225983076566 optimization_config.init_lr=1.4437759099424898e-06 optimization_config.lr_decay_power=2.1036180956002903 optimization_config.lr_frac_warmup_steps=5.015833820841619e-05 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.0009132692834446936 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1
2025-04-10 14:38:32,408 - wandb.wandb_agent - INFO - Running runs: ['5aqi2n4m']
[2025-04-10 14:38:32,408][wandb.wandb_agent][INFO] - Running runs: ['5aqi2n4m']
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_143834-5aqi2n4m
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/5aqi2n4m
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.2951597625909382
Overwriting input_dropout in config from 0.4494236115512016 to 0.4659420631118019
Overwriting resid_dropout in config from 0.4939188761966135 to 0.3732504848764159
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'last', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.2951597625909382
Overwriting input_dropout in config from 0.4494236115512016 to 0.4659420631118019
Overwriting resid_dropout in config from 0.4939188761966135 to 0.3732504848764159
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'last', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.53it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/3 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s] 
Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.68it/s]
Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.68it/s, v_num=2n4m]/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.
  warnings.warn(*args, **kwargs)

Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.96it/s, v_num=2n4m]
Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.96it/s, v_num=2n4m]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.13it/s, v_num=2n4m]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.13it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.44it/s][A

                                                                      [A
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.65it/s, v_num=2n4m]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.65it/s, v_num=2n4m]
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.68it/s, v_num=2n4m]
Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.68it/s, v_num=2n4m]
Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.95it/s, v_num=2n4m]
Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.95it/s, v_num=2n4m]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.13it/s, v_num=2n4m]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.13it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.53it/s][A

                                                                      [A
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.65it/s, v_num=2n4m]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.65it/s, v_num=2n4m]
Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.65it/s, v_num=2n4m]
Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.65it/s, v_num=2n4m]
Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.90it/s, v_num=2n4m]
Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.90it/s, v_num=2n4m]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.07it/s, v_num=2n4m]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.07it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.97it/s][A

                                                                      [A
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.60it/s, v_num=2n4m]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.60it/s, v_num=2n4m]
Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.58it/s, v_num=2n4m]
Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.57it/s, v_num=2n4m]
Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.82it/s, v_num=2n4m]
Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.82it/s, v_num=2n4m]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.99it/s, v_num=2n4m]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.99it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.13it/s][A

                                                                      [A
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.59it/s, v_num=2n4m]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.59it/s, v_num=2n4m]
Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.58it/s, v_num=2n4m]
Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.58it/s, v_num=2n4m]
Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.83it/s, v_num=2n4m]
Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.83it/s, v_num=2n4m]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.99it/s, v_num=2n4m]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.99it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.09it/s][A

                                                                      [A
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.58it/s, v_num=2n4m]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.58it/s, v_num=2n4m]
Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.62it/s, v_num=2n4m]
Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.62it/s, v_num=2n4m]
Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.86it/s, v_num=2n4m]
Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.86it/s, v_num=2n4m]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.01it/s, v_num=2n4m]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.01it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.53it/s][A

                                                                      [A
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.59it/s, v_num=2n4m]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.59it/s, v_num=2n4m]
Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.55it/s, v_num=2n4m]
Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.55it/s, v_num=2n4m]
Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.80it/s, v_num=2n4m]
Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.80it/s, v_num=2n4m]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.97it/s, v_num=2n4m]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.97it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.11it/s][A

                                                                      [A
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.57it/s, v_num=2n4m]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.57it/s, v_num=2n4m]
Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.63it/s, v_num=2n4m]
Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.63it/s, v_num=2n4m]
Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.89it/s, v_num=2n4m]
Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.89it/s, v_num=2n4m]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.05it/s, v_num=2n4m]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.05it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s][A

                                                                      [A
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.61it/s, v_num=2n4m]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.61it/s, v_num=2n4m]
Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.56it/s, v_num=2n4m]
Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.56it/s, v_num=2n4m]
Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.83it/s, v_num=2n4m]
Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.83it/s, v_num=2n4m]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.99it/s, v_num=2n4m]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.99it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s][A

                                                                      [A
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.59it/s, v_num=2n4m]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.59it/s, v_num=2n4m]
Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.64it/s, v_num=2n4m]
Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.64it/s, v_num=2n4m]
Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.87it/s, v_num=2n4m]
Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.87it/s, v_num=2n4m]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.03it/s, v_num=2n4m]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.03it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.13it/s][A

                                                                      [A
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.60it/s, v_num=2n4m]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.60it/s, v_num=2n4m]
Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.57it/s, v_num=2n4m]
Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.57it/s, v_num=2n4m]
Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.82it/s, v_num=2n4m]
Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.82it/s, v_num=2n4m]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.99it/s, v_num=2n4m]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.99it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s][A

                                                                      [A
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.59it/s, v_num=2n4m]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.59it/s, v_num=2n4m]
Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 11:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.67it/s, v_num=2n4m]
Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.67it/s, v_num=2n4m]
Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.93it/s, v_num=2n4m]
Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.93it/s, v_num=2n4m]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.09it/s, v_num=2n4m]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.09it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.15it/s][A

                                                                      [A
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.62it/s, v_num=2n4m]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.62it/s, v_num=2n4m]
Epoch 11:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.63it/s, v_num=2n4m]
Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.62it/s, v_num=2n4m]
Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.88it/s, v_num=2n4m]
Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.88it/s, v_num=2n4m]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.05it/s, v_num=2n4m]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.05it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s][A

                                                                      [A
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.60it/s, v_num=2n4m]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.60it/s, v_num=2n4m]
Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 13:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.58it/s, v_num=2n4m]
Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.58it/s, v_num=2n4m]
Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.85it/s, v_num=2n4m]
Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.85it/s, v_num=2n4m]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.01it/s, v_num=2n4m]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.01it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.22it/s][A

                                                                      [A
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.59it/s, v_num=2n4m]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  0.59it/s, v_num=2n4m]
Epoch 13:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 14:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.63it/s, v_num=2n4m]
Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.63it/s, v_num=2n4m]
Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.88it/s, v_num=2n4m]
Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.88it/s, v_num=2n4m]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.05it/s, v_num=2n4m]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.05it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s][A

                                                                      [A
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.61it/s, v_num=2n4m]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.61it/s, v_num=2n4m]
Epoch 14:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]
Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.61it/s, v_num=2n4m]
Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.61it/s, v_num=2n4m]
Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.87it/s, v_num=2n4m]
Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.87it/s, v_num=2n4m]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.04it/s, v_num=2n4m]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.04it/s, v_num=2n4m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s][A

                                                                      [A
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.76it/s, v_num=2n4m]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.76it/s, v_num=2n4m]
Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m]        
Epoch 16:   0%|          | 0/3 [00:00<?, ?it/s, v_num=2n4m][rank: 1] Child process with PID 1166811 terminated with code -9. Forcefully terminating all other processes to avoid zombies üßü
2025-04-10 14:40:15,813 - wandb.wandb_agent - INFO - Cleaning up finished run: 5aqi2n4m
[2025-04-10 14:40:15,813][wandb.wandb_agent][INFO] - Cleaning up finished run: 5aqi2n4m
2025-04-10 14:40:16,356 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:40:16,356][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:40:16,357 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.1425209069241511
	config.input_dropout: 0.38076395706111366
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.43866755095879745
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: last
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 16
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.032439860430808584
	optimization_config.init_lr: 1.7313400655099632e-07
	optimization_config.lr_decay_power: 0.9388013508688702
	optimization_config.lr_frac_warmup_steps: 0.00015027083091494772
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.0026837624592566385
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:40:16,357][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.1425209069241511
	config.input_dropout: 0.38076395706111366
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.43866755095879745
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: last
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 16
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.032439860430808584
	optimization_config.init_lr: 1.7313400655099632e-07
	optimization_config.lr_decay_power: 0.9388013508688702
	optimization_config.lr_frac_warmup_steps: 0.00015027083091494772
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.0026837624592566385
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:40:16,368 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.1425209069241511 config.input_dropout=0.38076395706111366 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.43866755095879745 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=last data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=16 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.032439860430808584 optimization_config.init_lr=1.7313400655099632e-07 optimization_config.lr_decay_power=0.9388013508688702 optimization_config.lr_frac_warmup_steps=0.00015027083091494772 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.0026837624592566385 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:40:16,368][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.1425209069241511 config.input_dropout=0.38076395706111366 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.43866755095879745 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=last data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=16 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.032439860430808584 optimization_config.init_lr=1.7313400655099632e-07 optimization_config.lr_decay_power=0.9388013508688702 optimization_config.lr_frac_warmup_steps=0.00015027083091494772 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.0026837624592566385 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
2025-04-10 14:40:21,381 - wandb.wandb_agent - INFO - Running runs: ['ydq8llhr']
[2025-04-10 14:40:21,381][wandb.wandb_agent][INFO] - Running runs: ['ydq8llhr']
Seed set to 1
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_144023-ydq8llhr
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/ydq8llhr
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.1425209069241511
Overwriting input_dropout in config from 0.4494236115512016 to 0.38076395706111366
Overwriting resid_dropout in config from 0.4939188761966135 to 0.43866755095879745
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'last', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.1425209069241511
Overwriting input_dropout in config from 0.4494236115512016 to 0.38076395706111366
Overwriting resid_dropout in config from 0.4939188761966135 to 0.43866755095879745
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'last', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.47it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/6 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/6 [00:00<?, ?it/s] /home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.
  warnings.warn(*args, **kwargs)

Epoch 0:  17%|‚ñà‚ñã        | 1/6 [00:00<00:03,  1.52it/s]
Epoch 0:  17%|‚ñà‚ñã        | 1/6 [00:00<00:03,  1.52it/s, v_num=llhr]
Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:00<00:01,  2.27it/s, v_num=llhr]
Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:00<00:01,  2.27it/s, v_num=llhr]
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  2.74it/s, v_num=llhr]
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  2.74it/s, v_num=llhr]
Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:01<00:00,  3.06it/s, v_num=llhr]
Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:01<00:00,  3.06it/s, v_num=llhr]
Epoch 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:01<00:00,  3.26it/s, v_num=llhr]
Epoch 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:01<00:00,  3.26it/s, v_num=llhr]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  3.29it/s, v_num=llhr]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  3.29it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.51it/s][A

                                                                      [A
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.35it/s, v_num=llhr]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.34it/s, v_num=llhr]
Epoch 0:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 1:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 1:  17%|‚ñà‚ñã        | 1/6 [00:00<00:04,  1.11it/s, v_num=llhr]
Epoch 1:  17%|‚ñà‚ñã        | 1/6 [00:00<00:04,  1.10it/s, v_num=llhr]
Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.77it/s, v_num=llhr]
Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.77it/s, v_num=llhr]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  2.23it/s, v_num=llhr]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  2.23it/s, v_num=llhr]
Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:01<00:00,  2.54it/s, v_num=llhr]
Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:01<00:00,  2.53it/s, v_num=llhr]
Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:01<00:00,  2.77it/s, v_num=llhr]
Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:01<00:00,  2.77it/s, v_num=llhr]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.95it/s, v_num=llhr]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.95it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.43it/s][A

                                                                      [A
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.17it/s, v_num=llhr]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.16it/s, v_num=llhr]
Epoch 1:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 2:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 2:  17%|‚ñà‚ñã        | 1/6 [00:00<00:04,  1.17it/s, v_num=llhr]
Epoch 2:  17%|‚ñà‚ñã        | 1/6 [00:00<00:04,  1.17it/s, v_num=llhr]
Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.78it/s, v_num=llhr]
Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.78it/s, v_num=llhr]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  2.22it/s, v_num=llhr]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  2.21it/s, v_num=llhr]
Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:01<00:00,  2.48it/s, v_num=llhr]
Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:01<00:00,  2.48it/s, v_num=llhr]
Epoch 2:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:01<00:00,  2.71it/s, v_num=llhr]
Epoch 2:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:01<00:00,  2.71it/s, v_num=llhr]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.88it/s, v_num=llhr]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.88it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.10it/s][A

                                                                      [A
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.16it/s, v_num=llhr]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.15it/s, v_num=llhr]
Epoch 2:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 3:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 3:  17%|‚ñà‚ñã        | 1/6 [00:00<00:04,  1.01it/s, v_num=llhr]
Epoch 3:  17%|‚ñà‚ñã        | 1/6 [00:00<00:04,  1.01it/s, v_num=llhr]
Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.54it/s, v_num=llhr]
Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.54it/s, v_num=llhr]
Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.82it/s, v_num=llhr]
Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.82it/s, v_num=llhr]
Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:01<00:00,  2.12it/s, v_num=llhr]
Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:01<00:00,  2.12it/s, v_num=llhr]
Epoch 3:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  2.33it/s, v_num=llhr]
Epoch 3:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  2.33it/s, v_num=llhr]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.39it/s, v_num=llhr]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.39it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.13it/s][A

                                                                      [A
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.80it/s, v_num=llhr]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.79it/s, v_num=llhr]
Epoch 3:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 4:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 4:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.79it/s, v_num=llhr]
Epoch 4:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.79it/s, v_num=llhr]
Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.20it/s, v_num=llhr]
Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.20it/s, v_num=llhr]
Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.47it/s, v_num=llhr]
Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.47it/s, v_num=llhr]
Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.68it/s, v_num=llhr]
Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.68it/s, v_num=llhr]
Epoch 4:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.86it/s, v_num=llhr]
Epoch 4:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.86it/s, v_num=llhr]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.97it/s, v_num=llhr]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.97it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.76it/s][A

                                                                      [A
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.51it/s, v_num=llhr]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.51it/s, v_num=llhr]
Epoch 4:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 5:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 5:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.95it/s, v_num=llhr]
Epoch 5:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.94it/s, v_num=llhr]
Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.40it/s, v_num=llhr]
Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.40it/s, v_num=llhr]
Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.70it/s, v_num=llhr]
Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.70it/s, v_num=llhr]
Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.91it/s, v_num=llhr]
Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.91it/s, v_num=llhr]
Epoch 5:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  2.06it/s, v_num=llhr]
Epoch 5:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  2.06it/s, v_num=llhr]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.18it/s, v_num=llhr]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.18it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.59it/s][A

                                                                      [A
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.64it/s, v_num=llhr]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.64it/s, v_num=llhr]
Epoch 5:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 6:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 6:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.96it/s, v_num=llhr]
Epoch 6:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.96it/s, v_num=llhr]
Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.45it/s, v_num=llhr]
Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.45it/s, v_num=llhr]
Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.71it/s, v_num=llhr]
Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.71it/s, v_num=llhr]
Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.90it/s, v_num=llhr]
Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.90it/s, v_num=llhr]
Epoch 6:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  2.04it/s, v_num=llhr]
Epoch 6:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  2.04it/s, v_num=llhr]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.13it/s, v_num=llhr]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.13it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.69it/s][A

                                                                      [A
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.61it/s, v_num=llhr]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.61it/s, v_num=llhr]
Epoch 6:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 7:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 7:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.78it/s, v_num=llhr]
Epoch 7:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.78it/s, v_num=llhr]
Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.12it/s, v_num=llhr]
Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.12it/s, v_num=llhr]
Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.37it/s, v_num=llhr]
Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.37it/s, v_num=llhr]
Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.58it/s, v_num=llhr]
Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.58it/s, v_num=llhr]
Epoch 7:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.74it/s, v_num=llhr]
Epoch 7:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.74it/s, v_num=llhr]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.91it/s, v_num=llhr]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.91it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.85it/s][A

                                                                      [A
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.54it/s, v_num=llhr]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.53it/s, v_num=llhr]
Epoch 7:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 8:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 8:  17%|‚ñà‚ñã        | 1/6 [00:00<00:04,  1.02it/s, v_num=llhr]
Epoch 8:  17%|‚ñà‚ñã        | 1/6 [00:00<00:04,  1.02it/s, v_num=llhr]
Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.40it/s, v_num=llhr]
Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.40it/s, v_num=llhr]
Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.70it/s, v_num=llhr]
Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.70it/s, v_num=llhr]
Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.91it/s, v_num=llhr]
Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.91it/s, v_num=llhr]
Epoch 8:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  2.09it/s, v_num=llhr]
Epoch 8:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  2.08it/s, v_num=llhr]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.19it/s, v_num=llhr]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.19it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.20it/s][A

                                                                      [A
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.27it/s, v_num=llhr]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.27it/s, v_num=llhr]
Epoch 8:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 9:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 9:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.78it/s, v_num=llhr]
Epoch 9:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.78it/s, v_num=llhr]
Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.05it/s, v_num=llhr]
Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.05it/s, v_num=llhr]
Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.32it/s, v_num=llhr]
Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.32it/s, v_num=llhr]
Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.52it/s, v_num=llhr]
Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.52it/s, v_num=llhr]
Epoch 9:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.69it/s, v_num=llhr]
Epoch 9:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.69it/s, v_num=llhr]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.82it/s, v_num=llhr]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.82it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.67it/s][A

                                                                      [A
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.37it/s, v_num=llhr]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.36it/s, v_num=llhr]
Epoch 9:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 10:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 10:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.94it/s, v_num=llhr]
Epoch 10:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.94it/s, v_num=llhr]
Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.43it/s, v_num=llhr]
Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.43it/s, v_num=llhr]
Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.70it/s, v_num=llhr]
Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.70it/s, v_num=llhr]
Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.89it/s, v_num=llhr]
Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.89it/s, v_num=llhr]
Epoch 10:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.85it/s, v_num=llhr]
Epoch 10:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.85it/s, v_num=llhr]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.82it/s, v_num=llhr]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.82it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.46it/s][A

                                                                      [A
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.30it/s, v_num=llhr]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.30it/s, v_num=llhr]
Epoch 10:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 11:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 11:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.87it/s, v_num=llhr]
Epoch 11:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.87it/s, v_num=llhr]
Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.13it/s, v_num=llhr]
Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.13it/s, v_num=llhr]
Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.27it/s, v_num=llhr]
Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.27it/s, v_num=llhr]
Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.35it/s, v_num=llhr]
Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.35it/s, v_num=llhr]
Epoch 11:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.49it/s, v_num=llhr]
Epoch 11:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.49it/s, v_num=llhr]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.62it/s, v_num=llhr]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.62it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.17it/s][A

                                                                      [A
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.30it/s, v_num=llhr]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.30it/s, v_num=llhr]
Epoch 11:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 12:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 12:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.71it/s, v_num=llhr]
Epoch 12:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.71it/s, v_num=llhr]
Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.12it/s, v_num=llhr]
Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.12it/s, v_num=llhr]
Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.41it/s, v_num=llhr]
Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.41it/s, v_num=llhr]
Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.61it/s, v_num=llhr]
Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.61it/s, v_num=llhr]
Epoch 12:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.77it/s, v_num=llhr]
Epoch 12:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.77it/s, v_num=llhr]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.85it/s, v_num=llhr]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.85it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.46it/s][A

                                                                      [A
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.42it/s, v_num=llhr]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.42it/s, v_num=llhr]
Epoch 12:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 13:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 13:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.96it/s, v_num=llhr]
Epoch 13:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.96it/s, v_num=llhr]
Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.22it/s, v_num=llhr]
Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.22it/s, v_num=llhr]
Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.48it/s, v_num=llhr]
Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.48it/s, v_num=llhr]
Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.57it/s, v_num=llhr]
Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.57it/s, v_num=llhr]
Epoch 13:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.72it/s, v_num=llhr]
Epoch 13:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.72it/s, v_num=llhr]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.83it/s, v_num=llhr]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.83it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.50it/s][A

                                                                      [A
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.38it/s, v_num=llhr]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.38it/s, v_num=llhr]
Epoch 13:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 14:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 14:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.75it/s, v_num=llhr]
Epoch 14:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.75it/s, v_num=llhr]
Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.17it/s, v_num=llhr]
Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.17it/s, v_num=llhr]
Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.46it/s, v_num=llhr]
Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.46it/s, v_num=llhr]
Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.66it/s, v_num=llhr]
Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.66it/s, v_num=llhr]
Epoch 14:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.81it/s, v_num=llhr]
Epoch 14:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.81it/s, v_num=llhr]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.93it/s, v_num=llhr]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.93it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.62it/s][A

                                                                      [A
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.32it/s, v_num=llhr]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.32it/s, v_num=llhr]
Epoch 14:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 15:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 15:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.87it/s, v_num=llhr]
Epoch 15:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.87it/s, v_num=llhr]
Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.31it/s, v_num=llhr]
Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.31it/s, v_num=llhr]
Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.60it/s, v_num=llhr]
Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.60it/s, v_num=llhr]
Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.72it/s, v_num=llhr]
Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.72it/s, v_num=llhr]
Epoch 15:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.83it/s, v_num=llhr]
Epoch 15:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.83it/s, v_num=llhr]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.87it/s, v_num=llhr]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.87it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.55it/s][A

                                                                      [A
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.29it/s, v_num=llhr]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.29it/s, v_num=llhr]
Epoch 15:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 16:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 16:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.85it/s, v_num=llhr]
Epoch 16:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.85it/s, v_num=llhr]
Epoch 16:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.13it/s, v_num=llhr]
Epoch 16:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.13it/s, v_num=llhr]
Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.32it/s, v_num=llhr]
Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.32it/s, v_num=llhr]
Epoch 16:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.40it/s, v_num=llhr]
Epoch 16:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.39it/s, v_num=llhr]
Epoch 16:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.42it/s, v_num=llhr]
Epoch 16:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.42it/s, v_num=llhr]
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.45it/s, v_num=llhr]
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.45it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.10it/s][A

                                                                      [A
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:06<00:00,  0.96it/s, v_num=llhr]
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:06<00:00,  0.96it/s, v_num=llhr]
Epoch 16:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 17:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 17:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.72it/s, v_num=llhr]
Epoch 17:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.72it/s, v_num=llhr]
Epoch 17:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:02<00:04,  0.97it/s, v_num=llhr]
Epoch 17:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:02<00:04,  0.97it/s, v_num=llhr]
Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.22it/s, v_num=llhr]
Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.22it/s, v_num=llhr]
Epoch 17:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.42it/s, v_num=llhr]
Epoch 17:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.42it/s, v_num=llhr]
Epoch 17:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.58it/s, v_num=llhr]
Epoch 17:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.58it/s, v_num=llhr]
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.69it/s, v_num=llhr]
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.69it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s][A

                                                                      [A
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.31it/s, v_num=llhr]
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.30it/s, v_num=llhr]
Epoch 17:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 18:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 18:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.92it/s, v_num=llhr]
Epoch 18:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.92it/s, v_num=llhr]
Epoch 18:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.37it/s, v_num=llhr]
Epoch 18:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.37it/s, v_num=llhr]
Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.63it/s, v_num=llhr]
Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.63it/s, v_num=llhr]
Epoch 18:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.83it/s, v_num=llhr]
Epoch 18:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.83it/s, v_num=llhr]
Epoch 18:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.99it/s, v_num=llhr]
Epoch 18:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.98it/s, v_num=llhr]
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.10it/s, v_num=llhr]
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.10it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s][A

                                                                      [A
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.53it/s, v_num=llhr]
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.52it/s, v_num=llhr]
Epoch 18:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 19:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 19:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.70it/s, v_num=llhr]
Epoch 19:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.70it/s, v_num=llhr]
Epoch 19:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.06it/s, v_num=llhr]
Epoch 19:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.06it/s, v_num=llhr]
Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.35it/s, v_num=llhr]
Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.35it/s, v_num=llhr]
Epoch 19:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.54it/s, v_num=llhr]
Epoch 19:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.54it/s, v_num=llhr]
Epoch 19:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.67it/s, v_num=llhr]
Epoch 19:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.67it/s, v_num=llhr]
Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.79it/s, v_num=llhr]
Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.79it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.80it/s][A

                                                                      [A
Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.39it/s, v_num=llhr]
Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.39it/s, v_num=llhr]
Epoch 19:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 20:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 20:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.89it/s, v_num=llhr]
Epoch 20:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.89it/s, v_num=llhr]
Epoch 20:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.37it/s, v_num=llhr]
Epoch 20:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.37it/s, v_num=llhr]
Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.65it/s, v_num=llhr]
Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  1.65it/s, v_num=llhr]
Epoch 20:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.82it/s, v_num=llhr]
Epoch 20:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.82it/s, v_num=llhr]
Epoch 20:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.88it/s, v_num=llhr]
Epoch 20:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.88it/s, v_num=llhr]
Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.94it/s, v_num=llhr]
Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.94it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.42it/s][A

                                                                      [A
Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.13it/s, v_num=llhr]
Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.12it/s, v_num=llhr]
Epoch 20:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 21:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 21:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.90it/s, v_num=llhr]
Epoch 21:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.90it/s, v_num=llhr]
Epoch 21:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.14it/s, v_num=llhr]
Epoch 21:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.14it/s, v_num=llhr]
Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.27it/s, v_num=llhr]
Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.26it/s, v_num=llhr]
Epoch 21:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.34it/s, v_num=llhr]
Epoch 21:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.34it/s, v_num=llhr]
Epoch 21:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.46it/s, v_num=llhr]
Epoch 21:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.46it/s, v_num=llhr]
Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.59it/s, v_num=llhr]
Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.59it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.67it/s][A

                                                                      [A
Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.20it/s, v_num=llhr]
Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.20it/s, v_num=llhr]
Epoch 21:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 22:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 22:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.65it/s, v_num=llhr]
Epoch 22:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.65it/s, v_num=llhr]
Epoch 22:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.03it/s, v_num=llhr]
Epoch 22:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.03it/s, v_num=llhr]
Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.30it/s, v_num=llhr]
Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.30it/s, v_num=llhr]
Epoch 22:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.50it/s, v_num=llhr]
Epoch 22:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.50it/s, v_num=llhr]
Epoch 22:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.66it/s, v_num=llhr]
Epoch 22:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.66it/s, v_num=llhr]
Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.78it/s, v_num=llhr]
Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.78it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.63it/s][A

                                                                      [A
Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.37it/s, v_num=llhr]
Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.37it/s, v_num=llhr]
Epoch 22:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 23:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 23:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.71it/s, v_num=llhr]
Epoch 23:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.71it/s, v_num=llhr]
Epoch 23:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:02<00:04,  0.99it/s, v_num=llhr]
Epoch 23:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:02<00:04,  0.99it/s, v_num=llhr]
Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.24it/s, v_num=llhr]
Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.24it/s, v_num=llhr]
Epoch 23:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.44it/s, v_num=llhr]
Epoch 23:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.44it/s, v_num=llhr]
Epoch 23:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.60it/s, v_num=llhr]
Epoch 23:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.60it/s, v_num=llhr]
Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.72it/s, v_num=llhr]
Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.72it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.84it/s][A

                                                                      [A
Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.31it/s, v_num=llhr]
Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.30it/s, v_num=llhr]
Epoch 23:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 24:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 24:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.68it/s, v_num=llhr]
Epoch 24:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.68it/s, v_num=llhr]
Epoch 24:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:02<00:04,  0.91it/s, v_num=llhr]
Epoch 24:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:02<00:04,  0.91it/s, v_num=llhr]
Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.11it/s, v_num=llhr]
Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.11it/s, v_num=llhr]
Epoch 24:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:03<00:01,  1.31it/s, v_num=llhr]
Epoch 24:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:03<00:01,  1.31it/s, v_num=llhr]
Epoch 24:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.49it/s, v_num=llhr]
Epoch 24:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.49it/s, v_num=llhr]
Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.62it/s, v_num=llhr]
Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.62it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.49it/s][A

                                                                      [A
Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.21it/s, v_num=llhr]
Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.20it/s, v_num=llhr]
Epoch 24:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 25:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 25:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.65it/s, v_num=llhr]
Epoch 25:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.65it/s, v_num=llhr]
Epoch 25:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.05it/s, v_num=llhr]
Epoch 25:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.05it/s, v_num=llhr]
Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.33it/s, v_num=llhr]
Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.33it/s, v_num=llhr]
Epoch 25:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.53it/s, v_num=llhr]
Epoch 25:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.53it/s, v_num=llhr]
Epoch 25:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.68it/s, v_num=llhr]
Epoch 25:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  1.68it/s, v_num=llhr]
Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.80it/s, v_num=llhr]
Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.80it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s][A

                                                                      [A
Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.18it/s, v_num=llhr]
Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.18it/s, v_num=llhr]
Epoch 25:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]        
Epoch 26:   0%|          | 0/6 [00:00<?, ?it/s, v_num=llhr]
Epoch 26:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.68it/s, v_num=llhr]
Epoch 26:  17%|‚ñà‚ñã        | 1/6 [00:01<00:07,  0.68it/s, v_num=llhr]
Epoch 26:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:02<00:04,  0.97it/s, v_num=llhr]
Epoch 26:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:02<00:04,  0.97it/s, v_num=llhr]
Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.22it/s, v_num=llhr]
Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.22it/s, v_num=llhr]
Epoch 26:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.43it/s, v_num=llhr]
Epoch 26:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.43it/s, v_num=llhr]
Epoch 26:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.59it/s, v_num=llhr]
Epoch 26:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.59it/s, v_num=llhr]
Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.63it/s, v_num=llhr]
Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.63it/s, v_num=llhr]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.24it/s][A[rank: 1] Child process with PID 1170256 terminated with code -9. Forcefully terminating all other processes to avoid zombies üßü
2025-04-10 14:42:35,818 - wandb.wandb_agent - INFO - Cleaning up finished run: ydq8llhr
[2025-04-10 14:42:35,818][wandb.wandb_agent][INFO] - Cleaning up finished run: ydq8llhr
2025-04-10 14:42:36,569 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:42:36,569][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:42:36,570 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.1835703809603332
	config.input_dropout: 0.02231367161627912
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.198066128599958
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: last
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 12
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.12633915445725638
	optimization_config.init_lr: 0.5476144198132562
	optimization_config.lr_decay_power: 1.004586514384448
	optimization_config.lr_frac_warmup_steps: 0.009583319727632315
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.007895016967838528
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:42:36,570][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.1835703809603332
	config.input_dropout: 0.02231367161627912
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.198066128599958
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: last
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 12
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.12633915445725638
	optimization_config.init_lr: 0.5476144198132562
	optimization_config.lr_decay_power: 1.004586514384448
	optimization_config.lr_frac_warmup_steps: 0.009583319727632315
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.007895016967838528
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:42:36,576 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.1835703809603332 config.input_dropout=0.02231367161627912 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.198066128599958 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=last data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=12 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.12633915445725638 optimization_config.init_lr=0.5476144198132562 optimization_config.lr_decay_power=1.004586514384448 optimization_config.lr_frac_warmup_steps=0.009583319727632315 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.007895016967838528 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:42:36,576][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.1835703809603332 config.input_dropout=0.02231367161627912 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.198066128599958 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=last data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=12 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.12633915445725638 optimization_config.init_lr=0.5476144198132562 optimization_config.lr_decay_power=1.004586514384448 optimization_config.lr_frac_warmup_steps=0.009583319727632315 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.007895016967838528 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
2025-04-10 14:42:41,587 - wandb.wandb_agent - INFO - Running runs: ['s12od9wz']
[2025-04-10 14:42:41,587][wandb.wandb_agent][INFO] - Running runs: ['s12od9wz']
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_144244-s12od9wz
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/s12od9wz
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.1835703809603332
Overwriting input_dropout in config from 0.4494236115512016 to 0.02231367161627912
Overwriting resid_dropout in config from 0.4939188761966135 to 0.198066128599958
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'last', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.1835703809603332
Overwriting input_dropout in config from 0.4494236115512016 to 0.02231367161627912
Overwriting resid_dropout in config from 0.4939188761966135 to 0.198066128599958
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'last', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.45it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/7 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] /home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.
  warnings.warn(*args, **kwargs)

Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00<00:03,  1.69it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00<00:03,  1.69it/s, v_num=d9wz]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.34it/s, v_num=d9wz]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:02,  2.34it/s, v_num=d9wz]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.72it/s, v_num=d9wz]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.72it/s, v_num=d9wz]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.91it/s, v_num=d9wz]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.91it/s, v_num=d9wz]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.14it/s, v_num=d9wz]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  3.13it/s, v_num=d9wz]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.29it/s, v_num=d9wz]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.29it/s, v_num=d9wz]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.41it/s, v_num=d9wz]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.41it/s, v_num=d9wz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.18it/s][A

                                                                      [A
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.57it/s, v_num=d9wz]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.56it/s, v_num=d9wz]
Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s, v_num=d9wz]        
Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=d9wz]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00<00:05,  1.12it/s, v_num=d9wz]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00<00:05,  1.12it/s, v_num=d9wz]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.72it/s, v_num=d9wz]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.72it/s, v_num=d9wz]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.15it/s, v_num=d9wz]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.15it/s, v_num=d9wz]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.46it/s, v_num=d9wz]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.46it/s, v_num=d9wz]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.69it/s, v_num=d9wz]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.69it/s, v_num=d9wz]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.86it/s, v_num=d9wz]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.86it/s, v_num=d9wz]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.01it/s, v_num=d9wz]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.01it/s, v_num=d9wz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.44it/s][A

                                                                      [A
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:03<00:00,  2.33it/s, v_num=d9wz]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:03<00:00,  2.33it/s, v_num=d9wz]
Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=d9wz]        
Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=d9wz]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.22it/s, v_num=d9wz]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.22it/s, v_num=d9wz]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.89it/s, v_num=d9wz]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:02,  1.89it/s, v_num=d9wz]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.33it/s, v_num=d9wz]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.33it/s, v_num=d9wz]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.60it/s, v_num=d9wz]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.60it/s, v_num=d9wz]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.75it/s, v_num=d9wz]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.75it/s, v_num=d9wz]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.84it/s, v_num=d9wz]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:02<00:00,  2.84it/s, v_num=d9wz]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.87it/s, v_num=d9wz]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.87it/s, v_num=d9wz]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.86it/s][A[rank: 1] Child process with PID 1177745 terminated with code -9. Forcefully terminating all other processes to avoid zombies üßü
2025-04-10 14:43:07,471 - wandb.wandb_agent - INFO - Cleaning up finished run: s12od9wz
[2025-04-10 14:43:07,471][wandb.wandb_agent][INFO] - Cleaning up finished run: s12od9wz
2025-04-10 14:43:08,052 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:43:08,052][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:43:08,052 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.05851032806345424
	config.input_dropout: 0.16397598196697344
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.2862976459701478
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: last
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 14
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.007214684804938199
	optimization_config.init_lr: 3.863395404460505e-07
	optimization_config.lr_decay_power: 4.561873578521885
	optimization_config.lr_frac_warmup_steps: 0.27927144485216654
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.008456437090384962
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:43:08,052][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.05851032806345424
	config.input_dropout: 0.16397598196697344
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.2862976459701478
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: last
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 14
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.007214684804938199
	optimization_config.init_lr: 3.863395404460505e-07
	optimization_config.lr_decay_power: 4.561873578521885
	optimization_config.lr_frac_warmup_steps: 0.27927144485216654
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.008456437090384962
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:43:08,059 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.05851032806345424 config.input_dropout=0.16397598196697344 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.2862976459701478 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=last data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=14 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.007214684804938199 optimization_config.init_lr=3.863395404460505e-07 optimization_config.lr_decay_power=4.561873578521885 optimization_config.lr_frac_warmup_steps=0.27927144485216654 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.008456437090384962 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:43:08,059][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.05851032806345424 config.input_dropout=0.16397598196697344 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.2862976459701478 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=last data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=14 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.007214684804938199 optimization_config.init_lr=3.863395404460505e-07 optimization_config.lr_decay_power=4.561873578521885 optimization_config.lr_frac_warmup_steps=0.27927144485216654 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.008456437090384962 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
2025-04-10 14:43:13,069 - wandb.wandb_agent - INFO - Running runs: ['3pd3xp4r']
[2025-04-10 14:43:13,069][wandb.wandb_agent][INFO] - Running runs: ['3pd3xp4r']
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_144316-3pd3xp4r
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/3pd3xp4r
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.05851032806345424
Overwriting input_dropout in config from 0.4494236115512016 to 0.16397598196697344
Overwriting resid_dropout in config from 0.4939188761966135 to 0.2862976459701478
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'last', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.05851032806345424
Overwriting input_dropout in config from 0.4494236115512016 to 0.16397598196697344
Overwriting resid_dropout in config from 0.4939188761966135 to 0.2862976459701478
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'last', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  0.83it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/6 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/6 [00:00<?, ?it/s] /home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.
  warnings.warn(*args, **kwargs)

Epoch 0:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.87it/s]
Epoch 0:  17%|‚ñà‚ñã        | 1/6 [00:01<00:05,  0.87it/s, v_num=xp4r]
Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.13it/s, v_num=xp4r]
Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.13it/s, v_num=xp4r]
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.26it/s, v_num=xp4r]
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.26it/s, v_num=xp4r]
Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.35it/s, v_num=xp4r]
Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:02<00:01,  1.35it/s, v_num=xp4r]
Epoch 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.41it/s, v_num=xp4r]
Epoch 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:03<00:00,  1.41it/s, v_num=xp4r]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.44it/s, v_num=xp4r]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.44it/s, v_num=xp4r]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.33it/s][A

                                                                      [A
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:06<00:00,  0.95it/s, v_num=xp4r]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:06<00:00,  0.95it/s, v_num=xp4r]
Epoch 0:   0%|          | 0/6 [00:00<?, ?it/s, v_num=xp4r]        
Epoch 1:   0%|          | 0/6 [00:00<?, ?it/s, v_num=xp4r]
Epoch 1:  17%|‚ñà‚ñã        | 1/6 [00:00<00:04,  1.10it/s, v_num=xp4r]
Epoch 1:  17%|‚ñà‚ñã        | 1/6 [00:00<00:04,  1.10it/s, v_num=xp4r]
Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.73it/s, v_num=xp4r]
Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:02,  1.73it/s, v_num=xp4r]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  2.04it/s, v_num=xp4r]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  2.04it/s, v_num=xp4r]
Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:01<00:00,  2.32it/s, v_num=xp4r]
Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:01<00:00,  2.32it/s, v_num=xp4r]
Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  2.31it/s, v_num=xp4r]
Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:02<00:00,  2.31it/s, v_num=xp4r]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.48it/s, v_num=xp4r]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.48it/s, v_num=xp4r]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.30it/s][A

                                                                      [A
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.41it/s, v_num=xp4r]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.41it/s, v_num=xp4r]
Epoch 1:   0%|          | 0/6 [00:00<?, ?it/s, v_num=xp4r]        
Epoch 2:   0%|          | 0/6 [00:00<?, ?it/s, v_num=xp4r]
Epoch 2:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.80it/s, v_num=xp4r]
Epoch 2:  17%|‚ñà‚ñã        | 1/6 [00:01<00:06,  0.80it/s, v_num=xp4r]
Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.11it/s, v_num=xp4r]
Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.11it/s, v_num=xp4r]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.27it/s, v_num=xp4r]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:02<00:02,  1.27it/s, v_num=xp4r][rank: 1] Child process with PID 1179435 terminated with code -9. Forcefully terminating all other processes to avoid zombies üßü
2025-04-10 14:43:49,230 - wandb.wandb_agent - INFO - Cleaning up finished run: 3pd3xp4r
[2025-04-10 14:43:49,230][wandb.wandb_agent][INFO] - Cleaning up finished run: 3pd3xp4r
2025-04-10 14:43:49,823 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:43:49,823][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:43:49,824 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.04433832058132536
	config.input_dropout: 0.1855682350827
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.02496240342756939
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: max
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 32
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.008688883819444226
	optimization_config.init_lr: 0.8929708117631892
	optimization_config.lr_decay_power: 3.5189064243510857
	optimization_config.lr_frac_warmup_steps: 5.7168131530058265e-06
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.006998014702659846
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:43:49,824][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.04433832058132536
	config.input_dropout: 0.1855682350827
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.02496240342756939
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: max
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 32
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.008688883819444226
	optimization_config.init_lr: 0.8929708117631892
	optimization_config.lr_decay_power: 3.5189064243510857
	optimization_config.lr_frac_warmup_steps: 5.7168131530058265e-06
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.006998014702659846
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:43:49,831 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.04433832058132536 config.input_dropout=0.1855682350827 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.02496240342756939 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=max data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=32 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.008688883819444226 optimization_config.init_lr=0.8929708117631892 optimization_config.lr_decay_power=3.5189064243510857 optimization_config.lr_frac_warmup_steps=5.7168131530058265e-06 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.006998014702659846 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:43:49,831][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.04433832058132536 config.input_dropout=0.1855682350827 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.02496240342756939 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=max data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=32 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.008688883819444226 optimization_config.init_lr=0.8929708117631892 optimization_config.lr_decay_power=3.5189064243510857 optimization_config.lr_frac_warmup_steps=5.7168131530058265e-06 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.006998014702659846 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
2025-04-10 14:43:54,840 - wandb.wandb_agent - INFO - Running runs: ['mbkzs4rs']
[2025-04-10 14:43:54,840][wandb.wandb_agent][INFO] - Running runs: ['mbkzs4rs']
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_144357-mbkzs4rs
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/mbkzs4rs
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.04433832058132536
Overwriting input_dropout in config from 0.4494236115512016 to 0.1855682350827
Overwriting resid_dropout in config from 0.4939188761966135 to 0.02496240342756939
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'max', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.04433832058132536
Overwriting input_dropout in config from 0.4494236115512016 to 0.1855682350827
Overwriting resid_dropout in config from 0.4939188761966135 to 0.02496240342756939
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'max', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.48it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/3 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s] 
Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.93it/s]
Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.93it/s, v_num=s4rs]/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.
  warnings.warn(*args, **kwargs)

Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.50it/s, v_num=s4rs]
Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.50it/s, v_num=s4rs]Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 378, in wrap
    fn_return = task_func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/fine_tuning_dev.py", line 388, in train
    trainer.fit(model=LM, train_dataloaders=train_dataloader, val_dataloaders=tuning_dataloader)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
    self.advance(data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 320, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 176, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1302, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 140, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 493, in wrapper
    out = func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
    loss = closure()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 390, in training_step
    return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
    wrapper_output = wrapper_module(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
    out = method(*_args, **_kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/generative_modeling.py", line 488, in training_step
    out_tuple = self.model(batch)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/conditionally_independent_model.py", line 329, in forward
    encoded = self.encoder(batch, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/transformer.py", line 828, in forward
    torch._assert(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/__init__.py", line 2132, in _assert
    assert condition, message
AssertionError: 601920 NaNs in input_embeds
None
EXCEPTION: 601920 NaNs in input_embeds
Error executing job with overrides: ['config.attention_dropout=0.04433832058132536', 'config.input_dropout=0.1855682350827', 'config.is_cls_dist=False', 'config.is_event_classification=True', 'config.resid_dropout=0.02496240342756939', 'config.save_metrics=False', 'config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test', 'config.task_specific_params.pooling_method=max', 'data_config.max_seq_len=256', 'data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield', 'do_overwrite=True', 'load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/', 'optimization_config.batch_size=32', 'optimization_config.end_lr=null', 'optimization_config.end_lr_frac_of_init_lr=0.008688883819444226', 'optimization_config.init_lr=0.8929708117631892', 'optimization_config.lr_decay_power=3.5189064243510857', 'optimization_config.lr_frac_warmup_steps=5.7168131530058265e-06', 'optimization_config.max_epochs=200', 'optimization_config.num_dataloader_workers=5', 'optimization_config.patience=10', 'optimization_config.weight_decay=0.006998014702659846', 'pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights', 'seed=1', 'task_df_name=task_df_eneryield_event_label', 'trainer_config.detect_anomaly=False', 'trainer_config.log_every_n_steps=50', 'wandb_logger_kwargs.do_log_graph=False', 'wandb_logger_kwargs.log_model=False', 'wandb_logger_kwargs.name=generative_event_stream_transformer', 'wandb_logger_kwargs.project=eneryield_ft_sweep']
Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 378, in wrap
    fn_return = task_func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/fine_tuning_dev.py", line 388, in train
    trainer.fit(model=LM, train_dataloaders=train_dataloader, val_dataloaders=tuning_dataloader)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
    self.advance(data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 320, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 176, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1302, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 140, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 493, in wrapper
    out = func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
    loss = closure()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 390, in training_step
    return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
    wrapper_output = wrapper_module(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
    out = method(*_args, **_kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/generative_modeling.py", line 488, in training_step
    out_tuple = self.model(batch)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/conditionally_independent_model.py", line 329, in forward
    encoded = self.encoder(batch, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/transformer.py", line 828, in forward
    torch._assert(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/__init__.py", line 2132, in _assert
    assert condition, message
AssertionError: 523440 NaNs in input_embeds
None
wandb: Waiting for W&B process to finish... (success).
Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/scripts/finetune.py", line 44, in main
    return train(cfg)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 385, in wrap
    raise ex
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 378, in wrap
    fn_return = task_func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/fine_tuning_dev.py", line 388, in train
    trainer.fit(model=LM, train_dataloaders=train_dataloader, val_dataloaders=tuning_dataloader)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
    self.advance(data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 320, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 176, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1302, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 140, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 493, in wrapper
    out = func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
    loss = closure()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 390, in training_step
    return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
    wrapper_output = wrapper_module(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
    out = method(*_args, **_kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/generative_modeling.py", line 488, in training_step
    out_tuple = self.model(batch)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/conditionally_independent_model.py", line 329, in forward
    encoded = self.encoder(batch, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/transformer.py", line 828, in forward
    torch._assert(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/__init__.py", line 2132, in _assert
    assert condition, message
AssertionError: 601920 NaNs in input_embeds

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[rank: 1] Child process with PID 1181294 terminated with code 1. Forcefully terminating all other processes to avoid zombies üßü
2025-04-10 14:44:15,514 - wandb.wandb_agent - INFO - Cleaning up finished run: mbkzs4rs
[2025-04-10 14:44:15,514][wandb.wandb_agent][INFO] - Cleaning up finished run: mbkzs4rs
2025-04-10 14:44:16,051 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:44:16,051][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:44:16,051 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.03463675747722844
	config.input_dropout: 0.06531869329331452
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.4945703122294177
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: max
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 52
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.0001457527180544808
	optimization_config.init_lr: 0.005965629693153047
	optimization_config.lr_decay_power: 2.1238035204672125
	optimization_config.lr_frac_warmup_steps: 0.2146211383472891
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.003530307434197978
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:44:16,051][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.03463675747722844
	config.input_dropout: 0.06531869329331452
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.4945703122294177
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: max
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 52
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.0001457527180544808
	optimization_config.init_lr: 0.005965629693153047
	optimization_config.lr_decay_power: 2.1238035204672125
	optimization_config.lr_frac_warmup_steps: 0.2146211383472891
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.003530307434197978
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:44:16,058 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.03463675747722844 config.input_dropout=0.06531869329331452 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.4945703122294177 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=max data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=52 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.0001457527180544808 optimization_config.init_lr=0.005965629693153047 optimization_config.lr_decay_power=2.1238035204672125 optimization_config.lr_frac_warmup_steps=0.2146211383472891 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.003530307434197978 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:44:16,058][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.03463675747722844 config.input_dropout=0.06531869329331452 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.4945703122294177 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=max data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=52 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.0001457527180544808 optimization_config.init_lr=0.005965629693153047 optimization_config.lr_decay_power=2.1238035204672125 optimization_config.lr_frac_warmup_steps=0.2146211383472891 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.003530307434197978 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
2025-04-10 14:44:21,070 - wandb.wandb_agent - INFO - Running runs: ['4xk2lzqe']
[2025-04-10 14:44:21,070][wandb.wandb_agent][INFO] - Running runs: ['4xk2lzqe']
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_144425-4xk2lzqe
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/4xk2lzqe
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.03463675747722844
Overwriting input_dropout in config from 0.4494236115512016 to 0.06531869329331452
Overwriting resid_dropout in config from 0.4939188761966135 to 0.4945703122294177
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'max', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.03463675747722844
Overwriting input_dropout in config from 0.4494236115512016 to 0.06531869329331452
Overwriting resid_dropout in config from 0.4939188761966135 to 0.4945703122294177
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'max', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  0.63it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/2 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] 
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.61it/s]
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.61it/s, v_num=lzqe]/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.
  warnings.warn(*args, **kwargs)

Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.87it/s, v_num=lzqe]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.87it/s, v_num=lzqe]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.02it/s][A

                                                                      [A
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  0.46it/s, v_num=lzqe]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  0.46it/s, v_num=lzqe]
Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s, v_num=lzqe]        
Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=lzqe]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  0.49it/s, v_num=lzqe]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  0.49it/s, v_num=lzqe]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.74it/s, v_num=lzqe]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.74it/s, v_num=lzqe]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.53it/s][A

                                                                      [A
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  0.42it/s, v_num=lzqe]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  0.41it/s, v_num=lzqe]
Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=lzqe]        
Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=lzqe]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.66it/s, v_num=lzqe]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.66it/s, v_num=lzqe]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.05it/s, v_num=lzqe]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.05it/s, v_num=lzqe]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.71it/s][A

                                                                      [A
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  0.66it/s, v_num=lzqe]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  0.66it/s, v_num=lzqe]
Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=lzqe]        
Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, v_num=lzqe]
Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.61it/s, v_num=lzqe]
Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.61it/s, v_num=lzqe]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.00it/s, v_num=lzqe]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.00it/s, v_num=lzqe]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.95it/s][A

                                                                      [A
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.68it/s, v_num=lzqe]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.68it/s, v_num=lzqe]
Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, v_num=lzqe]        
Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, v_num=lzqe]
Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.56it/s, v_num=lzqe]
Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.56it/s, v_num=lzqe]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.82it/s, v_num=lzqe]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.82it/s, v_num=lzqe]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s][A

                                                                      [A
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  0.45it/s, v_num=lzqe]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  0.45it/s, v_num=lzqe]
Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, v_num=lzqe]        
Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, v_num=lzqe][rank: 1] Child process with PID 1182910 terminated with code -9. Forcefully terminating all other processes to avoid zombies üßü
2025-04-10 14:45:02,465 - wandb.wandb_agent - INFO - Cleaning up finished run: 4xk2lzqe
[2025-04-10 14:45:02,465][wandb.wandb_agent][INFO] - Cleaning up finished run: 4xk2lzqe
2025-04-10 14:45:03,045 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:45:03,045][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:45:03,046 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.3285890189611502
	config.input_dropout: 0.3727923682927825
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.03770082939904745
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: cls
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 33
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.00022993394369088605
	optimization_config.init_lr: 0.02088507140090064
	optimization_config.lr_decay_power: 2.9387126637055845
	optimization_config.lr_frac_warmup_steps: 0.08679275154095659
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.006720947485860205
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:45:03,046][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.3285890189611502
	config.input_dropout: 0.3727923682927825
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.03770082939904745
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: cls
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 33
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.00022993394369088605
	optimization_config.init_lr: 0.02088507140090064
	optimization_config.lr_decay_power: 2.9387126637055845
	optimization_config.lr_frac_warmup_steps: 0.08679275154095659
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.006720947485860205
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:45:03,053 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.3285890189611502 config.input_dropout=0.3727923682927825 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.03770082939904745 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=cls data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=33 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.00022993394369088605 optimization_config.init_lr=0.02088507140090064 optimization_config.lr_decay_power=2.9387126637055845 optimization_config.lr_frac_warmup_steps=0.08679275154095659 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.006720947485860205 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:45:03,053][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.3285890189611502 config.input_dropout=0.3727923682927825 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.03770082939904745 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=cls data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=33 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.00022993394369088605 optimization_config.init_lr=0.02088507140090064 optimization_config.lr_decay_power=2.9387126637055845 optimization_config.lr_frac_warmup_steps=0.08679275154095659 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.006720947485860205 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
2025-04-10 14:45:08,066 - wandb.wandb_agent - INFO - Running runs: ['izd1usvo']
[2025-04-10 14:45:08,066][wandb.wandb_agent][INFO] - Running runs: ['izd1usvo']
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_144512-izd1usvo
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/izd1usvo
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.3285890189611502
Overwriting input_dropout in config from 0.4494236115512016 to 0.3727923682927825
Overwriting resid_dropout in config from 0.4939188761966135 to 0.03770082939904745
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'cls', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.3285890189611502
Overwriting input_dropout in config from 0.4494236115512016 to 0.3727923682927825
Overwriting resid_dropout in config from 0.4939188761966135 to 0.03770082939904745
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'cls', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  0.70it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/3 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s] 
Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.68it/s]
Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.68it/s, v_num=usvo]/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.
  warnings.warn(*args, **kwargs)

Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.91it/s, v_num=usvo]
Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.91it/s, v_num=usvo]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.08it/s, v_num=usvo]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.08it/s, v_num=usvo]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.87it/s][A

                                                                      [A
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.79it/s, v_num=usvo]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.79it/s, v_num=usvo]
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]        
Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]
Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.77it/s, v_num=usvo]
Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.77it/s, v_num=usvo]
Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.27it/s, v_num=usvo]
Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.27it/s, v_num=usvo]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.64it/s, v_num=usvo]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.64it/s, v_num=usvo]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.74it/s][A

                                                                      [A
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.11it/s, v_num=usvo]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.11it/s, v_num=usvo]
Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]        
Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]
Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.87it/s, v_num=usvo]
Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.86it/s, v_num=usvo]
Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.25it/s, v_num=usvo]
Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.25it/s, v_num=usvo]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.49it/s, v_num=usvo]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.49it/s, v_num=usvo]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.41it/s][A

                                                                      [A
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.98it/s, v_num=usvo]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.97it/s, v_num=usvo]
Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]        
Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]
Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.69it/s, v_num=usvo]
Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.69it/s, v_num=usvo]
Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.94it/s, v_num=usvo]
Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  0.94it/s, v_num=usvo]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.11it/s, v_num=usvo]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.11it/s, v_num=usvo]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s][A

                                                                      [A
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.64it/s, v_num=usvo]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  0.64it/s, v_num=usvo]
Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]        
Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]
Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.82it/s, v_num=usvo]
Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.82it/s, v_num=usvo]
Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.34it/s, v_num=usvo]
Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.34it/s, v_num=usvo]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.69it/s, v_num=usvo]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.69it/s, v_num=usvo]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.11it/s][A

                                                                      [A
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.79it/s, v_num=usvo]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.79it/s, v_num=usvo]
Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]        
Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]
Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.64it/s, v_num=usvo]
Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  0.63it/s, v_num=usvo]
Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.07it/s, v_num=usvo]
Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.07it/s, v_num=usvo]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.35it/s, v_num=usvo]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.35it/s, v_num=usvo]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s][A

                                                                      [A
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.97it/s, v_num=usvo]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  0.97it/s, v_num=usvo]
Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]        
Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, v_num=usvo]
Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.74it/s, v_num=usvo]
Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  0.74it/s, v_num=usvo]
Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.15it/s, v_num=usvo]
Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.14it/s, v_num=usvo]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.45it/s, v_num=usvo]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.45it/s, v_num=usvo]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.02it/s][A[rank: 1] Child process with PID 1185153 terminated with code -9. Forcefully terminating all other processes to avoid zombies üßü
2025-04-10 14:45:54,596 - wandb.wandb_agent - INFO - Cleaning up finished run: izd1usvo
[2025-04-10 14:45:54,596][wandb.wandb_agent][INFO] - Cleaning up finished run: izd1usvo
2025-04-10 14:45:55,399 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:45:55,399][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:45:55,399 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.04473605318207036
	config.input_dropout: 0.17220329104183174
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.29454200842388734
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: cls
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 55
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.00019344120871045233
	optimization_config.init_lr: 0.4824544449550824
	optimization_config.lr_decay_power: 2.352031988028803
	optimization_config.lr_frac_warmup_steps: 7.794206159249655e-05
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.0015239076422735643
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:45:55,399][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.04473605318207036
	config.input_dropout: 0.17220329104183174
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.29454200842388734
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: cls
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 55
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.00019344120871045233
	optimization_config.init_lr: 0.4824544449550824
	optimization_config.lr_decay_power: 2.352031988028803
	optimization_config.lr_frac_warmup_steps: 7.794206159249655e-05
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.0015239076422735643
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:45:55,405 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.04473605318207036 config.input_dropout=0.17220329104183174 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.29454200842388734 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=cls data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=55 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.00019344120871045233 optimization_config.init_lr=0.4824544449550824 optimization_config.lr_decay_power=2.352031988028803 optimization_config.lr_frac_warmup_steps=7.794206159249655e-05 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.0015239076422735643 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:45:55,405][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.04473605318207036 config.input_dropout=0.17220329104183174 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.29454200842388734 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=cls data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=55 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.00019344120871045233 optimization_config.init_lr=0.4824544449550824 optimization_config.lr_decay_power=2.352031988028803 optimization_config.lr_frac_warmup_steps=7.794206159249655e-05 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.0015239076422735643 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
2025-04-10 14:46:00,415 - wandb.wandb_agent - INFO - Running runs: ['y8g9bo7m']
[2025-04-10 14:46:00,415][wandb.wandb_agent][INFO] - Running runs: ['y8g9bo7m']
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_144603-y8g9bo7m
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/y8g9bo7m
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.04473605318207036
Overwriting input_dropout in config from 0.4494236115512016 to 0.17220329104183174
Overwriting resid_dropout in config from 0.4939188761966135 to 0.29454200842388734
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'cls', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_event_label', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting max_seq_len in data_config from 256 to 256
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.04473605318207036
Overwriting input_dropout in config from 0.4494236115512016 to 0.17220329104183174
Overwriting resid_dropout in config from 0.4939188761966135 to 0.29454200842388734
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to True
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'cls', 'num_samples': None}
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/train_0.parquet
Re-loading task data for task_df_eneryield_event_label from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_event_label/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.47it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/2 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] 
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.61it/s]
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.61it/s, v_num=bo7m]/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.
  warnings.warn(*args, **kwargs)

Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.90it/s, v_num=bo7m]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.90it/s, v_num=bo7m]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][ATraceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 378, in wrap
    fn_return = task_func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/fine_tuning_dev.py", line 388, in train
    trainer.fit(model=LM, train_dataloaders=train_dataloader, val_dataloaders=tuning_dataloader)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 151, in run
    self.on_advance_end(data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 370, in on_advance_end
    self.val_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 411, in validation_step
    return self._forward_redirection(self.model, self.lightning_module, "validation_step", *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
    wrapper_output = wrapper_module(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
    out = method(*_args, **_kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/generative_modeling.py", line 527, in validation_step
    out_tuple = self.model(batch)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/conditionally_independent_model.py", line 329, in forward
    encoded = self.encoder(batch, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/transformer.py", line 828, in forward
    torch._assert(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/__init__.py", line 2132, in _assert
    assert condition, message
AssertionError: 383400 NaNs in input_embeds
None
EXCEPTION: 383400 NaNs in input_embeds
Error executing job with overrides: ['config.attention_dropout=0.04473605318207036', 'config.input_dropout=0.17220329104183174', 'config.is_cls_dist=False', 'config.is_event_classification=True', 'config.resid_dropout=0.29454200842388734', 'config.save_metrics=False', 'config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test', 'config.task_specific_params.pooling_method=cls', 'data_config.max_seq_len=256', 'data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield', 'do_overwrite=True', 'load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/', 'optimization_config.batch_size=55', 'optimization_config.end_lr=null', 'optimization_config.end_lr_frac_of_init_lr=0.00019344120871045233', 'optimization_config.init_lr=0.4824544449550824', 'optimization_config.lr_decay_power=2.352031988028803', 'optimization_config.lr_frac_warmup_steps=7.794206159249655e-05', 'optimization_config.max_epochs=200', 'optimization_config.num_dataloader_workers=5', 'optimization_config.patience=10', 'optimization_config.weight_decay=0.0015239076422735643', 'pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights', 'seed=1', 'task_df_name=task_df_eneryield_event_label', 'trainer_config.detect_anomaly=False', 'trainer_config.log_every_n_steps=50', 'wandb_logger_kwargs.do_log_graph=False', 'wandb_logger_kwargs.log_model=False', 'wandb_logger_kwargs.name=generative_event_stream_transformer', 'wandb_logger_kwargs.project=eneryield_ft_sweep']
Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 378, in wrap
    fn_return = task_func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/fine_tuning_dev.py", line 388, in train
    trainer.fit(model=LM, train_dataloaders=train_dataloader, val_dataloaders=tuning_dataloader)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 151, in run
    self.on_advance_end(data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 370, in on_advance_end
    self.val_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 411, in validation_step
    return self._forward_redirection(self.model, self.lightning_module, "validation_step", *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
    wrapper_output = wrapper_module(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
    out = method(*_args, **_kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/generative_modeling.py", line 527, in validation_step
    out_tuple = self.model(batch)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/conditionally_independent_model.py", line 329, in forward
    encoded = self.encoder(batch, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/transformer.py", line 828, in forward
    torch._assert(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/__init__.py", line 2132, in _assert
    assert condition, message
AssertionError: 264240 NaNs in input_embeds
None
wandb: Waiting for W&B process to finish... (success).
Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/scripts/finetune.py", line 44, in main
    return train(cfg)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 385, in wrap
    raise ex
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 378, in wrap
    fn_return = task_func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/fine_tuning_dev.py", line 388, in train
    trainer.fit(model=LM, train_dataloaders=train_dataloader, val_dataloaders=tuning_dataloader)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 151, in run
    self.on_advance_end(data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 370, in on_advance_end
    self.val_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 411, in validation_step
    return self._forward_redirection(self.model, self.lightning_module, "validation_step", *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
    wrapper_output = wrapper_module(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
    out = method(*_args, **_kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/generative_modeling.py", line 527, in validation_step
    out_tuple = self.model(batch)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/conditionally_independent_model.py", line 329, in forward
    encoded = self.encoder(batch, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/transformer.py", line 828, in forward
    torch._assert(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/__init__.py", line 2132, in _assert
    assert condition, message
AssertionError: 383400 NaNs in input_embeds

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[rank: 1] Child process with PID 1187783 terminated with code 1. Forcefully terminating all other processes to avoid zombies üßü
2025-04-10 14:46:21,078 - wandb.wandb_agent - INFO - Cleaning up finished run: y8g9bo7m
[2025-04-10 14:46:21,078][wandb.wandb_agent][INFO] - Cleaning up finished run: y8g9bo7m
2025-04-10 14:46:21,705 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:46:21,705][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:46:21,705 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.2702717673588413
	config.input_dropout: 0.1920312458793053
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.34472843498522154
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: max
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 41
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.5285428973709969
	optimization_config.init_lr: 0.009421349005597284
	optimization_config.lr_decay_power: 2.8847696351674417
	optimization_config.lr_frac_warmup_steps: 2.8597640234139265e-05
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.00817531382057172
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:46:21,705][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.2702717673588413
	config.input_dropout: 0.1920312458793053
	config.is_cls_dist: False
	config.is_event_classification: True
	config.resid_dropout: 0.34472843498522154
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: max
	data_config.max_seq_len: 256
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 41
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.5285428973709969
	optimization_config.init_lr: 0.009421349005597284
	optimization_config.lr_decay_power: 2.8847696351674417
	optimization_config.lr_frac_warmup_steps: 2.8597640234139265e-05
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 10
	optimization_config.weight_decay: 0.00817531382057172
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_event_label
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:46:21,711 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.2702717673588413 config.input_dropout=0.1920312458793053 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.34472843498522154 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=max data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=41 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.5285428973709969 optimization_config.init_lr=0.009421349005597284 optimization_config.lr_decay_power=2.8847696351674417 optimization_config.lr_frac_warmup_steps=2.8597640234139265e-05 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.00817531382057172 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:46:21,711][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.2702717673588413 config.input_dropout=0.1920312458793053 config.is_cls_dist=False config.is_event_classification=True config.resid_dropout=0.34472843498522154 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=max data_config.max_seq_len=256 data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=41 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.5285428973709969 optimization_config.init_lr=0.009421349005597284 optimization_config.lr_decay_power=2.8847696351674417 optimization_config.lr_frac_warmup_steps=2.8597640234139265e-05 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=10 optimization_config.weight_decay=0.00817531382057172 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_event_label trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
2025-04-10 14:46:26,722 - wandb.wandb_agent - INFO - Running runs: ['a242w05h']
[2025-04-10 14:46:26,722][wandb.wandb_agent][INFO] - Running runs: ['a242w05h']
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_event_label/wandb/run-20250410_144630-a242w05h
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/sj5xnnh1
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/a242w05h
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)
[2025-04-10 14:46:37,211][wandb.sdk.internal.internal_api][ERROR] - 404 response executing GraphQL.
[2025-04-10 14:46:37,211][wandb.sdk.internal.internal_api][ERROR] - {"errors":[{"message":"could not find agent 1z1z8wm6 during agentHeartbeat","path":["agentHeartbeat"]}],"data":{"agentHeartbeat":null}}
wandb: ERROR Error while calling W&B API: could not find agent 1z1z8wm6 during agentHeartbeat (<Response [404]>)
wandb: Terminating and syncing runs. Press ctrl-c to kill.
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/lib/retry.py", line 131, in __call__
    result = self._call_fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 366, in execute
    return self.client.execute(*args, **kwargs)  # type: ignore
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 52, in execute
    result = self._get_result(document, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 60, in _get_result
    return self.transport.execute(document, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/lib/gql_request.py", line 59, in execute
    request.raise_for_status()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://api.wandb.ai/graphql

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 2777, in agent_heartbeat
    response = self.gql(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 338, in gql
    ret = self._retry_gql(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/lib/retry.py", line 147, in __call__
    retry_timedelta_triggered = check_retry_fn(e)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/util.py", line 906, in no_retry_auth
    raise CommError(
wandb.errors.CommError: It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 404: Not Found)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/scripts/launch_finetuning_wandb_hp_sweep.py", line 113, in main
    wandb.agent(project=sweep_kwargs["project"], entity="marcus-student-chalmers-personal", sweep_id=sweep_id)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/wandb_agent.py", line 583, in agent
    return run_agent(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/wandb_agent.py", line 528, in run_agent
    agent.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/wandb_agent.py", line 277, in run
    commands = self._api.agent_heartbeat(agent_id, {}, run_status)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/apis/internal.py", line 153, in agent_heartbeat
    return self.api.agent_heartbeat(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 2788, in agent_heartbeat
    message = ast.literal_eval(e.args[0])["message"]
  File "/usr/lib/python3.10/ast.py", line 64, in literal_eval
    node_or_string = parse(node_or_string.lstrip(" \t"), mode='eval')
  File "/usr/lib/python3.10/ast.py", line 50, in parse
    return compile(source, filename, mode, flags,
  File "<unknown>", line 1
    It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 404: Not Found)
       ^^^^^^^
SyntaxError: invalid syntax

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)
Running sweep with config: FT_hp_sweep_interruption_in_seq
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
2025-04-10 14:46:45,922 - wandb.wandb_agent - INFO - Running runs: []
Create sweep with ID: pcobuuh4
Sweep URL: https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/pcobuuh4
[2025-04-10 14:46:45,922][wandb.wandb_agent][INFO] - Running runs: []
2025-04-10 14:46:46,199 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:46:46,199][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:46:46,200 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.0811174720681564
	config.input_dropout: 0.23554346392655623
	config.is_cls_dist: False
	config.is_event_classification: False
	config.resid_dropout: 0.31116144306689336
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: max
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 62
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.000338095620123374
	optimization_config.init_lr: 0.0023039135155050504
	optimization_config.lr_decay_power: 4.903441109327579
	optimization_config.lr_frac_warmup_steps: 0.00023952080860051693
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 8
	optimization_config.weight_decay: 0.0068215100267745585
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_interruption_in_seq
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:46:46,200][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.0811174720681564
	config.input_dropout: 0.23554346392655623
	config.is_cls_dist: False
	config.is_event_classification: False
	config.resid_dropout: 0.31116144306689336
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: max
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 62
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.000338095620123374
	optimization_config.init_lr: 0.0023039135155050504
	optimization_config.lr_decay_power: 4.903441109327579
	optimization_config.lr_frac_warmup_steps: 0.00023952080860051693
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 8
	optimization_config.weight_decay: 0.0068215100267745585
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_interruption_in_seq
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:46:46,210 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.0811174720681564 config.input_dropout=0.23554346392655623 config.is_cls_dist=False config.is_event_classification=False config.resid_dropout=0.31116144306689336 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=max data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=62 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.000338095620123374 optimization_config.init_lr=0.0023039135155050504 optimization_config.lr_decay_power=4.903441109327579 optimization_config.lr_frac_warmup_steps=0.00023952080860051693 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=8 optimization_config.weight_decay=0.0068215100267745585 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_interruption_in_seq trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:46:46,210][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.0811174720681564 config.input_dropout=0.23554346392655623 config.is_cls_dist=False config.is_event_classification=False config.resid_dropout=0.31116144306689336 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=max data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=62 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.000338095620123374 optimization_config.init_lr=0.0023039135155050504 optimization_config.lr_decay_power=4.903441109327579 optimization_config.lr_frac_warmup_steps=0.00023952080860051693 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=8 optimization_config.weight_decay=0.0068215100267745585 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_interruption_in_seq trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
2025-04-10 14:46:51,221 - wandb.wandb_agent - INFO - Running runs: ['1sp3233v']
[2025-04-10 14:46:51,221][wandb.wandb_agent][INFO] - Running runs: ['1sp3233v']
Seed set to 1
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_interruption_in_seq/wandb/run-20250410_144652-1sp3233v
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/pcobuuh4
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/1sp3233v
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_interruption_in_seq', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.0811174720681564
Overwriting input_dropout in config from 0.4494236115512016 to 0.23554346392655623
Overwriting resid_dropout in config from 0.4939188761966135 to 0.31116144306689336
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to False
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'max', 'num_samples': None}
Re-loading task data for task_df_eneryield_interruption_in_seq from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq/train_0.parquet
Re-loading task data for task_df_eneryield_interruption_in_seq from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_interruption_in_seq/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_interruption_in_seq', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.0811174720681564
Overwriting input_dropout in config from 0.4494236115512016 to 0.23554346392655623
Overwriting resid_dropout in config from 0.4939188761966135 to 0.31116144306689336
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to False
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'max', 'num_samples': None}
Re-loading task data for task_df_eneryield_interruption_in_seq from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq/train_0.parquet
Re-loading task data for task_df_eneryield_interruption_in_seq from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq/tuning_0.parquet

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.42it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/2 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] 
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.79it/s]
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.79it/s, v_num=233v]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.32it/s, v_num=233v]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.32it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.44it/s][A

                                                                      [A
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.88it/s, v_num=233v]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.87it/s, v_num=233v]
Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.72it/s, v_num=233v]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.72it/s, v_num=233v]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.22it/s, v_num=233v]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.22it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.18it/s][A

                                                                      [A
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.83it/s, v_num=233v]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.83it/s, v_num=233v]
Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.78it/s, v_num=233v]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.78it/s, v_num=233v]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.32it/s, v_num=233v]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.31it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.84it/s][A

                                                                      [A
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.87it/s, v_num=233v]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.87it/s, v_num=233v]
Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.68it/s, v_num=233v]
Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.68it/s, v_num=233v]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.07it/s, v_num=233v]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.07it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.87it/s][A

                                                                      [A
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.75it/s, v_num=233v]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.75it/s, v_num=233v]
Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.69it/s, v_num=233v]
Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.69it/s, v_num=233v]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.19it/s, v_num=233v]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.19it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.35it/s][A

                                                                      [A
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.83it/s, v_num=233v]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.82it/s, v_num=233v]
Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.70it/s, v_num=233v]
Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.70it/s, v_num=233v]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.20it/s, v_num=233v]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.20it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s][A

                                                                      [A
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.81it/s, v_num=233v]
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.81it/s, v_num=233v]
Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.66it/s, v_num=233v]
Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.66it/s, v_num=233v]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.13it/s, v_num=233v]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.13it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.04it/s][A

                                                                      [A
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.77it/s, v_num=233v]
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.77it/s, v_num=233v]
Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.65it/s, v_num=233v]
Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.65it/s, v_num=233v]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.12it/s, v_num=233v]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.12it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s][A

                                                                      [A
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.70it/s, v_num=233v]
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.70it/s, v_num=233v]
Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.55it/s, v_num=233v]
Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.55it/s, v_num=233v]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.97it/s, v_num=233v]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.97it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.14it/s][A

                                                                      [A
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.68it/s, v_num=233v]
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.67it/s, v_num=233v]
Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.64it/s, v_num=233v]
Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.64it/s, v_num=233v]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.11it/s, v_num=233v]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.11it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.94it/s][A

                                                                      [A
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.80it/s, v_num=233v]
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.79it/s, v_num=233v]
Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.64it/s, v_num=233v]
Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.64it/s, v_num=233v]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.09it/s, v_num=233v]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.09it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.86it/s][A

                                                                      [A
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.79it/s, v_num=233v]
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.79it/s, v_num=233v]
Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.65it/s, v_num=233v]
Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.64it/s, v_num=233v]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.10it/s, v_num=233v]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.10it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.86it/s][A

                                                                      [A
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.80it/s, v_num=233v]
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.80it/s, v_num=233v]
Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.58it/s, v_num=233v]
Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.58it/s, v_num=233v]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.99it/s, v_num=233v]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.98it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.35it/s][A

                                                                      [A
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.71it/s, v_num=233v]
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.70it/s, v_num=233v]
Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.60it/s, v_num=233v]
Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.60it/s, v_num=233v]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.04it/s, v_num=233v]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.04it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.00it/s][A

                                                                      [A
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.77it/s, v_num=233v]
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.77it/s, v_num=233v]
Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.56it/s, v_num=233v]
Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.56it/s, v_num=233v]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.98it/s, v_num=233v]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.98it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.86it/s][A

                                                                      [A
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.73it/s, v_num=233v]
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.73it/s, v_num=233v]
Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.65it/s, v_num=233v]
Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.65it/s, v_num=233v]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.10it/s, v_num=233v]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.10it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.37it/s][A

                                                                      [A
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.77it/s, v_num=233v]
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.76it/s, v_num=233v]
Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.67it/s, v_num=233v]
Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.67it/s, v_num=233v]
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.14it/s, v_num=233v]
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.14it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s][A

                                                                      [A
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.81it/s, v_num=233v]
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.81it/s, v_num=233v]
Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 17:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.66it/s, v_num=233v]
Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.66it/s, v_num=233v]
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.10it/s, v_num=233v]
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.10it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.40it/s][A

                                                                      [A
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.78it/s, v_num=233v]
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.78it/s, v_num=233v]
Epoch 17:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]        
Epoch 18:   0%|          | 0/2 [00:00<?, ?it/s, v_num=233v]
Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.59it/s, v_num=233v]
Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.59it/s, v_num=233v]
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.01it/s, v_num=233v]
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.01it/s, v_num=233v]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.85it/s][A

                                                                      [A
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.74it/s, v_num=233v]
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.74it/s, v_num=233v]
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.73it/s, v_num=233v]Restoring states from the checkpoint path at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_interruption_in_seq/eneryield_ft_sweep/1sp3233v/checkpoints/epoch=10-val_loss=0.00-best_model.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
Loaded model weights from the checkpoint at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_interruption_in_seq/eneryield_ft_sweep/1sp3233v/checkpoints/epoch=10-val_loss=0.00-best_model.ckpt
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:216: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.

/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_interruption_in_seq/finetune_weights
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Re-loading task data for task_df_eneryield_interruption_in_seq from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq/held_out_0.parquet
/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_interruption_in_seq/finetune_weights
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Re-loading task data for task_df_eneryield_interruption_in_seq from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq/held_out_0.parquet

Validation: |          | 0/? [00:00<?, ?it/s]
Validation:   0%|          | 0/1 [00:00<?, ?it/s]
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.44it/s]
Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]Restoring states from the checkpoint path at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_interruption_in_seq/eneryield_ft_sweep/1sp3233v/checkpoints/epoch=10-val_loss=0.00-best_model.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
Loaded model weights from the checkpoint at /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_interruption_in_seq/eneryield_ft_sweep/1sp3233v/checkpoints/epoch=10-val_loss=0.00-best_model.ckpt
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:216: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
          Validate metric                       DataLoader 0
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
             task_AUROC                      0.5833333134651184
           task_accuracy                     0.7000000476837158
             task_loss                       10.046354293823242
           tuning_TTE_MSE                     32635.580078125
          tuning_TTE_MSLE                    7.662966251373291
         tuning_TTE_reg_NLL                  5.478168964385986
     tuning_event_label_cls_NLL             0.16692006587982178
 tuning_event_label_macro_accuracy           0.9344079494476318
 tuning_event_label_micro_accuracy           0.9344080090522766
 tuning_event_label_weighted_AUROC           0.7265058755874634
tuning_event_label_weighted_accuracy         0.7769001722335815
     tuning_event_type_cls_NLL              0.008980464190244675
  tuning_event_type_macro_accuracy                  0.0
  tuning_event_type_micro_accuracy                  0.0
  tuning_event_type_weighted_AUROC                  0.0
tuning_event_type_weighted_accuracy                 0.0
        tuning_feature_0_MSE                0.16516177356243134
      tuning_feature_0_reg_NLL              -0.03942649066448212
       tuning_feature_10_MSE                 1.4378107786178589
     tuning_feature_10_reg_NLL               1.123732566833496
       tuning_feature_11_MSE                 2.4985718727111816
     tuning_feature_11_reg_NLL               1.3568429946899414
       tuning_feature_12_MSE                 2.0881307125091553
     tuning_feature_12_reg_NLL               1.2390720844268799
       tuning_feature_13_MSE                 2.3186888694763184
     tuning_feature_13_reg_NLL                1.42486572265625
       tuning_feature_14_MSE                 1.6722123622894287
     tuning_feature_14_reg_NLL               1.193088173866272
       tuning_feature_15_MSE                 1.9963396787643433
     tuning_feature_15_reg_NLL               1.3876029253005981
       tuning_feature_16_MSE                 1.6324357986450195
     tuning_feature_16_reg_NLL               1.3108136653900146
       tuning_feature_17_MSE                 1.8075404167175293
     tuning_feature_17_reg_NLL               1.3209311962127686
       tuning_feature_18_MSE                 1.6027963161468506
     tuning_feature_18_reg_NLL               1.1307867765426636
       tuning_feature_19_MSE                 0.6247126460075378
     tuning_feature_19_reg_NLL               0.6310133934020996
        tuning_feature_1_MSE                 0.5439877510070801
      tuning_feature_1_reg_NLL              0.13311801850795746
       tuning_feature_20_MSE                 0.5444042682647705
     tuning_feature_20_reg_NLL               0.5923725962638855
       tuning_feature_21_MSE                 0.5678051114082336
     tuning_feature_21_reg_NLL               0.5823950171470642
       tuning_feature_22_MSE                 7.7617316246032715
     tuning_feature_22_reg_NLL               3.9386038780212402
       tuning_feature_23_MSE                 6.598361015319824
     tuning_feature_23_reg_NLL               1.7062932252883911
       tuning_feature_24_MSE                 16.930217742919922
     tuning_feature_24_reg_NLL               2.1491713523864746
        tuning_feature_2_MSE                 1.8555660247802734
      tuning_feature_2_reg_NLL               0.827643632888794
        tuning_feature_3_MSE                 2.0708682537078857
      tuning_feature_3_reg_NLL               0.8129433393478394
        tuning_feature_4_MSE                 1.5398592948913574
      tuning_feature_4_reg_NLL               0.4747525453567505
        tuning_feature_5_MSE                 0.7282723188400269
      tuning_feature_5_reg_NLL               0.5225473642349243
        tuning_feature_6_MSE                 1.210206389427185
      tuning_feature_6_reg_NLL               1.0556509494781494
        tuning_feature_7_MSE                 1.8841192722320557
      tuning_feature_7_reg_NLL               1.4731968641281128
        tuning_feature_8_MSE                 1.6652549505233765
      tuning_feature_8_reg_NLL               1.407463788986206
        tuning_feature_9_MSE                 2.178147315979004
      tuning_feature_9_reg_NLL               1.3570492267608643
            tuning_loss                      44.812950134277344
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

Testing: |          | 0/? [00:00<?, ?it/s]
Testing:   0%|          | 0/1 [00:00<?, ?it/s]
Testing DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Testing DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.76it/s]
Testing DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.67it/s]wandb: Waiting for W&B process to finish... (success).
wandb: - 0.000 MB of 0.000 MB uploaded (0.000 MB deduped)
wandb: \ 0.050 MB of 0.050 MB uploaded (0.000 MB deduped)
wandb: | 0.050 MB of 0.050 MB uploaded (0.000 MB deduped)
wandb: 
wandb: Run history:
wandb:                                  epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                       held_out_TTE_MSE ‚ñÅ
wandb:                      held_out_TTE_MSLE ‚ñÅ
wandb:                   held_out_TTE_reg_NLL ‚ñÅ
wandb:           held_out_event_label_cls_NLL ‚ñÅ
wandb:    held_out_event_label_macro_accuracy ‚ñÅ
wandb:    held_out_event_label_micro_accuracy ‚ñÅ
wandb:    held_out_event_label_weighted_AUROC ‚ñÅ
wandb: held_out_event_label_weighted_accuracy ‚ñÅ
wandb:            held_out_event_type_cls_NLL ‚ñÅ
wandb:     held_out_event_type_macro_accuracy ‚ñÅ
wandb:     held_out_event_type_micro_accuracy ‚ñÅ
wandb:     held_out_event_type_weighted_AUROC ‚ñÅ
wandb:  held_out_event_type_weighted_accuracy ‚ñÅ
wandb:                 held_out_feature_0_MSE ‚ñÅ
wandb:             held_out_feature_0_reg_NLL ‚ñÅ
wandb:                held_out_feature_10_MSE ‚ñÅ
wandb:            held_out_feature_10_reg_NLL ‚ñÅ
wandb:                held_out_feature_11_MSE ‚ñÅ
wandb:            held_out_feature_11_reg_NLL ‚ñÅ
wandb:                held_out_feature_12_MSE ‚ñÅ
wandb:            held_out_feature_12_reg_NLL ‚ñÅ
wandb:                held_out_feature_13_MSE ‚ñÅ
wandb:            held_out_feature_13_reg_NLL ‚ñÅ
wandb:                held_out_feature_14_MSE ‚ñÅ
wandb:            held_out_feature_14_reg_NLL ‚ñÅ
wandb:                held_out_feature_15_MSE ‚ñÅ
wandb:            held_out_feature_15_reg_NLL ‚ñÅ
wandb:                held_out_feature_16_MSE ‚ñÅ
wandb:            held_out_feature_16_reg_NLL ‚ñÅ
wandb:                held_out_feature_17_MSE ‚ñÅ
wandb:            held_out_feature_17_reg_NLL ‚ñÅ
wandb:                held_out_feature_18_MSE ‚ñÅ
wandb:            held_out_feature_18_reg_NLL ‚ñÅ
wandb:                held_out_feature_19_MSE ‚ñÅ
wandb:            held_out_feature_19_reg_NLL ‚ñÅ
wandb:                 held_out_feature_1_MSE ‚ñÅ
wandb:             held_out_feature_1_reg_NLL ‚ñÅ
wandb:                held_out_feature_20_MSE ‚ñÅ
wandb:            held_out_feature_20_reg_NLL ‚ñÅ
wandb:                held_out_feature_21_MSE ‚ñÅ
wandb:            held_out_feature_21_reg_NLL ‚ñÅ
wandb:                held_out_feature_22_MSE ‚ñÅ
wandb:            held_out_feature_22_reg_NLL ‚ñÅ
wandb:                held_out_feature_23_MSE ‚ñÅ
wandb:            held_out_feature_23_reg_NLL ‚ñÅ
wandb:                held_out_feature_24_MSE ‚ñÅ
wandb:            held_out_feature_24_reg_NLL ‚ñÅ
wandb:                 held_out_feature_2_MSE ‚ñÅ
wandb:             held_out_feature_2_reg_NLL ‚ñÅ
wandb:                 held_out_feature_3_MSE ‚ñÅ
wandb:             held_out_feature_3_reg_NLL ‚ñÅ
wandb:                 held_out_feature_4_MSE ‚ñÅ
wandb:             held_out_feature_4_reg_NLL ‚ñÅ
wandb:                 held_out_feature_5_MSE ‚ñÅ
wandb:             held_out_feature_5_reg_NLL ‚ñÅ
wandb:                 held_out_feature_6_MSE ‚ñÅ
wandb:             held_out_feature_6_reg_NLL ‚ñÅ
wandb:                 held_out_feature_7_MSE ‚ñÅ
wandb:             held_out_feature_7_reg_NLL ‚ñÅ
wandb:                 held_out_feature_8_MSE ‚ñÅ
wandb:             held_out_feature_8_reg_NLL ‚ñÅ
wandb:                 held_out_feature_9_MSE ‚ñÅ
wandb:             held_out_feature_9_reg_NLL ‚ñÅ
wandb:                          held_out_loss ‚ñÅ
wandb:                             task_AUROC ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÅ
wandb:                          task_accuracy ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:                              task_loss ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                    trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                         tuning_TTE_MSE ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:                        tuning_TTE_MSLE ‚ñÜ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ
wandb:                     tuning_TTE_reg_NLL ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÇ
wandb:             tuning_event_label_cls_NLL ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÑ
wandb:      tuning_event_label_macro_accuracy ‚ñá‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñà
wandb:      tuning_event_label_micro_accuracy ‚ñá‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñà
wandb:      tuning_event_label_weighted_AUROC ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ
wandb:   tuning_event_label_weighted_accuracy ‚ñÖ‚ñÑ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:              tuning_event_type_cls_NLL ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñÅ
wandb:       tuning_event_type_macro_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       tuning_event_type_micro_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       tuning_event_type_weighted_AUROC ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:    tuning_event_type_weighted_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   tuning_feature_0_MSE ‚ñÑ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ
wandb:               tuning_feature_0_reg_NLL ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ
wandb:                  tuning_feature_10_MSE ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:              tuning_feature_10_reg_NLL ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:                  tuning_feature_11_MSE ‚ñÖ‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:              tuning_feature_11_reg_NLL ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:                  tuning_feature_12_MSE ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:              tuning_feature_12_reg_NLL ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb:                  tuning_feature_13_MSE ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ
wandb:              tuning_feature_13_reg_NLL ‚ñà‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:                  tuning_feature_14_MSE ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:              tuning_feature_14_reg_NLL ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ
wandb:                  tuning_feature_15_MSE ‚ñà‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá
wandb:              tuning_feature_15_reg_NLL ‚ñÇ‚ñÅ‚ñá‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ
wandb:                  tuning_feature_16_MSE ‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá
wandb:              tuning_feature_16_reg_NLL ‚ñá‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:                  tuning_feature_17_MSE ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ
wandb:              tuning_feature_17_reg_NLL ‚ñà‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:                  tuning_feature_18_MSE ‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ
wandb:              tuning_feature_18_reg_NLL ‚ñà‚ñÜ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ
wandb:                  tuning_feature_19_MSE ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
wandb:              tuning_feature_19_reg_NLL ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:                   tuning_feature_1_MSE ‚ñá‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:               tuning_feature_1_reg_NLL ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:                  tuning_feature_20_MSE ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:              tuning_feature_20_reg_NLL ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                  tuning_feature_21_MSE ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:              tuning_feature_21_reg_NLL ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                  tuning_feature_22_MSE ‚ñÇ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:              tuning_feature_22_reg_NLL ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà
wandb:                  tuning_feature_23_MSE ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÇ
wandb:              tuning_feature_23_reg_NLL ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá
wandb:                  tuning_feature_24_MSE ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb:              tuning_feature_24_reg_NLL ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:                   tuning_feature_2_MSE ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:               tuning_feature_2_reg_NLL ‚ñÅ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ
wandb:                   tuning_feature_3_MSE ‚ñÇ‚ñÑ‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb:               tuning_feature_3_reg_NLL ‚ñÅ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb:                   tuning_feature_4_MSE ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
wandb:               tuning_feature_4_reg_NLL ‚ñá‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:                   tuning_feature_5_MSE ‚ñÜ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:               tuning_feature_5_reg_NLL ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:                   tuning_feature_6_MSE ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ
wandb:               tuning_feature_6_reg_NLL ‚ñÉ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ
wandb:                   tuning_feature_7_MSE ‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ
wandb:               tuning_feature_7_reg_NLL ‚ñÜ‚ñÅ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ
wandb:                   tuning_feature_8_MSE ‚ñÑ‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ
wandb:               tuning_feature_8_reg_NLL ‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ
wandb:                   tuning_feature_9_MSE ‚ñÜ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñá
wandb:               tuning_feature_9_reg_NLL ‚ñÉ‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ
wandb:                            tuning_loss ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                                  epoch 19
wandb:                       held_out_TTE_MSE 35063.54297
wandb:                      held_out_TTE_MSLE 7.90927
wandb:                   held_out_TTE_reg_NLL 5.55964
wandb:           held_out_event_label_cls_NLL 0.18751
wandb:    held_out_event_label_macro_accuracy 0.93685
wandb:    held_out_event_label_micro_accuracy 0.93685
wandb:    held_out_event_label_weighted_AUROC 0.87242
wandb: held_out_event_label_weighted_accuracy 0.8216
wandb:            held_out_event_type_cls_NLL 0.00966
wandb:     held_out_event_type_macro_accuracy 0.0
wandb:     held_out_event_type_micro_accuracy 0.0
wandb:     held_out_event_type_weighted_AUROC 0.0
wandb:  held_out_event_type_weighted_accuracy 0.0
wandb:                 held_out_feature_0_MSE 1.06397
wandb:             held_out_feature_0_reg_NLL 0.73009
wandb:                held_out_feature_10_MSE 2.31075
wandb:            held_out_feature_10_reg_NLL 2.27438
wandb:                held_out_feature_11_MSE 2.57136
wandb:            held_out_feature_11_reg_NLL 1.80278
wandb:                held_out_feature_12_MSE 3.07864
wandb:            held_out_feature_12_reg_NLL 2.39461
wandb:                held_out_feature_13_MSE 2.37851
wandb:            held_out_feature_13_reg_NLL 2.3683
wandb:                held_out_feature_14_MSE 2.4555
wandb:            held_out_feature_14_reg_NLL 1.31997
wandb:                held_out_feature_15_MSE 1.92269
wandb:            held_out_feature_15_reg_NLL 1.4394
wandb:                held_out_feature_16_MSE 1.68251
wandb:            held_out_feature_16_reg_NLL 1.37449
wandb:                held_out_feature_17_MSE 1.78497
wandb:            held_out_feature_17_reg_NLL 1.37089
wandb:                held_out_feature_18_MSE 1.97231
wandb:            held_out_feature_18_reg_NLL 1.53467
wandb:                held_out_feature_19_MSE 1.11135
wandb:            held_out_feature_19_reg_NLL 1.00479
wandb:                 held_out_feature_1_MSE 1.7759
wandb:             held_out_feature_1_reg_NLL 1.93936
wandb:                held_out_feature_20_MSE 1.05063
wandb:            held_out_feature_20_reg_NLL 1.01835
wandb:                held_out_feature_21_MSE 1.09701
wandb:            held_out_feature_21_reg_NLL 0.99459
wandb:                held_out_feature_22_MSE 1.00251
wandb:            held_out_feature_22_reg_NLL 0.92855
wandb:                held_out_feature_23_MSE 1.67459
wandb:            held_out_feature_23_reg_NLL 1.05356
wandb:                held_out_feature_24_MSE 1.77596
wandb:            held_out_feature_24_reg_NLL 1.12727
wandb:                 held_out_feature_2_MSE 1.71532
wandb:             held_out_feature_2_reg_NLL 1.86286
wandb:                 held_out_feature_3_MSE 1.31514
wandb:             held_out_feature_3_reg_NLL 1.4771
wandb:                 held_out_feature_4_MSE 1.2624
wandb:             held_out_feature_4_reg_NLL 1.61336
wandb:                 held_out_feature_5_MSE 1.58352
wandb:             held_out_feature_5_reg_NLL 2.69525
wandb:                 held_out_feature_6_MSE 1.02378
wandb:             held_out_feature_6_reg_NLL 0.9796
wandb:                 held_out_feature_7_MSE 1.8179
wandb:             held_out_feature_7_reg_NLL 1.46668
wandb:                 held_out_feature_8_MSE 1.50479
wandb:             held_out_feature_8_reg_NLL 1.3432
wandb:                 held_out_feature_9_MSE 2.22278
wandb:             held_out_feature_9_reg_NLL 1.41162
wandb:                          held_out_loss 56.83082
wandb:                             task_AUROC 0.45387
wandb:                          task_accuracy 0.6
wandb:                              task_loss 13.5483
wandb:                    trainer/global_step 38
wandb:                         tuning_TTE_MSE 32635.58008
wandb:                        tuning_TTE_MSLE 7.66297
wandb:                     tuning_TTE_reg_NLL 5.47817
wandb:             tuning_event_label_cls_NLL 0.16692
wandb:      tuning_event_label_macro_accuracy 0.93441
wandb:      tuning_event_label_micro_accuracy 0.93441
wandb:      tuning_event_label_weighted_AUROC 0.72651
wandb:   tuning_event_label_weighted_accuracy 0.7769
wandb:              tuning_event_type_cls_NLL 0.00898
wandb:       tuning_event_type_macro_accuracy 0.0
wandb:       tuning_event_type_micro_accuracy 0.0
wandb:       tuning_event_type_weighted_AUROC 0.0
wandb:    tuning_event_type_weighted_accuracy 0.0
wandb:                   tuning_feature_0_MSE 0.16516
wandb:               tuning_feature_0_reg_NLL -0.03943
wandb:                  tuning_feature_10_MSE 1.43781
wandb:              tuning_feature_10_reg_NLL 1.12373
wandb:                  tuning_feature_11_MSE 2.49857
wandb:              tuning_feature_11_reg_NLL 1.35684
wandb:                  tuning_feature_12_MSE 2.08813
wandb:              tuning_feature_12_reg_NLL 1.23907
wandb:                  tuning_feature_13_MSE 2.31869
wandb:              tuning_feature_13_reg_NLL 1.42487
wandb:                  tuning_feature_14_MSE 1.67221
wandb:              tuning_feature_14_reg_NLL 1.19309
wandb:                  tuning_feature_15_MSE 1.99634
wandb:              tuning_feature_15_reg_NLL 1.3876
wandb:                  tuning_feature_16_MSE 1.63244
wandb:              tuning_feature_16_reg_NLL 1.31081
wandb:                  tuning_feature_17_MSE 1.80754
wandb:              tuning_feature_17_reg_NLL 1.32093
wandb:                  tuning_feature_18_MSE 1.6028
wandb:              tuning_feature_18_reg_NLL 1.13079
wandb:                  tuning_feature_19_MSE 0.62471
wandb:              tuning_feature_19_reg_NLL 0.63101
wandb:                   tuning_feature_1_MSE 0.54399
wandb:               tuning_feature_1_reg_NLL 0.13312
wandb:                  tuning_feature_20_MSE 0.5444
wandb:              tuning_feature_20_reg_NLL 0.59237
wandb:                  tuning_feature_21_MSE 0.56781
wandb:              tuning_feature_21_reg_NLL 0.5824
wandb:                  tuning_feature_22_MSE 7.76173
wandb:              tuning_feature_22_reg_NLL 3.9386
wandb:                  tuning_feature_23_MSE 6.59836
wandb:              tuning_feature_23_reg_NLL 1.70629
wandb:                  tuning_feature_24_MSE 16.93022
wandb:              tuning_feature_24_reg_NLL 2.14917
wandb:                   tuning_feature_2_MSE 1.85557
wandb:               tuning_feature_2_reg_NLL 0.82764
wandb:                   tuning_feature_3_MSE 2.07087
wandb:               tuning_feature_3_reg_NLL 0.81294
wandb:                   tuning_feature_4_MSE 1.53986
wandb:               tuning_feature_4_reg_NLL 0.47475
wandb:                   tuning_feature_5_MSE 0.72827
wandb:               tuning_feature_5_reg_NLL 0.52255
wandb:                   tuning_feature_6_MSE 1.21021
wandb:               tuning_feature_6_reg_NLL 1.05565
wandb:                   tuning_feature_7_MSE 1.88412
wandb:               tuning_feature_7_reg_NLL 1.4732
wandb:                   tuning_feature_8_MSE 1.66525
wandb:               tuning_feature_8_reg_NLL 1.40746
wandb:                   tuning_feature_9_MSE 2.17815
wandb:               tuning_feature_9_reg_NLL 1.35705
wandb:                            tuning_loss 44.81295
wandb: 
wandb: üöÄ View run generative_event_stream_transformer at: https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/1sp3233v
wandb: Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./pretrain/eneryield/finetuning/task_df_eneryield_interruption_in_seq/wandb/run-20250410_144652-1sp3233v/logs

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
             Test metric                           DataLoader 0
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
           held_out_TTE_MSE                       35063.54296875
          held_out_TTE_MSLE                     7.909273624420166
         held_out_TTE_reg_NLL                   5.559643268585205
     held_out_event_label_cls_NLL              0.18750815093517303
 held_out_event_label_macro_accuracy            0.9368484020233154
 held_out_event_label_micro_accuracy            0.9368483424186707
 held_out_event_label_weighted_AUROC            0.8724167346954346
held_out_event_label_weighted_accuracy          0.8215963840484619
     held_out_event_type_cls_NLL               0.009659388102591038
  held_out_event_type_macro_accuracy                   0.0
  held_out_event_type_micro_accuracy                   0.0
  held_out_event_type_weighted_AUROC                   0.0
held_out_event_type_weighted_accuracy                  0.0
        held_out_feature_0_MSE                  1.0639718770980835
      held_out_feature_0_reg_NLL                0.7300927042961121
       held_out_feature_10_MSE                  2.3107521533966064
     held_out_feature_10_reg_NLL                2.274376153945923
       held_out_feature_11_MSE                  2.571355104446411
     held_out_feature_11_reg_NLL                1.802781105041504
       held_out_feature_12_MSE                  3.078636407852173
     held_out_feature_12_reg_NLL                2.3946146965026855
       held_out_feature_13_MSE                  2.3785083293914795
     held_out_feature_13_reg_NLL                2.3683035373687744
       held_out_feature_14_MSE                  2.4554951190948486
     held_out_feature_14_reg_NLL                1.3199719190597534
       held_out_feature_15_MSE                  1.9226945638656616
     held_out_feature_15_reg_NLL                1.4393999576568604
       held_out_feature_16_MSE                  1.6825098991394043
     held_out_feature_16_reg_NLL                1.3744850158691406
       held_out_feature_17_MSE                  1.7849663496017456
     held_out_feature_17_reg_NLL                1.3708857297897339
       held_out_feature_18_MSE                  1.9723148345947266
     held_out_feature_18_reg_NLL                1.5346742868423462
       held_out_feature_19_MSE                  1.1113524436950684
     held_out_feature_19_reg_NLL                1.0047906637191772
        held_out_feature_1_MSE                  1.7759047746658325
      held_out_feature_1_reg_NLL                1.9393571615219116
       held_out_feature_20_MSE                  1.0506311655044556
     held_out_feature_20_reg_NLL                1.0183475017547607
       held_out_feature_21_MSE                  1.0970109701156616
     held_out_feature_21_reg_NLL                0.994590163230896
       held_out_feature_22_MSE                  1.0025118589401245
     held_out_feature_22_reg_NLL                0.9285500049591064
       held_out_feature_23_MSE                  1.674587368965149
     held_out_feature_23_reg_NLL                1.053564429283142
       held_out_feature_24_MSE                  1.7759562730789185
     held_out_feature_24_reg_NLL                1.1272673606872559
        held_out_feature_2_MSE                  1.7153183221817017
      held_out_feature_2_reg_NLL                1.862857699394226
        held_out_feature_3_MSE                  1.3151397705078125
      held_out_feature_3_reg_NLL                1.477102518081665
        held_out_feature_4_MSE                  1.2623976469039917
      held_out_feature_4_reg_NLL                1.613357663154602
        held_out_feature_5_MSE                  1.5835164785385132
      held_out_feature_5_reg_NLL                2.6952526569366455
        held_out_feature_6_MSE                  1.0237840414047241
      held_out_feature_6_reg_NLL                0.9795987606048584
        held_out_feature_7_MSE                  1.8178989887237549
      held_out_feature_7_reg_NLL                1.4666757583618164
        held_out_feature_8_MSE                  1.5047879219055176
      held_out_feature_8_reg_NLL                1.3431978225708008
        held_out_feature_9_MSE                  2.2227799892425537
      held_out_feature_9_reg_NLL                1.4116169214248657
            held_out_loss                       56.83081817626953
              task_AUROC                        0.4538690745830536
            task_accuracy                       0.5999999642372131
              task_loss                         13.548298835754395
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Saving final metrics...
2025-04-10 14:48:03,554 - wandb.wandb_agent - INFO - Cleaning up finished run: 1sp3233v
[2025-04-10 14:48:03,554][wandb.wandb_agent][INFO] - Cleaning up finished run: 1sp3233v
2025-04-10 14:48:05,004 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:48:05,004][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:48:05,004 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.1739541381288366
	config.input_dropout: 0.04599125150971495
	config.is_cls_dist: False
	config.is_event_classification: False
	config.resid_dropout: 0.22415535250195445
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: mean
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 58
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.18995468005096655
	optimization_config.init_lr: 0.6354938279391936
	optimization_config.lr_decay_power: 3.8158746683967424
	optimization_config.lr_frac_warmup_steps: 0.1730177616789857
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 8
	optimization_config.weight_decay: 0.00790006155934278
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_interruption_in_seq
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:48:05,004][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.1739541381288366
	config.input_dropout: 0.04599125150971495
	config.is_cls_dist: False
	config.is_event_classification: False
	config.resid_dropout: 0.22415535250195445
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: mean
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 58
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.18995468005096655
	optimization_config.init_lr: 0.6354938279391936
	optimization_config.lr_decay_power: 3.8158746683967424
	optimization_config.lr_frac_warmup_steps: 0.1730177616789857
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 8
	optimization_config.weight_decay: 0.00790006155934278
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_interruption_in_seq
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:48:05,018 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.1739541381288366 config.input_dropout=0.04599125150971495 config.is_cls_dist=False config.is_event_classification=False config.resid_dropout=0.22415535250195445 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=mean data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=58 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.18995468005096655 optimization_config.init_lr=0.6354938279391936 optimization_config.lr_decay_power=3.8158746683967424 optimization_config.lr_frac_warmup_steps=0.1730177616789857 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=8 optimization_config.weight_decay=0.00790006155934278 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_interruption_in_seq trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:48:05,018][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.1739541381288366 config.input_dropout=0.04599125150971495 config.is_cls_dist=False config.is_event_classification=False config.resid_dropout=0.22415535250195445 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=mean data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=58 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.18995468005096655 optimization_config.init_lr=0.6354938279391936 optimization_config.lr_decay_power=3.8158746683967424 optimization_config.lr_frac_warmup_steps=0.1730177616789857 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=8 optimization_config.weight_decay=0.00790006155934278 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_interruption_in_seq trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
2025-04-10 14:48:10,031 - wandb.wandb_agent - INFO - Running runs: ['lid3894x']
[2025-04-10 14:48:10,031][wandb.wandb_agent][INFO] - Running runs: ['lid3894x']
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1
Terminated
Running sweep with config: FT_hp_sweep_interruption_next_week
wandb: Currently logged in as: marcus-student-chalmers (marcus-student-chalmers-personal). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: wandb version 0.19.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_interruption_in_seq/wandb/run-20250410_144813-lid3894x
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run generative_event_stream_transformer
wandb: ‚≠êÔ∏è View project at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep
wandb: üßπ View sweep at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/pcobuuh4
wandb: üöÄ View run at https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/runs/lid3894x
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-04-10 14:48:20,597 - wandb.wandb_agent - INFO - Running runs: []
Create sweep with ID: xr3apx2j
Sweep URL: https://wandb.ai/marcus-student-chalmers-personal/eneryield_ft_sweep/sweeps/xr3apx2j
[2025-04-10 14:48:20,597][wandb.wandb_agent][INFO] - Running runs: []
2025-04-10 14:48:20,943 - wandb.wandb_agent - INFO - Agent received command: run
[2025-04-10 14:48:20,943][wandb.wandb_agent][INFO] - Agent received command: run
2025-04-10 14:48:20,944 - wandb.wandb_agent - INFO - Agent starting run with config:
	config.attention_dropout: 0.3098025165580312
	config.input_dropout: 0.3828406544084096
	config.is_cls_dist: False
	config.is_event_classification: False
	config.resid_dropout: 0.2275914392452988
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: last
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 13
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.10505565183244996
	optimization_config.init_lr: 0.7159377871158936
	optimization_config.lr_decay_power: 1.3363080597357604
	optimization_config.lr_frac_warmup_steps: 2.710644657669468e-06
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 8
	optimization_config.weight_decay: 0.0047655251203918255
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_interruption_next_week
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
[2025-04-10 14:48:20,944][wandb.wandb_agent][INFO] - Agent starting run with config:
	config.attention_dropout: 0.3098025165580312
	config.input_dropout: 0.3828406544084096
	config.is_cls_dist: False
	config.is_event_classification: False
	config.resid_dropout: 0.2275914392452988
	config.save_metrics: False
	config.save_metrics_fp: /home/filip-marcus/resutls/eneryield/test
	config.task_specific_params.pooling_method: last
	data_config.save_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
	do_overwrite: True
	load_from_model_dir: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/
	optimization_config.batch_size: 13
	optimization_config.end_lr: null
	optimization_config.end_lr_frac_of_init_lr: 0.10505565183244996
	optimization_config.init_lr: 0.7159377871158936
	optimization_config.lr_decay_power: 1.3363080597357604
	optimization_config.lr_frac_warmup_steps: 2.710644657669468e-06
	optimization_config.max_epochs: 200
	optimization_config.num_dataloader_workers: 5
	optimization_config.patience: 8
	optimization_config.weight_decay: 0.0047655251203918255
	pretrained_weights_fp: /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights
	seed: 1
	task_df_name: task_df_eneryield_interruption_next_week
	trainer_config.detect_anomaly: False
	trainer_config.log_every_n_steps: 50
	wandb_logger_kwargs.do_log_graph: False
	wandb_logger_kwargs.log_model: False
	wandb_logger_kwargs.name: generative_event_stream_transformer
	wandb_logger_kwargs.project: eneryield_ft_sweep
2025-04-10 14:48:20,956 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.3098025165580312 config.input_dropout=0.3828406544084096 config.is_cls_dist=False config.is_event_classification=False config.resid_dropout=0.2275914392452988 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=last data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=13 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.10505565183244996 optimization_config.init_lr=0.7159377871158936 optimization_config.lr_decay_power=1.3363080597357604 optimization_config.lr_frac_warmup_steps=2.710644657669468e-06 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=8 optimization_config.weight_decay=0.0047655251203918255 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_interruption_next_week trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
[2025-04-10 14:48:20,956][wandb.wandb_agent][INFO] - About to run command: /usr/bin/env python scripts/finetune.py config.attention_dropout=0.3098025165580312 config.input_dropout=0.3828406544084096 config.is_cls_dist=False config.is_event_classification=False config.resid_dropout=0.2275914392452988 config.save_metrics=False config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test config.task_specific_params.pooling_method=last data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield do_overwrite=True load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/ optimization_config.batch_size=13 optimization_config.end_lr=null optimization_config.end_lr_frac_of_init_lr=0.10505565183244996 optimization_config.init_lr=0.7159377871158936 optimization_config.lr_decay_power=1.3363080597357604 optimization_config.lr_frac_warmup_steps=2.710644657669468e-06 optimization_config.max_epochs=200 optimization_config.num_dataloader_workers=5 optimization_config.patience=8 optimization_config.weight_decay=0.0047655251203918255 pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights seed=1 task_df_name=task_df_eneryield_interruption_next_week trainer_config.detect_anomaly=False trainer_config.log_every_n_steps=50 wandb_logger_kwargs.do_log_graph=False wandb_logger_kwargs.log_model=False wandb_logger_kwargs.name=generative_event_stream_transformer wandb_logger_kwargs.project=eneryield_ft_sweep
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                               | Params | Mode 
---------------------------------------------------------------------------
0 | tte_metrics | ModuleDict                         | 0      | train
1 | metrics     | ModuleDict                         | 0      | train
2 | model       | CIPPTForGenerativeSequenceModeling | 1.5 M  | eval 
---------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
6.148     Total estimated model params size (MB)
92        Modules in train mode
197       Modules in eval mode
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_interruption_in_seq', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.1739541381288366
Overwriting input_dropout in config from 0.4494236115512016 to 0.04599125150971495
Overwriting resid_dropout in config from 0.4939188761966135 to 0.22415535250195445
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to False
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'mean', 'num_samples': None}
Re-loading task data for task_df_eneryield_interruption_in_seq from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq/train_0.parquet
Re-loading task data for task_df_eneryield_interruption_in_seq from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_interruption_in_seq/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_interruption_in_seq', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.1739541381288366
Overwriting input_dropout in config from 0.4494236115512016 to 0.04599125150971495
Overwriting resid_dropout in config from 0.4939188761966135 to 0.22415535250195445
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to False
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'mean', 'num_samples': None}
Re-loading task data for task_df_eneryield_interruption_in_seq from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq/train_0.parquet
Re-loading task data for task_df_eneryield_interruption_in_seq from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_in_seq/tuning_0.parquet
Terminated
./sweep_script.sh: line 15: unexpected EOF while looking for matching `"'
./sweep_script.sh: line 17: syntax error: unexpected end of file

Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  0.93it/s]
                                                                           
/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/2 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] 
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  0.48it/s]
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  0.48it/s, v_num=894x]WARNING: For a conditionally_independent model, measurements_per_dep_graph_level is not used; got []. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
Seed set to 1

Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.75it/s, v_num=894x]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.75it/s, v_num=894x]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.08it/s][ATraceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_manager.py", line 115, in _service_connect
    svc_iface._svc_connect(port=port)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/service/service_sock.py", line 30, in _svc_connect
    self._sock_client.connect(port=port)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 102, in connect
    s.connect(("localhost", port))
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 378, in wrap
    fn_return = task_func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/fine_tuning_dev.py", line 378, in train
    wandb_logger.experiment.config.update(cfg.wandb_experiment_config_kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/fabric/loggers/logger.py", line 118, in experiment
    return fn(self)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py", line 407, in experiment
    self._experiment = wandb.init(**self._wandb_init)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1189, in init
    raise e
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1166, in init
    wi.setup(kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 191, in setup
    self._wl = wandb_setup.setup(settings=setup_settings)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 327, in setup
    ret = _setup(settings=settings)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 320, in _setup
    wl = _WandbSetup(settings=settings)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 303, in __init__
    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 114, in __init__
    self._setup()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 250, in _setup
    self._setup_manager()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 277, in _setup_manager
    self._manager = wandb_manager._Manager(settings=self._settings)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_manager.py", line 152, in __init__
    wandb._sentry.reraise(e)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/analytics/sentry.py", line 154, in reraise
    raise exc.with_traceback(sys.exc_info()[2])
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_manager.py", line 150, in __init__
    self._service_connect()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_manager.py", line 124, in _service_connect
    raise ManagerConnectionRefusedError(message)
wandb.sdk.wandb_manager.ManagerConnectionRefusedError: Connection to wandb service failed since the process is not available. 
None
Loading data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/data_config.json
reloaded_data_config PytorchDatasetConfig(save_dir=PosixPath('/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield'), max_seq_len=256, min_seq_len=2, seq_padding_side='right', subsequence_sampling_strategy='random', train_subset_size='FULL', train_subset_seed=1, task_df_name='task_df_eneryield_interruption_next_week', do_include_subsequence_indices=False, do_include_subject_id=False, do_include_start_time_min=False)
Overwriting save_dir in data_config from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield to /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield
Overwriting seq_padding_side in data_config from right to right
Overwriting subsequence_sampling_strategy in data_config from random to to_end
Overwriting train_subset_size in data_config from FULL to FULL
Overwriting train_subset_seed in data_config from 1 to 1
Loading config from /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/config.json
Overwriting attention_dropout in config from 0.004563095202856138 to 0.3098025165580312
Overwriting input_dropout in config from 0.4494236115512016 to 0.3828406544084096
Overwriting resid_dropout in config from 0.4939188761966135 to 0.2275914392452988
Overwriting is_cls_dist in config from False to False
Overwriting is_event_classification in config from False to False
Overwriting save_metrics in config from True to False
Overwriting save_metrics_fp in config from /home/filip-marcus/results/eneryield/pretrain_10_04_2025 to /home/filip-marcus/resutls/eneryield/test
Overwriting task_specific_params in config from None to {'pooling_method': 'last', 'num_samples': None}
Re-loading task data for task_df_eneryield_interruption_next_week from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_next_week:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_next_week/train_0.parquet
Re-loading task data for task_df_eneryield_interruption_next_week from /home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_next_week:
/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield/DL_reps/for_task/task_df_eneryield_interruption_next_week/tuning_0.parquet
Saving config files...
Writing to /home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/finetuning/task_df_eneryield_interruption_next_week/config.json
WARNING: For a conditionally_independent model, do_full_block_in_seq_attention is not used; got False. Setting to None.
WARNING: For a conditionally_independent model, do_full_block_in_dep_graph_attention is not used; got True. Setting to None.
WARNING: For a conditionally_independent model, dep_graph_window_size is not used; got 2. Setting to None.
EXCEPTION: Connection to wandb service failed since the process is not available. 
Error executing job with overrides: ['config.attention_dropout=0.3098025165580312', 'config.input_dropout=0.3828406544084096', 'config.is_cls_dist=False', 'config.is_event_classification=False', 'config.resid_dropout=0.2275914392452988', 'config.save_metrics=False', 'config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test', 'config.task_specific_params.pooling_method=last', 'data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield', 'do_overwrite=True', 'load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/', 'optimization_config.batch_size=13', 'optimization_config.end_lr=null', 'optimization_config.end_lr_frac_of_init_lr=0.10505565183244996', 'optimization_config.init_lr=0.7159377871158936', 'optimization_config.lr_decay_power=1.3363080597357604', 'optimization_config.lr_frac_warmup_steps=2.710644657669468e-06', 'optimization_config.max_epochs=200', 'optimization_config.num_dataloader_workers=5', 'optimization_config.patience=8', 'optimization_config.weight_decay=0.0047655251203918255', 'pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights', 'seed=1', 'task_df_name=task_df_eneryield_interruption_next_week', 'trainer_config.detect_anomaly=False', 'trainer_config.log_every_n_steps=50', 'wandb_logger_kwargs.do_log_graph=False', 'wandb_logger_kwargs.log_model=False', 'wandb_logger_kwargs.name=generative_event_stream_transformer', 'wandb_logger_kwargs.project=eneryield_ft_sweep']
Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_manager.py", line 115, in _service_connect
    svc_iface._svc_connect(port=port)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/service/service_sock.py", line 30, in _svc_connect
    self._sock_client.connect(port=port)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 102, in connect
    s.connect(("localhost", port))
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/scripts/finetune.py", line 44, in main
    return train(cfg)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 385, in wrap
    raise ex
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 378, in wrap
    fn_return = task_func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/fine_tuning_dev.py", line 378, in train
    wandb_logger.experiment.config.update(cfg.wandb_experiment_config_kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/fabric/loggers/logger.py", line 118, in experiment
    return fn(self)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py", line 407, in experiment
    self._experiment = wandb.init(**self._wandb_init)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1189, in init
    raise e
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1166, in init
    wi.setup(kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 191, in setup
    self._wl = wandb_setup.setup(settings=setup_settings)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 327, in setup
    ret = _setup(settings=settings)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 320, in _setup
    wl = _WandbSetup(settings=settings)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 303, in __init__
    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 114, in __init__
    self._setup()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 250, in _setup
    self._setup_manager()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py", line 277, in _setup_manager
    self._manager = wandb_manager._Manager(settings=self._settings)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_manager.py", line 152, in __init__
    wandb._sentry.reraise(e)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/analytics/sentry.py", line 154, in reraise
    raise exc.with_traceback(sys.exc_info()[2])
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_manager.py", line 150, in __init__
    self._service_connect()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/wandb/sdk/wandb_manager.py", line 124, in _service_connect
    raise ManagerConnectionRefusedError(message)
wandb.sdk.wandb_manager.ManagerConnectionRefusedError: Connection to wandb service failed since the process is not available. 

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.


                                                                      [A
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  0.41it/s, v_num=894x]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  0.41it/s, v_num=894x]
Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s, v_num=894x]        
Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=894x]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  0.41it/s, v_num=894x]
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  0.41it/s, v_num=894x]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  0.66it/s, v_num=894x]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  0.66it/s, v_num=894x]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.30it/s][A

                                                                      [A
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  0.39it/s, v_num=894x]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  0.39it/s, v_num=894x]
Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=894x]        
Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=894x]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.58it/s, v_num=894x]
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  0.58it/s, v_num=894x]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.86it/s, v_num=894x]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  0.86it/s, v_num=894x]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.03it/s][A

                                                                      [A
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  0.46it/s, v_num=894x]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  0.46it/s, v_num=894x]
Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=894x]        
Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, v_num=894x][rank: 1] Received SIGTERM: 15
[rank: 0] Received SIGTERM: 15
[rank: 1] Received SIGTERM: 15

Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  0.47it/s, v_num=894x]
Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  0.47it/s, v_num=894x]Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
    self.advance(data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 320, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 176, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1302, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 140, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 493, in wrapper
    out = func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
    loss = closure()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1097, in backward
    loss.backward(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/_tensor.py", line 626, in backward
    torch.autograd.backward(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/autograd/graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1198989) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 378, in wrap
    fn_return = task_func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/fine_tuning_dev.py", line 388, in train
    trainer.fit(model=LM, train_dataloaders=train_dataloader, val_dataloaders=tuning_dataloader)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 69, in _call_and_handle_interrupt
    trainer._teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1035, in _teardown
    self.strategy.teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 419, in teardown
    super().teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/parallel.py", line 134, in teardown
    super().teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 536, in teardown
    self.lightning_module.cpu()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/fabric/utilities/device_dtype_mixin.py", line 82, in cpu
    return super().cpu()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1121, in cpu
    return self._apply(lambda t: t.cpu())
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 929, in _apply
    with torch.no_grad():
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 85, in __exit__
    torch.set_grad_enabled(self.prev)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 187, in __init__
    torch._C._set_grad_enabled(mode)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1198817) is killed by signal: Terminated. 
None
EXCEPTION: DataLoader worker (pid 1198817) is killed by signal: Terminated. 
Error executing job with overrides: ['config.attention_dropout=0.1739541381288366', 'config.input_dropout=0.04599125150971495', 'config.is_cls_dist=False', 'config.is_event_classification=False', 'config.resid_dropout=0.22415535250195445', 'config.save_metrics=False', 'config.save_metrics_fp=/home/filip-marcus/resutls/eneryield/test', 'config.task_specific_params.pooling_method=mean', 'data_config.save_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/data/processed/eneryield', 'do_overwrite=True', 'load_from_model_dir=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/', 'optimization_config.batch_size=58', 'optimization_config.end_lr=null', 'optimization_config.end_lr_frac_of_init_lr=0.18995468005096655', 'optimization_config.init_lr=0.6354938279391936', 'optimization_config.lr_decay_power=3.8158746683967424', 'optimization_config.lr_frac_warmup_steps=0.1730177616789857', 'optimization_config.max_epochs=200', 'optimization_config.num_dataloader_workers=5', 'optimization_config.patience=8', 'optimization_config.weight_decay=0.00790006155934278', 'pretrained_weights_fp=/home/filip-marcus/ESGPT_new/EventStreamGPT/pretrain/eneryield/pretrained_weights', 'seed=1', 'task_df_name=task_df_eneryield_interruption_in_seq', 'trainer_config.detect_anomaly=False', 'trainer_config.log_every_n_steps=50', 'wandb_logger_kwargs.do_log_graph=False', 'wandb_logger_kwargs.log_model=False', 'wandb_logger_kwargs.name=generative_event_stream_transformer', 'wandb_logger_kwargs.project=eneryield_ft_sweep']
Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 151, in run
    self.on_advance_end(data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 386, in on_advance_end
    raise SIGTERMException
lightning.pytorch.utilities.exceptions.SIGTERMException

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 378, in wrap
    fn_return = task_func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/fine_tuning_dev.py", line 388, in train
    trainer.fit(model=LM, train_dataloaders=train_dataloader, val_dataloaders=tuning_dataloader)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 69, in _call_and_handle_interrupt
    trainer._teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1035, in _teardown
    self.strategy.teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 419, in teardown
    super().teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/parallel.py", line 134, in teardown
    super().teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 532, in teardown
    _optimizers_to_device(self.optimizers, torch.device("cpu"))
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/fabric/utilities/optimizer.py", line 27, in _optimizers_to_device
    _optimizer_to_device(opt, device)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/fabric/utilities/optimizer.py", line 41, in _optimizer_to_device
    v[key] = move_data_to_device(val, device)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py", line 110, in move_data_to_device
    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py", line 66, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py", line 104, in batch_to
    data_output = data.to(device, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1199033) is killed by signal: Terminated. 
None
wandb: Waiting for W&B process to finish... (success).
Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
    self.advance(data_fetcher)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 320, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 176, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1302, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 140, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 493, in wrapper
    out = func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
    loss = closure()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1097, in backward
    loss.backward(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/_tensor.py", line 626, in backward
    torch.autograd.backward(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/autograd/graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1198989) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/scripts/finetune.py", line 44, in main
    return train(cfg)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 385, in wrap
    raise ex
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/utils.py", line 378, in wrap
    fn_return = task_func(*args, **kwargs)
  File "/home/filip-marcus/ESGPT_new/EventStreamGPT/EventStream/transformer/lightning_modules/fine_tuning_dev.py", line 388, in train
    trainer.fit(model=LM, train_dataloaders=train_dataloader, val_dataloaders=tuning_dataloader)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 69, in _call_and_handle_interrupt
    trainer._teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1035, in _teardown
    self.strategy.teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 419, in teardown
    super().teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/parallel.py", line 134, in teardown
    super().teardown()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 536, in teardown
    self.lightning_module.cpu()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/lightning/fabric/utilities/device_dtype_mixin.py", line 82, in cpu
    return super().cpu()
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1121, in cpu
    return self._apply(lambda t: t.cpu())
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 929, in _apply
    with torch.no_grad():
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 85, in __exit__
    torch.set_grad_enabled(self.prev)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 187, in __init__
    torch._C._set_grad_enabled(mode)
  File "/home/filip-marcus/ESGPT_new/esgpt-new-venv/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1198817) is killed by signal: Terminated. 

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[rank: 1] Child process with PID 1197711 terminated with code 1. Forcefully terminating all other processes to avoid zombies üßü
